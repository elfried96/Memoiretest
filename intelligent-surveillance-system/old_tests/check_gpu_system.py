#!/usr/bin/env python3
"""
üîç V√©rification Compl√®te du Syst√®me GPU
=====================================

Script de diagnostic pour s'assurer que tout fonctionne parfaitement
sur serveur GPU avant les tests de production.
"""

import sys
import subprocess
import importlib
from pathlib import Path
import torch
import cv2
import numpy as np

# Ajout du chemin
sys.path.insert(0, str(Path(__file__).parent))

from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn

console = Console()

def check_gpu_setup():
    """V√©rification de la configuration GPU."""
    
    console.print(Panel.fit(
        "[bold blue]üîç DIAGNOSTIC SYST√àME GPU[/bold blue]\n"
        "[dim]V√©rification compl√®te pour serveur de surveillance[/dim]",
        border_style="blue"
    ))
    
    # Table des r√©sultats
    results_table = Table(title="üìä √âtat du Syst√®me")
    results_table.add_column("Composant", style="cyan", no_wrap=True)
    results_table.add_column("Status", style="bold")
    results_table.add_column("D√©tails", style="dim")
    
    # 1. V√©rification GPU
    try:
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            results_table.add_row(
                "GPU NVIDIA", 
                "‚úÖ D√©tect√©", 
                f"{gpu_name} ({gpu_memory:.1f} GB)"
            )
        else:
            results_table.add_row(
                "GPU NVIDIA", 
                "‚ö†Ô∏è Non d√©tect√©", 
                "Mode CPU activ√©"
            )
    except Exception as e:
        results_table.add_row(
            "GPU NVIDIA", 
            "‚ùå Erreur", 
            str(e)
        )
    
    # 2. PyTorch
    try:
        import torch
        cuda_status = "GPU" if torch.cuda.is_available() else "CPU"
        results_table.add_row(
            "PyTorch", 
            "‚úÖ Install√©", 
            f"v{torch.__version__} ({cuda_status})"
        )
    except ImportError:
        results_table.add_row(
            "PyTorch", 
            "‚ùå Manquant", 
            "pip install torch"
        )
    
    # 3. Ultralytics YOLO
    try:
        from ultralytics import YOLO
        model = YOLO('yolov11n.pt')
        results_table.add_row(
            "YOLO11", 
            "‚úÖ Pr√™t", 
            "Mod√®le t√©l√©charg√©"
        )
    except Exception as e:
        results_table.add_row(
            "YOLO11", 
            "‚ùå Probl√®me", 
            str(e)[:50]
        )
    
    # 4. OpenCV
    try:
        import cv2
        results_table.add_row(
            "OpenCV", 
            "‚úÖ Install√©", 
            f"v{cv2.__version__}"
        )
    except ImportError:
        results_table.add_row(
            "OpenCV", 
            "‚ùå Manquant", 
            "pip install opencv-python"
        )
    
    # 5. Transformers
    try:
        import transformers
        results_table.add_row(
            "Transformers", 
            "‚úÖ Install√©", 
            f"v{transformers.__version__}"
        )
    except ImportError:
        results_table.add_row(
            "Transformers", 
            "‚ùå Manquant", 
            "pip install transformers"
        )
    
    # 6. Types syst√®me
    try:
        from src.core.types import Detection, BoundingBox, AnalysisRequest
        results_table.add_row(
            "Types Syst√®me", 
            "‚úÖ Import√©s", 
            "Detection, BoundingBox, etc."
        )
    except ImportError as e:
        results_table.add_row(
            "Types Syst√®me", 
            "‚ùå Erreur", 
            str(e)[:50]
        )
    
    # 7. VLM Registry
    try:
        from src.core.vlm.model_registry import VLMModelRegistry
        registry = VLMModelRegistry()
        models = registry.list_available_models()
        results_table.add_row(
            "VLM Registry", 
            "‚úÖ Op√©rationnel", 
            f"{len(models)} mod√®les"
        )
    except Exception as e:
        results_table.add_row(
            "VLM Registry", 
            "‚ùå Erreur", 
            str(e)[:50]
        )
    
    # 8. Orchestrateur
    try:
        from src.core.orchestrator.vlm_orchestrator import ModernVLMOrchestrator
        results_table.add_row(
            "Orchestrateur", 
            "‚úÖ Pr√™t", 
            "ModernVLMOrchestrator"
        )
    except ImportError as e:
        results_table.add_row(
            "Orchestrateur", 
            "‚ùå Erreur", 
            str(e)[:50]
        )
    
    console.print(results_table)
    return results_table

def test_yolo_inference():
    """Test d'inf√©rence YOLO11."""
    
    console.print("\nüéØ Test d'Inf√©rence YOLO11")
    
    try:
        from ultralytics import YOLO
        
        # Chargement mod√®le
        model = YOLO('yolov11n.pt')
        console.print("‚úÖ Mod√®le YOLO11 charg√©")
        
        # Image de test
        test_image = np.random.randint(0, 255, (640, 480, 3), dtype=np.uint8)
        
        # Inf√©rence
        import time
        start_time = time.time()
        results = model(test_image, verbose=False)
        inference_time = time.time() - start_time
        
        console.print(f"‚úÖ Inf√©rence r√©ussie en {inference_time:.3f}s")
        
        # V√©rification GPU
        if torch.cuda.is_available():
            console.print(f"üî• GPU utilis√©: {torch.cuda.get_device_name(0)}")
        else:
            console.print("üíª CPU utilis√©")
            
        return True
        
    except Exception as e:
        console.print(f"‚ùå Erreur inf√©rence: {e}")
        return False

def test_system_integration():
    """Test d'int√©gration syst√®me."""
    
    console.print("\nüß™ Test d'Int√©gration Syst√®me")
    
    try:
        # Import des composants
        from src.core.types import Detection, BoundingBox
        from src.core.orchestrator.vlm_orchestrator import OrchestrationConfig, OrchestrationMode
        
        # Test BoundingBox
        bbox = BoundingBox(x1=100, y1=100, x2=200, y2=200, confidence=0.8)
        console.print(f"‚úÖ BoundingBox: {bbox.width}x{bbox.height}")
        
        # Test Detection
        detection = Detection(
            class_id=0,
            class_name="person",
            bbox=bbox,
            confidence=0.85
        )
        console.print(f"‚úÖ Detection: {detection.class_name}")
        
        # Test Config
        config = OrchestrationConfig(
            mode=OrchestrationMode.BALANCED,
            enable_advanced_tools=True
        )
        console.print(f"‚úÖ Config: {config.mode.value}")
        
        return True
        
    except Exception as e:
        console.print(f"‚ùå Erreur int√©gration: {e}")
        return False

def run_performance_benchmark():
    """Benchmark de performance."""
    
    console.print("\n‚ö° Benchmark de Performance")
    
    # Test m√©moire GPU
    if torch.cuda.is_available():
        torch.cuda.reset_peak_memory_stats()
        
        # Allocation test
        x = torch.randn(1000, 1000).cuda()
        y = torch.matmul(x, x)
        
        memory_used = torch.cuda.max_memory_allocated() / 1e6
        console.print(f"üî• M√©moire GPU utilis√©e: {memory_used:.1f} MB")
        
        del x, y
        torch.cuda.empty_cache()
    
    # Test YOLO performance
    try:
        from ultralytics import YOLO
        model = YOLO('yolov11n.pt')
        
        # Images de test multiples
        images = [np.random.randint(0, 255, (640, 480, 3), dtype=np.uint8) for _ in range(10)]
        
        import time
        start_time = time.time()
        
        for img in images:
            results = model(img, verbose=False)
        
        total_time = time.time() - start_time
        fps = len(images) / total_time
        
        console.print(f"‚ö° Performance: {fps:.1f} FPS sur {len(images)} images")
        
    except Exception as e:
        console.print(f"‚ùå Erreur benchmark: {e}")

def generate_gpu_report():
    """G√©n√©ration rapport GPU."""
    
    report = {
        "gpu_available": torch.cuda.is_available(),
        "pytorch_version": torch.__version__,
        "cuda_version": torch.version.cuda if torch.cuda.is_available() else None,
    }
    
    if torch.cuda.is_available():
        report.update({
            "gpu_name": torch.cuda.get_device_name(0),
            "gpu_memory_gb": torch.cuda.get_device_properties(0).total_memory / 1e9,
            "gpu_count": torch.cuda.device_count()
        })
    
    return report

def main():
    """Fonction principale."""
    
    # 1. Diagnostic syst√®me
    results_table = check_gpu_setup()
    
    # 2. Test YOLO
    yolo_ok = test_yolo_inference()
    
    # 3. Test int√©gration
    integration_ok = test_system_integration()
    
    # 4. Benchmark
    run_performance_benchmark()
    
    # 5. Rapport final
    console.print("\n" + "="*60)
    console.print(Panel.fit(
        "[bold green]üìã RAPPORT FINAL[/bold green]",
        border_style="green"
    ))
    
    if yolo_ok and integration_ok:
        console.print("üéâ [bold green]SYST√àME PR√äT POUR PRODUCTION ![/bold green]")
        console.print("\nüí° Commandes recommand√©es:")
        console.print("   ‚Ä¢ python test_full_system_video.py --video webcam --max-frames 50")
        console.print("   ‚Ä¢ python main.py --video webcam")
    else:
        console.print("‚ö†Ô∏è [bold yellow]PROBL√àMES D√âTECT√âS[/bold yellow]")
        console.print("üîß V√©rifiez les erreurs ci-dessus et relancez setup_gpu_server.sh")
    
    # G√©n√©ration rapport
    report = generate_gpu_report()
    console.print(f"\nüìä Configuration GPU: {report}")

if __name__ == "__main__":
    main()