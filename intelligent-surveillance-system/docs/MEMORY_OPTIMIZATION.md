# üíæ Guide d'Optimisation M√©moire

Guide pour √©conomiser la m√©moire lors des tests et de l'utilisation du syst√®me de surveillance.

## üéØ Probl√®me de M√©moire

Le syst√®me utilise des mod√®les VLM volumineux (Kimi-VL, Qwen2-VL) qui peuvent consommer beaucoup de m√©moire RAM/VRAM, surtout avec les mod√®les de fallback charg√©s simultan√©ment.

## ‚úÖ Solutions Impl√©ment√©es

### 1. **Configuration Sans Fallback par D√©faut**

```python
# Configuration par d√©faut (√©conome en m√©moire)
vlm_config = VLMConfig(
    primary_model="kimi-vl-a3b-thinking",
    fallback_models=[],  # Pas de mod√®les de fallback
    enable_fallback=False,
    load_in_4bit=True  # Quantization pour √©conomiser m√©moire
)
```

### 2. **Profils de Configuration D√©di√©s**

```bash
# Tests avec mod√®le l√©ger
ENV=testing python run_system.py

# Tests avec Kimi-VL uniquement  
ENV=testing_kimi python run_system.py

# Tests avec Qwen2-VL uniquement
ENV=testing_qwen python run_system.py
```

### 3. **Nettoyage M√©moire Optimis√©**

Le syst√®me inclut un nettoyage m√©moire avanc√© :
- Garbage collection Python
- Nettoyage cache GPU/CUDA
- Synchronisation GPU
- Lib√©ration explicite des tensors

## üöÄ Utilisation Optimis√©e

### Tests avec Mod√®le Unique

```bash
# Test Kimi-VL seulement
python scripts/test_single_model.py --kimi --memory-stats

# Test Qwen2-VL seulement  
python scripts/test_single_model.py --qwen --memory-stats

# Test mod√®le l√©ger
python scripts/test_single_model.py --git-base --memory-stats
```

### Tests Automatis√©s Optimis√©s

```bash
# Tests unitaires (mod√®le l√©ger par d√©faut)
python scripts/run_tests.py --unit

# Tests complets sans mod√®les lourds
ENV=testing python scripts/run_tests.py --all
```

### Syst√®me Principal avec Kimi-VL Uniquement

```bash
# Mode d√©veloppement (Kimi-VL uniquement)
ENV=development python run_system.py

# Mode production (Kimi-VL optimis√©)
ENV=production python run_system.py
```

## üìä Monitoring M√©moire

### Script de Test avec Stats M√©moire

```bash
python scripts/test_single_model.py --kimi --memory-stats
```

Affiche :
- Utilisation RAM (RSS/VMS)
- M√©moire GPU allou√©e/r√©serv√©e
- Avant/apr√®s chargement

### Variables d'Environnement

```bash
# Forcer mode √©conome
export ENABLE_FALLBACK=false
export VLM_MODEL=microsoft/git-base-coco  # Mod√®le l√©ger
export LOAD_IN_4BIT=true

# Monitoring m√©moire
export DISABLE_MONITORING=true  # √âconomise ressources
```

## ‚öôÔ∏è Configuration par Cas d'Usage

### üß™ Tests Unitaires (M√©moire Minimale)
```python
config = load_config("testing")
# ‚Üí Git-base, pas de fallback, quantization 4-bit
```

### üî¨ Tests avec Kimi-VL
```python  
config = load_config("testing_kimi")
# ‚Üí Kimi-VL uniquement, pas de fallback
```

### üåü Tests avec Qwen2-VL
```python
config = load_config("testing_qwen")
# ‚Üí Qwen2-VL uniquement, pas de fallback
```

### üöÄ Production
```python
config = load_config("production")
# ‚Üí Kimi-VL, pas de fallback, qualit√© optimale
```

## üîß Param√®tres d'Optimisation

### Quantization 4-bit
```python
vlm_config.load_in_4bit = True  # R√©duit utilisation m√©moire ~50%
```

### Device Management
```python
vlm_config.device = DeviceType.CPU  # Force CPU si GPU satur√©
```

### Concurrent Tools
```python
orchestration_config.max_concurrent_tools = 1  # Limite parall√©lisme
```

## üìà M√©triques de Performance

### Utilisation M√©moire Typique

| Configuration | RAM | VRAM | Temps Chargement |
|---------------|-----|------|------------------|
| Git-base + CPU | ~2GB | 0GB | ~5s |
| Git-base + GPU | ~1GB | ~2GB | ~3s |
| Kimi-VL + CPU | ~4GB | 0GB | ~15s |
| Kimi-VL + GPU | ~2GB | ~4GB | ~8s |
| Qwen2-VL + GPU | ~3GB | ~6GB | ~12s |

### Avec Fallback (NON Recommand√©)
| Configuration | RAM | VRAM | Temps Chargement |
|---------------|-----|------|------------------|
| Kimi + Qwen fallback | ~6GB | ~10GB | ~25s |

## ‚ö†Ô∏è Bonnes Pratiques

### ‚úÖ DO
- Utilisez un seul mod√®le √† la fois
- Activez la quantization 4-bit
- Lib√©rez la m√©moire apr√®s tests
- Utilisez les profils de configuration appropri√©s

### ‚ùå DON'T  
- Ne chargez pas multiple mod√®les simultan√©ment
- N'utilisez pas de fallback en d√©veloppement
- Ne gardez pas les mod√®les en m√©moire inutilement
- N'oubliez pas le nettoyage GPU

## üõ†Ô∏è D√©pannage

### Erreur "Out of Memory"
```bash
# Solution 1: Forcer CPU
export VLM_DEVICE=cpu

# Solution 2: Mod√®le plus l√©ger
export VLM_MODEL=microsoft/git-base-coco

# Solution 3: Quantization 4-bit
export LOAD_IN_4BIT=true
```

### Syst√®me Lent apr√®s Tests
```python
# Nettoyage manuel
vlm._unload_current_model()
torch.cuda.empty_cache()
```

### Monitoring Continu
```bash
# Surveillance m√©moire en temps r√©el
watch -n 1 'nvidia-smi && free -h'
```

---

**Optimisation M√©moire v1.0.0**  
*Syst√®me de Surveillance Intelligente - Tests Efficaces*