# ğŸ§ª Guide des Tests - Outils AvancÃ©s de Surveillance

## ğŸ“‹ Vue d'ensemble

Ce guide vous explique comment tester individuellement chacun des 8 outils avancÃ©s du systÃ¨me de surveillance intelligente, ainsi que comment exÃ©cuter la suite complÃ¨te de tests.

## ğŸ“‚ Structure des Fichiers de Test

```
intelligent-surveillance-system/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ advanced_tools/           # Code source des outils
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ sam2_segmentation.py
â”‚       â”œâ”€â”€ dino_features.py
â”‚       â”œâ”€â”€ pose_estimation.py
â”‚       â”œâ”€â”€ trajectory_analyzer.py
â”‚       â”œâ”€â”€ multimodal_fusion.py
â”‚       â”œâ”€â”€ temporal_transformer.py
â”‚       â”œâ”€â”€ adversarial_detector.py
â”‚       â””â”€â”€ domain_adapter.py
â”œâ”€â”€ test_sam2_segmentator.py      # Tests SAM2 segmentation
â”œâ”€â”€ test_dino_features.py         # Tests extraction features DINO v2
â”œâ”€â”€ test_pose_estimation.py       # Tests estimation de poses
â”œâ”€â”€ test_trajectory_analyzer.py   # Tests analyse trajectoires
â”œâ”€â”€ test_multimodal_fusion.py     # Tests fusion multimodale
â”œâ”€â”€ test_temporal_transformer.py  # Tests analyse temporelle
â”œâ”€â”€ test_adversarial_detector.py  # Tests dÃ©tection adversariale
â”œâ”€â”€ test_domain_adapter.py        # Tests adaptation domaines
â”œâ”€â”€ run_all_tests.py              # Script principal pour tous les tests
â”œâ”€â”€ RAPPORT_TESTS_OUTILS_AVANCES.md  # Rapport consolidÃ©
â””â”€â”€ README_TESTS.md               # Ce guide
```

## ğŸš€ Installation des DÃ©pendances

### DÃ©pendances Minimales (pour fallbacks)
```bash
pip install numpy opencv-python scikit-learn scipy
```

### DÃ©pendances ComplÃ¨tes (pour tous les modÃ¨les)
```bash
pip install numpy opencv-python torch torchvision scikit-learn scipy transformers mediapipe pillow tensorflow
```

### Installation via requirements.txt (recommandÃ©)
```bash
pip install -r requirements.txt
```

## ğŸ¯ ExÃ©cution des Tests

### Option 1: Tests Individuels

Testez un outil spÃ©cifique :

```bash
# Test SAM2 Segmentation
python test_sam2_segmentator.py

# Test DINO v2 Features
python test_dino_features.py

# Test OpenPose Estimation
python test_pose_estimation.py

# Test Trajectory Analysis
python test_trajectory_analyzer.py

# Test Multimodal Fusion
python test_multimodal_fusion.py

# Test Temporal Transformer
python test_temporal_transformer.py

# Test Adversarial Detection
python test_adversarial_detector.py

# Test Domain Adaptation
python test_domain_adapter.py
```

### Option 2: Suite ComplÃ¨te

ExÃ©cutez tous les tests automatiquement :

```bash
python run_all_tests.py
```

## ğŸ“Š InterprÃ©tation des RÃ©sultats

### Symboles de Status
- âœ… **SuccÃ¨s** - FonctionnalitÃ© opÃ©rationnelle
- âš ï¸ **Attention** - Fonctionne avec limitations
- âŒ **Ã‰chec** - ProblÃ¨me dÃ©tectÃ©
- ğŸ¯ **Information** - DÃ©tail technique

### Types de Tests

Chaque outil est testÃ© sur :

1. **FonctionnalitÃ©s de base** - API principale
2. **Cas normaux** - DonnÃ©es typiques
3. **Cas limites** - DonnÃ©es extrÃªmes
4. **Gestion d'erreurs** - Resilience aux pannes
5. **Performance** - Temps d'exÃ©cution
6. **Fallbacks** - Alternatives en cas d'Ã©chec

## ğŸ”§ RÃ©solution des ProblÃ¨mes Courants

### ProblÃ¨me: Module non trouvÃ©
```
ModuleNotFoundError: No module named 'numpy'
```
**Solution:** Installez les dÃ©pendances manquantes
```bash
pip install numpy opencv-python scikit-learn scipy
```

### ProblÃ¨me: ModÃ¨les non disponibles
```
WARNING: Could not load DINO v2: ..., using fallback
```
**Solution:** Normal ! Les fallbacks sont prÃ©vus. Pour les modÃ¨les complets :
```bash
pip install torch transformers mediapipe tensorflow
```

### ProblÃ¨me: Erreur GPU/CUDA
```
Expected all tensors to be on the same device
```
**Solution:** Les tests utilisent automatiquement les fallbacks CPU

### ProblÃ¨me: Permissions ou chemins
```
FileNotFoundError: ...
```
**Solution:** ExÃ©cutez depuis le rÃ©pertoire racine du projet
```bash
cd intelligent-surveillance-system/
python test_sam2_segmentator.py
```

## ğŸ“ˆ Comprendre les MÃ©triques

### SAM2Segmentator
- **Temps de traitement** - Performance segmentation
- **Nombre de masques** - Objets dÃ©tectÃ©s
- **PropriÃ©tÃ©s masques** - Aire, pÃ©rimÃ¨tre, compacitÃ©, soliditÃ©

### DinoV2FeatureExtractor  
- **SimilaritÃ© cosinus** - Comparaison features (0-1)
- **Clustering inertie** - QualitÃ© regroupement (plus bas = mieux)
- **Temps extraction** - Performance modÃ¨le

### OpenPoseEstimator
- **Score comportement** - Suspicion dÃ©tectÃ©e (0-1)
- **Nombre indicateurs** - Comportements suspects
- **Keypoints dÃ©tectÃ©s** - Points corporels trouvÃ©s

### TrajectoryAnalyzer
- **Score anomalie** - Mouvement suspect (0-1)
- **Classification pattern** - Type de mouvement
- **Changements direction** - ErraticitÃ© du mouvement

### MultiModalFusion
- **PrÃ©diction finale** - Score de confiance (0-1)
- **Poids attention** - Importance de chaque modalitÃ©
- **Shape features** - Dimension vecteur fusionnÃ©

### TemporalTransformer
- **Consistance sÃ©quence** - StabilitÃ© temporelle (0-1)
- **Patterns temporels** - Types dÃ©tectÃ©s
- **Score anomalie** - Changements suspects (0-1)

### AdversarialDetector
- **Est adversarial** - Attaque dÃ©tectÃ©e (Oui/Non)
- **Type attaque** - FGSM, PGD, C&W, DeepFool
- **Score robustesse** - RÃ©sistance aux attaques (0-1)

### DomainAdapter
- **Score alignement** - Adaptation rÃ©ussie (0-1)
- **AmÃ©lioration confiance** - Gain performance
- **Domaine dÃ©tectÃ©** - Environment identifiÃ©

## ğŸ¯ Cas d'Usage des Tests

### Pour les DÃ©veloppeurs
- Validation aprÃ¨s modifications du code
- Tests de rÃ©gression automatiques
- Profiling de performance

### Pour les DevOps
- Tests d'intÃ©gration continue
- Validation dÃ©ploiement
- Monitoring santÃ© systÃ¨me

### Pour les Data Scientists
- Validation modÃ¨les ML
- Analyse performances algorithmes
- Tuning hyperparamÃ¨tres

## ğŸ“ Personnaliser les Tests

### Ajouter des DonnÃ©es de Test
```python
# Dans test_sam2_segmentator.py
def create_custom_test_image():
    # Votre image personnalisÃ©e
    return custom_image

# Modifier la fonction de test
test_image = create_custom_test_image()
```

### Modifier les Seuils
```python
# Ajuster les critÃ¨res de validation
confidence_threshold = 0.8  # Plus strict
performance_threshold = 2.0  # Secondes max
```

### Ajouter des MÃ©triques
```python
# Nouvelles mÃ©triques dans vos tests
custom_metrics = {
    "memory_usage": get_memory_usage(),
    "accuracy": calculate_accuracy(results),
    "precision": calculate_precision(results)
}
```

## ğŸ“Š GÃ©nÃ©ration de Rapports

### Rapport JSON Automatique
```bash
python run_all_tests.py
# GÃ©nÃ¨re: test_results.json
```

### Rapport Markdown
Le fichier `RAPPORT_TESTS_OUTILS_AVANCES.md` contient l'analyse dÃ©taillÃ©e complÃ¨te.

### Logs DÃ©taillÃ©s
Chaque test produit des logs dÃ©taillÃ©s avec :
- Timestamp d'exÃ©cution
- MÃ©triques de performance
- Messages d'erreur si applicable
- Statistiques de validation

## ğŸ‰ Prochaines Ã‰tapes

AprÃ¨s validation des tests individuels :

1. **Tests d'intÃ©gration** - Outils ensemble
2. **Tests de charge** - Performance sous stress  
3. **Tests end-to-end** - Pipeline complet
4. **DÃ©ploiement production** - Mise en service

---

## ğŸ“ Support

Pour questions ou problÃ¨mes :
- ğŸ“§ Email : support-surveillance@company.com
- ğŸ“± GitHub Issues : [CrÃ©er une issue](https://github.com/company/surveillance/issues)
- ğŸ“š Documentation : [Wiki complet](https://wiki.company.com/surveillance)

---

*Guide maintenu par l'Ã©quipe Surveillance IA*  
*DerniÃ¨re mise Ã  jour : AoÃ»t 2025*