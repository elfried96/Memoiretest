"""
ğŸ”’ Dashboard de Surveillance Intelligente
========================================

Application Streamlit moderne pour la surveillance avec IA.
Architecture modulaire et optimisÃ©e.
"""

import streamlit as st
import sys
from pathlib import Path
import asyncio
from typing import Optional, Dict, Any
import atexit

# Configuration du path pour accÃ©der aux modules du systÃ¨me
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "src"))

# Import des composants dashboard
from config.settings import get_dashboard_config, get_audio_config
from services.session_manager import get_session_manager
from components.camera_grid import get_camera_grid, cleanup_camera_resources
from components.vlm_chat import get_vlm_chat
from utils.audio_alerts import get_audio_system, play_alert

# Imports systÃ¨me de surveillance (si disponible)
try:
    from src.core.vlm.model import VisionLanguageModel
    from src.core.orchestrator.adaptive_orchestrator import AdaptiveOrchestrator
    VLM_AVAILABLE = True
except ImportError:
    VLM_AVAILABLE = False
    st.warning("âš ï¸ Modules VLM non trouvÃ©s - Mode dÃ©mo activÃ©")

class SurveillanceDashboard:
    """Dashboard principal de surveillance."""
    
    def __init__(self):
        self.config = get_dashboard_config()
        self.audio_config = get_audio_config()
        self.session = get_session_manager()
        
        # Composants principaux
        self.camera_grid = get_camera_grid()
        self.vlm_chat = get_vlm_chat()
        self.audio_system = get_audio_system()
        
        # SystÃ¨me de surveillance (si disponible)
        self.vlm_model: Optional[VisionLanguageModel] = None
        self.orchestrator: Optional[AdaptiveOrchestrator] = None
        
        self._setup_callbacks()
        self._init_vlm_system()
    
    def _setup_callbacks(self):
        """Configure les callbacks entre composants."""
        
        # Callback VLM pour le chat
        self.vlm_chat.set_vlm_callback(self._handle_vlm_query)
        
        # Callback dÃ©tection pour les camÃ©ras
        self.camera_grid.set_detection_callback(self._handle_detection)
    
    def _init_vlm_system(self):
        """Initialise le systÃ¨me VLM si disponible."""
        
        if not VLM_AVAILABLE:
            return
        
        try:
            # Chargement asynchrone du VLM
            if 'vlm_system' not in st.session_state:
                st.session_state.vlm_system = {
                    'loading': False,
                    'loaded': False,
                    'model': None,
                    'orchestrator': None
                }
        
        except Exception as e:
            st.error(f"Erreur initialisation VLM: {e}")
    
    def _handle_vlm_query(self, question: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Traite une requÃªte chat VLM."""
        
        try:
            if not VLM_AVAILABLE or not st.session_state.get('vlm_system', {}).get('loaded', False):
                # Mode dÃ©mo
                return self._demo_vlm_response(question, context)
            
            # Traitement rÃ©el avec VLM
            model = st.session_state.vlm_system.get('model')
            if model:
                # TODO: ImplÃ©menter appel VLM rÃ©el
                response = f"RÃ©ponse VLM Ã : {question}"
                
                return {
                    'content': response,
                    'metadata': {
                        'confidence': 0.85,
                        'tools_used': ['vlm', 'context_analysis']
                    }
                }
            
        except Exception as e:
            return {
                'content': f"âŒ Erreur VLM: {str(e)}",
                'metadata': {'error': True}
            }
        
        return self._demo_vlm_response(question, context)
    
    def _demo_vlm_response(self, question: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """GÃ©nÃ¨re une rÃ©ponse dÃ©mo intelligente."""
        
        question_lower = question.lower()
        
        # Analyse du contexte
        video_count = len(context.get('video_analyses', {}))
        camera_count = len(context.get('cameras_state', {}))
        alert_count = len(context.get('active_alerts', []))
        
        # RÃ©ponses contextuelles
        if any(word in question_lower for word in ['risque', 'danger', 'menace']):
            level = "FAIBLE" if alert_count == 0 else ("MOYEN" if alert_count < 3 else "Ã‰LEVÃ‰")
            response = f"ğŸ” **Ã‰valuation du risque: {level}**\n\n"
            response += f"- {camera_count} camÃ©ras actives\n"
            response += f"- {alert_count} alertes en cours\n"
            response += f"- {video_count} analyses rÃ©centes\n\n"
            
            if alert_count == 0:
                response += "âœ… Aucune activitÃ© suspecte dÃ©tectÃ©e actuellement."
            else:
                response += "âš ï¸ Surveillance renforcÃ©e recommandÃ©e."
        
        elif any(word in question_lower for word in ['personnes', 'individus', 'gens']):
            response = f"ğŸ‘¥ **Analyse des personnes dÃ©tectÃ©es:**\n\n"
            response += f"BasÃ© sur {video_count} analyses rÃ©centes:\n"
            response += "- 2-4 personnes gÃ©nÃ©ralement visibles\n"
            response += "- Comportement normal observÃ©\n"
            response += "- Aucun regroupement suspect\n\n"
            response += "ğŸ’¡ *Utilisez l'upload vidÃ©o pour une analyse prÃ©cise.*"
        
        elif any(word in question_lower for word in ['alerte', 'alertes']):
            response = f"ğŸš¨ **Ã‰tat des alertes:**\n\n"
            
            if alert_count == 0:
                response += "âœ… Aucune alerte active\n"
                response += "ğŸ” SystÃ¨me de surveillance opÃ©rationnel\n"
            else:
                alerts = context.get('active_alerts', [])
                for alert in alerts[-3:]:  # 3 derniÃ¨res
                    level = alert.get('level', 'INFO')
                    message = alert.get('message', 'N/A')
                    emoji = {'LOW': 'ğŸ”µ', 'MEDIUM': 'ğŸŸ¡', 'HIGH': 'ğŸŸ ', 'CRITICAL': 'ğŸ”´'}.get(level, 'âšª')
                    response += f"{emoji} {message}\n"
        
        elif any(word in question_lower for word in ['systÃ¨me', 'Ã©tat', 'status']):
            response = f"ğŸ–¥ï¸ **Ã‰tat du systÃ¨me:**\n\n"
            response += f"ğŸ“¹ CamÃ©ras: {camera_count} configurÃ©es\n"
            response += f"ğŸ¤– IA: {'ğŸŸ¢ OpÃ©rationnelle' if VLM_AVAILABLE else 'ğŸŸ¡ Mode dÃ©mo'}\n"
            response += f"ğŸ”Š Audio: {'ğŸŸ¢ ActivÃ©' if self.audio_config.enabled else 'ğŸ”´ DÃ©sactivÃ©'}\n"
            response += f"ğŸ“Š Analyses: {video_count} disponibles\n\n"
            response += "âœ… Tous les systÃ¨mes fonctionnels"
        
        else:
            response = f"ğŸ¤– **Analyse de votre question:**\n\n"
            response += f"Votre question: *\"{question}\"*\n\n"
            response += f"ğŸ“Š **Contexte disponible:**\n"
            response += f"- {camera_count} flux camÃ©ra actifs\n" 
            response += f"- {video_count} analyses vidÃ©o stockÃ©es\n"
            response += f"- {alert_count} alertes en cours\n\n"
            response += "ğŸ’¡ *Posez des questions spÃ©cifiques sur les risques, personnes, alertes ou l'Ã©tat du systÃ¨me.*"
        
        return {
            'content': response,
            'metadata': {
                'demo_mode': True,
                'confidence': 0.8,
                'context_items': video_count + camera_count + alert_count
            }
        }
    
    def _handle_detection(self, camera_id: str, frame) -> Dict[str, Any]:
        """Traite une dÃ©tection camÃ©ra."""
        
        # Simulation dÃ©tection pour dÃ©mo
        import random
        
        if random.random() < 0.1:  # 10% chance de dÃ©tection
            confidence = random.uniform(0.6, 0.95)
            obj_type = random.choice(['personne', 'vÃ©hicule', 'objet'])
            
            return {
                'objects': [{
                    'type': obj_type,
                    'confidence': confidence,
                    'bbox': [100, 100, 200, 200]  # Exemple
                }],
                'timestamp': st.session_state.get('current_time', 0)
            }
        
        return {}
    
    def run(self):
        """Lance le dashboard principal."""
        
        # Configuration de la page
        st.set_page_config(
            page_title=self.config.page_title,
            layout=self.config.layout,
            initial_sidebar_state=self.config.initial_sidebar_state,
            page_icon="ğŸ”’"
        )
        
        # CSS personnalisÃ©
        self._apply_custom_css()
        
        # Sidebar de contrÃ´le
        self._render_sidebar()
        
        # Contenu principal
        self._render_main_content()
        
        # Nettoyage Ã  la fermeture
        atexit.register(self._cleanup)
    
    def _apply_custom_css(self):
        """Applique le CSS personnalisÃ©."""
        
        st.markdown("""
        <style>
        .main-header {
            background: linear-gradient(90deg, #1f4e79, #2d5aa0);
            padding: 1rem;
            border-radius: 10px;
            color: white;
            margin-bottom: 2rem;
        }
        
        .metric-container {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 8px;
            border: 1px solid #dee2e6;
        }
        
        .alert-high {
            background-color: #ffebee;
            border-left: 4px solid #f44336;
            padding: 1rem;
            border-radius: 4px;
        }
        
        .alert-medium {
            background-color: #fff8e1;
            border-left: 4px solid #ff9800;
            padding: 1rem;
            border-radius: 4px;
        }
        
        .alert-low {
            background-color: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 1rem;
            border-radius: 4px;
        }
        
        .camera-cell {
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            padding: 0.5rem;
            margin: 0.25rem;
        }
        
        .camera-active {
            border-color: #4caf50;
        }
        
        .camera-inactive {
            border-color: #f44336;
        }
        </style>
        """, unsafe_allow_html=True)
    
    def _render_sidebar(self):
        """Affiche la sidebar de contrÃ´le."""
        
        with st.sidebar:
            # En-tÃªte
            st.markdown("""
            <div class="main-header">
                <h2>ğŸ”’ Surveillance</h2>
                <p>Dashboard IA AvancÃ©</p>
            </div>
            """, unsafe_allow_html=True)
            
            # ContrÃ´les globaux
            st.subheader("âš™ï¸ ContrÃ´les")
            
            # Seuil d'alerte
            alert_threshold = st.slider(
                "Seuil d'alerte global",
                0, 100, 
                self.session.get_user_data('alert_threshold', 70),
                help="SensibilitÃ© des alertes automatiques"
            )
            
            if alert_threshold != self.session.get_user_data('alert_threshold', 70):
                self.session.set_user_data('alert_threshold', alert_threshold)
            
            # Audio
            audio_enabled = st.checkbox(
                "ğŸ”Š Sons d'alerte",
                self.audio_config.enabled
            )
            
            if audio_enabled != self.audio_config.enabled:
                self.audio_config.enabled = audio_enabled
            
            # Volume audio
            if audio_enabled:
                volume = st.slider(
                    "Volume",
                    0.0, 1.0,
                    self.audio_config.volume,
                    step=0.1
                )
                self.audio_config.volume = volume
            
            st.divider()
            
            # MÃ©triques systÃ¨me
            self._render_system_metrics()
            
            st.divider()
            
            # Actions rapides
            st.subheader("ğŸš€ Actions")
            
            if st.button("ğŸ§ª Test alerte", use_container_width=True):
                play_alert("MEDIUM", "Test du systÃ¨me d'alerte", force=True)
            
            if st.button("ğŸ“Š Rapport systÃ¨me", use_container_width=True):
                self._generate_system_report()
            
            if st.button("ğŸ§¹ Nettoyer session", use_container_width=True):
                self._cleanup_session()
                st.rerun()
    
    def _render_system_metrics(self):
        """Affiche les mÃ©triques systÃ¨me dans la sidebar."""
        
        st.subheader("ğŸ“Š Ã‰tat SystÃ¨me")
        
        # CamÃ©ras
        camera_stats = self.camera_grid.get_camera_stats()
        active_cameras = sum(1 for stats in camera_stats.values() if stats['running'])
        
        st.metric("CamÃ©ras actives", f"{active_cameras}/{len(camera_stats)}")
        
        # Alertes
        alerts = self.session.get_active_alerts()
        critical_alerts = len([a for a in alerts if a.get('level') == 'CRITICAL'])
        
        if critical_alerts > 0:
            st.metric("âš ï¸ Alertes critiques", critical_alerts, delta=critical_alerts)
        else:
            st.metric("Alertes actives", len(alerts))
        
        # Analyses VLM
        analyses = len(self.session.get_all_video_analyses())
        st.metric("Analyses VLM", analyses)
        
        # Messages chat
        chat_messages = len(self.session.get_chat_history())
        st.metric("Messages chat", chat_messages)
    
    def _render_main_content(self):
        """Affiche le contenu principal."""
        
        # En-tÃªte principal
        st.markdown("""
        <div class="main-header">
            <h1>ğŸ”’ Dashboard de Surveillance Intelligente</h1>
            <p>Surveillance automatisÃ©e avec IA - DÃ©tection comportementale avancÃ©e</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Onglets principaux
        tab1, tab2, tab3, tab4 = st.tabs([
            "ğŸ“¹ Surveillance Live", 
            "ğŸ“± Upload & Analyse", 
            "ğŸ’¬ Chat IA",
            "ğŸ“Š Rapports"
        ])
        
        with tab1:
            self._render_live_surveillance()
        
        with tab2:
            self._render_video_analysis()
        
        with tab3:
            self._render_chat_interface()
        
        with tab4:
            self._render_reports()
    
    def _render_live_surveillance(self):
        """Onglet surveillance en temps rÃ©el."""
        
        st.subheader("ğŸ“¹ Surveillance Multi-CamÃ©ras")
        
        # Panneau de configuration des camÃ©ras
        with st.expander("â• Configuration des CamÃ©ras", expanded=False):
            from components.camera_grid import render_camera_configuration_panel
            render_camera_configuration_panel()
        
        # Grille des camÃ©ras
        st.subheader("ğŸ¥ Flux en Direct")
        
        # Options d'affichage
        col1, col2, col3 = st.columns([2, 2, 1])
        
        with col1:
            grid_size = st.selectbox(
                "Grille d'affichage",
                ["2x2 (4 camÃ©ras)", "3x3 (9 camÃ©ras)", "4x4 (16 camÃ©ras)"],
                index=0
            )
        
        with col2:
            auto_refresh = st.checkbox("ğŸ”„ Actualisation auto", True)
            
        with col3:
            if st.button("ğŸ”„ Actualiser"):
                st.rerun()
        
        # Conversion taille grille
        grid_map = {
            "2x2 (4 camÃ©ras)": (2, 2),
            "3x3 (9 camÃ©ras)": (3, 3),
            "4x4 (16 camÃ©ras)": (4, 4)
        }
        
        selected_grid = grid_map[grid_size]
        
        # Affichage grille
        self.camera_grid.render_grid(selected_grid)
        
        # Alertes rÃ©centes
        self._render_recent_alerts()
    
    def _render_video_analysis(self):
        """Onglet analyse de vidÃ©os uploadÃ©es."""
        
        st.subheader("ğŸ“± Analyse de VidÃ©o")
        
        # Upload de fichier
        uploaded_file = st.file_uploader(
            "SÃ©lectionnez une vidÃ©o Ã  analyser",
            type=['mp4', 'avi', 'mov', 'mkv', 'webm'],
            help="Formats supportÃ©s: MP4, AVI, MOV, MKV, WEBM"
        )
        
        if uploaded_file is not None:
            col1, col2 = st.columns([3, 2])
            
            with col1:
                st.subheader("ğŸ¬ VidÃ©o uploadÃ©e")
                
                # Affichage vidÃ©o
                st.video(uploaded_file)
                
                # Options d'analyse
                with st.expander("âš™ï¸ Options d'analyse", expanded=True):
                    analyze_behavior = st.checkbox("ğŸ” Analyse comportementale", True)
                    detect_objects = st.checkbox("ğŸ“¦ DÃ©tection d'objets", True)
                    track_movement = st.checkbox("ğŸ‘¥ Suivi de mouvements", True)
                    
                    sensitivity = st.slider("SensibilitÃ©", 0.0, 1.0, 0.7)
                
                # Bouton d'analyse
                if st.button("ğŸš€ Lancer l'analyse complÃ¨te", type="primary", use_container_width=True):
                    self._analyze_uploaded_video(uploaded_file, {
                        'behavior': analyze_behavior,
                        'objects': detect_objects,
                        'movement': track_movement,
                        'sensitivity': sensitivity
                    })
            
            with col2:
                st.subheader("ğŸ“Š RÃ©sultats")
                
                # RÃ©sultats d'analyse
                video_id = f"video_{hash(uploaded_file.name)}"
                analysis = self.session.get_video_analysis(video_id)
                
                if analysis:
                    # MÃ©triques principales
                    confidence = analysis.get('confidence', 0)
                    suspicion = analysis.get('suspicion_level', 'LOW')
                    
                    col_a, col_b = st.columns(2)
                    
                    with col_a:
                        st.metric("Confiance", f"{confidence:.1%}")
                    
                    with col_b:
                        suspicion_colors = {
                            'LOW': 'ğŸŸ¢',
                            'MEDIUM': 'ğŸŸ¡', 
                            'HIGH': 'ğŸŸ ',
                            'CRITICAL': 'ğŸ”´'
                        }
                        st.metric("Suspicion", f"{suspicion_colors.get(suspicion, 'âšª')} {suspicion}")
                    
                    # DÃ©tails de l'analyse
                    st.subheader("ğŸ“‹ DÃ©tails")
                    st.json(analysis)
                    
                    # Export
                    if st.button("ğŸ’¾ Exporter analyse", use_container_width=True):
                        self._export_analysis(analysis)
                
                else:
                    st.info("ğŸ¯ Lancez une analyse pour voir les rÃ©sultats")
    
    def _render_chat_interface(self):
        """Onglet interface de chat."""
        self.vlm_chat.render_chat_interface()
    
    def _render_reports(self):
        """Onglet rapports et statistiques."""
        
        st.subheader("ğŸ“Š Rapports et Statistiques")
        
        # Statistiques de session
        session_stats = self.session.get_session_stats()
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Messages Ã©changÃ©s", session_stats['chat_messages'])
        
        with col2:
            st.metric("Analyses vidÃ©o", session_stats['video_analyses'])
        
        with col3:
            st.metric("Alertes gÃ©nÃ©rÃ©es", session_stats['active_alerts'])
        
        with col4:
            st.metric("CamÃ©ras configurÃ©es", session_stats['cameras_configured'])
        
        st.divider()
        
        # Export des donnÃ©es
        st.subheader("ğŸ’¾ Export des donnÃ©es")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ“„ Exporter session (JSON)", use_container_width=True):
                data = self.session.export_session_data('json')
                st.download_button(
                    "â¬‡ï¸ TÃ©lÃ©charger JSON",
                    data,
                    file_name=f"session_{self.session.get_session_id()[:8]}.json",
                    mime="application/json"
                )
        
        with col2:
            if st.button("ğŸ’¬ Exporter chat (TXT)", use_container_width=True):
                data = self.vlm_chat.export_chat_history('txt')
                st.download_button(
                    "â¬‡ï¸ TÃ©lÃ©charger TXT",
                    data,
                    file_name=f"chat_{self.session.get_session_id()[:8]}.txt",
                    mime="text/plain"
                )
        
        with col3:
            if st.button("ğŸ“Š Rapport PDF", use_container_width=True):
                st.info("ğŸš§ GÃ©nÃ©ration PDF en dÃ©veloppement")
    
    def _render_recent_alerts(self):
        """Affiche les alertes rÃ©centes."""
        
        st.subheader("ğŸš¨ Alertes RÃ©centes")
        
        alerts = self.session.get_active_alerts()
        
        if not alerts:
            st.success("âœ… Aucune alerte active")
            return
        
        # Affichage des alertes
        for alert in alerts[-5:]:  # 5 derniÃ¨res
            level = alert.get('level', 'LOW')
            message = alert.get('message', 'N/A')
            timestamp = alert.get('timestamp', '')
            source = alert.get('source', 'system')
            
            # Couleur selon le niveau
            if level == 'CRITICAL':
                st.error(f"ğŸ”´ **CRITIQUE** ({source}): {message}")
            elif level == 'HIGH':
                st.error(f"ğŸŸ  **Ã‰LEVÃ‰** ({source}): {message}")
            elif level == 'MEDIUM':
                st.warning(f"ğŸŸ¡ **MOYEN** ({source}): {message}")
            else:
                st.info(f"ğŸ”µ **FAIBLE** ({source}): {message}")
    
    def _analyze_uploaded_video(self, uploaded_file, options: Dict[str, Any]):
        """Analyse une vidÃ©o uploadÃ©e."""
        
        with st.spinner("ğŸ” Analyse en cours..."):
            try:
                # Simulation d'analyse (remplacer par vraie analyse)
                import time
                import random
                
                time.sleep(2)  # Simulation du temps d'analyse
                
                # GÃ©nÃ©ration rÃ©sultats simulÃ©s
                analysis_result = {
                    'video_name': uploaded_file.name,
                    'file_size': uploaded_file.size,
                    'analysis_options': options,
                    'confidence': random.uniform(0.7, 0.95),
                    'suspicion_level': random.choice(['LOW', 'MEDIUM', 'HIGH']),
                    'detected_objects': [
                        {'type': 'person', 'confidence': 0.92, 'count': random.randint(1, 5)},
                        {'type': 'vehicle', 'confidence': 0.78, 'count': random.randint(0, 2)}
                    ],
                    'behaviors': [
                        {'type': 'normal_walking', 'confidence': 0.89},
                        {'type': 'loitering', 'confidence': random.uniform(0.3, 0.7)}
                    ],
                    'timeline': [
                        {'time': '00:05', 'event': 'Personne entre dans le champ'},
                        {'time': '00:12', 'event': 'Mouvement vers la droite'},
                        {'time': '00:18', 'event': 'ArrÃªt prolongÃ© dÃ©tectÃ©'}
                    ],
                    'analysis_time': 2.3,
                    'timestamp': st.session_state.get('current_time', time.time())
                }
                
                # Stockage de l'analyse
                video_id = f"video_{hash(uploaded_file.name)}"
                self.session.store_video_analysis(video_id, analysis_result)
                
                # Ajout message systÃ¨me au chat
                suspicion = analysis_result['suspicion_level']
                confidence = analysis_result['confidence']
                
                self.vlm_chat.add_system_message(
                    f"Analyse terminÃ©e: {uploaded_file.name} - Suspicion {suspicion} ({confidence:.1%} confiance)",
                    'success' if suspicion == 'LOW' else 'warning'
                )
                
                # Alerte audio si suspicion Ã©levÃ©e
                if suspicion in ['HIGH', 'CRITICAL']:
                    play_alert(suspicion, f"Comportement suspect dÃ©tectÃ© dans {uploaded_file.name}")
                
                st.success("âœ… Analyse terminÃ©e avec succÃ¨s!")
                st.rerun()
                
            except Exception as e:
                st.error(f"âŒ Erreur lors de l'analyse: {str(e)}")
    
    def _export_analysis(self, analysis: Dict[str, Any]):
        """Exporte une analyse."""
        
        import json
        data = json.dumps(analysis, indent=2, ensure_ascii=False)
        
        st.download_button(
            "ğŸ’¾ TÃ©lÃ©charger analyse",
            data,
            file_name=f"analyse_{analysis.get('video_name', 'video')}.json",
            mime="application/json"
        )
    
    def _generate_system_report(self):
        """GÃ©nÃ¨re un rapport systÃ¨me."""
        
        st.info("ğŸ“Š GÃ©nÃ©ration du rapport systÃ¨me...")
        
        # TODO: ImplÃ©menter gÃ©nÃ©ration rapport complet
        report = {
            'timestamp': st.session_state.get('current_time', 0),
            'system_status': 'operational',
            'cameras': self.camera_grid.get_camera_stats(),
            'session': self.session.get_session_stats(),
            'audio': self.audio_system.get_status()
        }
        
        st.json(report)
    
    def _cleanup_session(self):
        """Nettoie la session."""
        
        self.session.clear_chat_history()
        self.session.clear_alerts()
        
        # RÃ©initialisation des caches
        self.session.cleanup_expired_data()
        
        st.success("ğŸ§¹ Session nettoyÃ©e")
    
    def _cleanup(self):
        """Nettoyage Ã  la fermeture."""
        cleanup_camera_resources()

def main():
    """Point d'entrÃ©e principal."""
    
    try:
        dashboard = SurveillanceDashboard()
        dashboard.run()
        
    except Exception as e:
        st.error(f"âŒ Erreur critique: {str(e)}")
        st.error("Veuillez redÃ©marrer l'application")

if __name__ == "__main__":
    main()