#!/usr/bin/env python3
"""
Test complet du syst√®me Kimi-VL int√©gr√© avec switching multi-VLM.
Script de test pour valider l'int√©gration Kimi-VL-A3B-Thinking.
"""

import asyncio
import base64
import time
from pathlib import Path
from PIL import Image
from io import BytesIO
import json

from src.core.vlm.dynamic_model import DynamicVisionLanguageModel
from src.core.vlm.model_registry import VLMModelRegistry
from src.core.types import AnalysisRequest
from src.core.orchestrator.vlm_orchestrator import (
    ModernVLMOrchestrator, 
    OrchestrationConfig, 
    OrchestrationMode
)


def create_test_image() -> str:
    """Cr√©e une image de test simple encod√©e en base64."""
    # Cr√©ation d'une image de test simple
    image = Image.new('RGB', (640, 480), color='lightblue')
    
    # Ajout de formes simples pour test
    from PIL import ImageDraw, ImageFont
    draw = ImageDraw.Draw(image)
    
    # Rectangle (simule une personne)
    draw.rectangle([200, 150, 300, 400], outline='red', width=3)
    draw.text((210, 130), "Person", fill='red')
    
    # Cercle (simule un objet)
    draw.ellipse([400, 200, 500, 300], outline='blue', width=2)
    draw.text((420, 180), "Object", fill='blue')
    
    # Ligne (simule un mouvement)
    draw.line([150, 100, 450, 350], fill='green', width=2)
    draw.text((300, 220), "Movement", fill='green')
    
    # Conversion en base64
    buffer = BytesIO()
    image.save(buffer, format='PNG')
    image_data = base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    return image_data


async def test_model_registry():
    """Test du registre des mod√®les."""
    print("üîç Test du Model Registry...")
    
    registry = VLMModelRegistry()
    
    # Liste des mod√®les disponibles
    models = registry.list_available_models()
    print(f"üì¶ Mod√®les enregistr√©s: {len(models)}")
    
    for model_id, config in models.items():
        print(f"  ‚Ä¢ {model_id} ({config.model_type.value}): {config.description}")
    
    # Test de validation des mod√®les
    print("\nüîé Validation des mod√®les:")
    for model_id in ["kimi-vl-a3b-thinking", "kimi-vl-a3b-instruct", "llava-v1.6-mistral-7b"]:
        is_available, message = registry.validate_model_availability(model_id)
        status = "‚úÖ" if is_available else "‚ùå"
        print(f"  {status} {model_id}: {message}")
    
    # Recommandations
    print("\nüí° Recommandations:")
    recommendations = registry.get_model_recommendations()
    for use_case, model in recommendations.items():
        print(f"  ‚Ä¢ {use_case}: {model}")
    
    return registry


async def test_dynamic_vlm():
    """Test du VLM dynamique avec Kimi-VL."""
    print("\nüß† Test du VLM Dynamique...")
    
    # Initialisation avec Kimi-VL-A3B-Thinking comme d√©faut
    vlm = DynamicVisionLanguageModel(
        default_model="kimi-vl-a3b-thinking",
        enable_fallback=True
    )
    
    # Tentative de chargement
    print("‚è≥ Chargement Kimi-VL-A3B-Thinking...")
    success = await vlm.load_model()
    
    if success:
        print("‚úÖ Kimi-VL charg√© avec succ√®s!")
        
        # Test d'analyse
        test_image = create_test_image()
        request = AnalysisRequest(
            frame_data=test_image,
            context={
                "location": "Test Store", 
                "camera": "CAM_TEST",
                "test_mode": True
            },
            tools_available=["dino_features", "pose_estimator", "multimodal_fusion"]
        )
        
        print("üîç Test d'analyse avec Kimi-VL...")
        start_time = time.time()
        result = await vlm.analyze_with_tools(request, use_advanced_tools=True)
        processing_time = time.time() - start_time
        
        print(f"üìä R√©sultat ({processing_time:.2f}s):")
        print(f"  ‚Ä¢ Suspicion: {result.suspicion_level.value}")
        print(f"  ‚Ä¢ Action: {result.action_type.value}")
        print(f"  ‚Ä¢ Confiance: {result.confidence:.2f}")
        print(f"  ‚Ä¢ Description: {result.description}")
        print(f"  ‚Ä¢ Outils utilis√©s: {result.tools_used}")
        
    else:
        print("‚ùå √âchec chargement Kimi-VL, test des fallbacks...")
        
        # Test fallback vers LLaVA
        print("‚è≥ Test fallback LLaVA...")
        success_llava = await vlm.switch_model("llava-v1.6-mistral-7b")
        
        if success_llava:
            print("‚úÖ Fallback LLaVA r√©ussi!")
        else:
            print("‚ùå Tous les mod√®les indisponibles")
    
    # Statut syst√®me
    print("\nüìà Statut du syst√®me:")
    status = vlm.get_system_status()
    print(f"  ‚Ä¢ Mod√®le actuel: {status['current_model']['model_id']}")
    print(f"  ‚Ä¢ Type: {status['current_model']['model_type']}")
    print(f"  ‚Ä¢ Device: {status['current_model']['device']}")
    print(f"  ‚Ä¢ CUDA disponible: {status['system']['cuda_available']}")
    
    return vlm


async def test_model_switching():
    """Test du switching entre mod√®les."""
    print("\nüîÑ Test du Model Switching...")
    
    vlm = DynamicVisionLanguageModel(enable_fallback=True)
    
    # Test de switching entre mod√®les
    models_to_test = [
        "kimi-vl-a3b-thinking",   # Mod√®le principal
        "kimi-vl-a3b-instruct",   # Variant instruct
        "llava-v1.6-mistral-7b",   # Fallback stable
        "qwen2-vl-7b-instruct"     # Alternative
    ]
    
    test_image = create_test_image()
    request = AnalysisRequest(
        frame_data=test_image,
        context={"location": "Switching Test"},
        tools_available=["dino_features"]
    )
    
    for model_id in models_to_test:
        print(f"\nüì± Test switching vers {model_id}...")
        
        success = await vlm.switch_model(model_id)
        
        if success:
            print(f"‚úÖ Switch r√©ussi vers {model_id}")
            
            # Test rapide d'analyse
            try:
                start_time = time.time()
                result = await vlm.analyze_with_tools(request, use_advanced_tools=False)
                processing_time = time.time() - start_time
                
                print(f"  üìä Analyse ({processing_time:.2f}s): {result.suspicion_level.value}")
                
            except Exception as e:
                print(f"  ‚ùå Erreur analyse: {e}")
        else:
            print(f"‚ùå Switch √©chou√© vers {model_id}")
    
    return vlm


async def test_orchestrator():
    """Test de l'orchestrateur avec Kimi-VL."""
    print("\nüéÆ Test de l'Orchestrateur...")
    
    # Configuration pour test avec Kimi-VL
    config = OrchestrationConfig(
        mode=OrchestrationMode.BALANCED,
        enable_advanced_tools=True,
        max_concurrent_tools=4,
        confidence_threshold=0.6
    )
    
    # Initialisation avec Kimi-VL par d√©faut
    orchestrator = ModernVLMOrchestrator(
        vlm_model_name="kimi-vl-a3b-thinking",
        config=config
    )
    
    # Test d'analyse compl√®te
    test_image = create_test_image()
    
    print("üîç Analyse orchestr√©e...")
    try:
        start_time = time.time()
        result = await orchestrator.analyze_surveillance_frame(
            frame_data=test_image,
            detections=[],  # Pas de d√©tections YOLO pour ce test
            context={
                "location": "Orchestrator Test Zone",
                "camera": "CAM_ORCH_01",
                "security_level": "high"
            }
        )
        processing_time = time.time() - start_time
        
        print(f"üìä R√©sultat orchestr√© ({processing_time:.2f}s):")
        print(f"  ‚Ä¢ Suspicion: {result.suspicion_level.value}")
        print(f"  ‚Ä¢ Action: {result.action_type.value}")
        print(f"  ‚Ä¢ Confiance: {result.confidence:.2f}")
        print(f"  ‚Ä¢ Description: {result.description}")
        print(f"  ‚Ä¢ Outils: {result.tools_used}")
        print(f"  ‚Ä¢ Recommandations: {result.recommendations}")
        
    except Exception as e:
        print(f"‚ùå Erreur orchestration: {e}")
    
    # Statut complet
    print("\nüìà Statut orchestrateur:")
    status = orchestrator.get_system_status()
    
    print(f"  ‚Ä¢ Mode: {status['orchestrator']['mode']}")
    print(f"  ‚Ä¢ Outils avanc√©s: {status['orchestrator']['enable_advanced_tools']}")
    print(f"  ‚Ä¢ Analyses totales: {status['performance']['total_analyses']}")
    print(f"  ‚Ä¢ Taux succ√®s: {status['performance']['success_rate_percent']:.1f}%")
    
    # Health check
    health = await orchestrator.health_check()
    print(f"  ‚Ä¢ Health check: {health}")
    
    return orchestrator


async def test_batch_processing():
    """Test du traitement par batch."""
    print("\nüì¶ Test Batch Processing...")
    
    vlm = DynamicVisionLanguageModel(
        default_model="kimi-vl-a3b-thinking",
        enable_fallback=True
    )
    
    success = await vlm.load_model()
    if not success:
        print("‚ùå Mod√®le non charg√©, skip batch test")
        return
    
    # Cr√©ation de plusieurs images de test
    test_images = []
    for i in range(3):
        image_data = create_test_image()
        test_images.append(AnalysisRequest(
            frame_data=image_data,
            context={
                "batch_id": f"batch_frame_{i}",
                "location": f"Zone_{i+1}"
            },
            tools_available=["dino_features", "pose_estimator"]
        ))
    
    print(f"üîÑ Traitement batch de {len(test_images)} images...")
    start_time = time.time()
    
    # Traitement s√©quentiel pour comparaison
    results = []
    for request in test_images:
        result = await vlm.analyze_with_tools(request, use_advanced_tools=True)
        results.append(result)
    
    processing_time = time.time() - start_time
    
    print(f"üìä Batch termin√© ({processing_time:.2f}s):")
    for i, result in enumerate(results):
        print(f"  Frame {i+1}: {result.suspicion_level.value} (conf: {result.confidence:.2f})")
    
    average_time = processing_time / len(results)
    print(f"  ‚Ä¢ Temps moyen/frame: {average_time:.2f}s")


async def main():
    """Fonction principale de test."""
    print("üöÄ Test Complet du Syst√®me Kimi-VL Multi-VLM")
    print("=" * 60)
    
    try:
        # Tests individuels
        await test_model_registry()
        await test_dynamic_vlm()
        await test_model_switching()
        await test_orchestrator()
        await test_batch_processing()
        
        print("\n" + "=" * 60)
        print("‚úÖ Tests termin√©s avec succ√®s!")
        
        print("\nüí° Recommandations d'utilisation:")
        print("1. üéØ Utilisez kimi-vl-a3b-thinking pour surveillance principale")
        print("2. üîÑ LLaVA comme fallback stable") 
        print("3. üß† Qwen2-VL pour analyses complexes")
        print("4. ‚öôÔ∏è Mode BALANCED pour production")
        print("5. üõ°Ô∏è Activez les fallbacks automatiques")
        
    except Exception as e:
        print(f"\n‚ùå Erreur durant les tests: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())