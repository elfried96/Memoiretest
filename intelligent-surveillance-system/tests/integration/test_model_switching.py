#!/usr/bin/env python3
"""Tests de switching entre KIM, LLaVA et Qwen2-VL."""

import sys
import os
import asyncio
import time
import base64
from io import BytesIO
from PIL import Image
import numpy as np

sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from src.core.vlm.dynamic_model import DynamicVisionLanguageModel
from src.core.vlm.model_registry import VLMModelRegistry, VLMModelType
from src.core.types import AnalysisRequest


def create_test_image() -> str:
    """Cr√©er une image de test pour les analyses."""
    # Image simul√©e de surveillance
    image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    # Ajout d'√©l√©ments visuels
    # Personne
    image[100:300, 200:350] = [120, 100, 80]
    # Objet suspect
    image[250:280, 320:370] = [200, 50, 50]
    # Background store-like
    image[400:480, :] = [150, 150, 150]  # Floor
    
    # Conversion vers base64
    pil_image = Image.fromarray(image)
    buffer = BytesIO()
    pil_image.save(buffer, format='PNG')
    
    return base64.b64encode(buffer.getvalue()).decode('utf-8')


async def test_model_registry():
    """Test du registre des mod√®les."""
    
    print("=== TEST REGISTRE DES MOD√àLES ===\n")
    
    registry = VLMModelRegistry()
    
    # Liste des mod√®les disponibles
    available_models = registry.list_available_models()
    print(f"üìã Mod√®les enregistr√©s: {len(available_models)}")
    
    for model_id, config in available_models.items():
        print(f"  ‚Ä¢ {model_id}")
        print(f"    Type: {config.model_type.value.upper()}")
        print(f"    Nom: {config.model_name}")
        print(f"    Tool-calling: {'‚úÖ' if config.supports_tool_calling else '‚ùå'}")
        print(f"    Memory efficient: {'‚úÖ' if config.memory_efficient else '‚ùå'}")
        print(f"    Description: {config.description}")
        print()
    
    # Test par type
    print("üìä Mod√®les par type:")
    for model_type in VLMModelType:
        models = registry.get_models_by_type(model_type)
        print(f"  {model_type.value.upper()}: {len(models)} mod√®les")
        for model_id in models.keys():
            print(f"    - {model_id}")
    print()
    
    # Recommandations
    print("üéØ Recommandations:")
    recommendations = {
        "Surveillance": registry.get_recommended_model("surveillance"),
        "Haute performance": registry.get_recommended_model("high_performance"),
        "√âconomie m√©moire": registry.get_recommended_model("memory_efficient"),
        "Raisonnement": registry.get_recommended_model("reasoning"),
        "Flagship": registry.get_recommended_model("flagship")
    }
    
    for use_case, model_id in recommendations.items():
        print(f"  {use_case}: {model_id}")
    
    # Test de validation
    print(f"\nüîç Validation des mod√®les:")
    for model_id in ["kim-7b-instruct", "llava-v1.6-mistral-7b", "qwen2-vl-7b-instruct"]:
        is_available, message = registry.validate_model_availability(model_id)
        status = "‚úÖ" if is_available else "‚ùå"
        print(f"  {status} {model_id}: {message}")
    
    return True


async def test_dynamic_model_loading():
    """Test du chargement dynamique des mod√®les."""
    
    print(f"\n=== TEST CHARGEMENT DYNAMIQUE ===\n")
    
    # Initialisation du VLM dynamique
    vlm = DynamicVisionLanguageModel(
        default_model="llava-v1.6-mistral-7b",  # LLaVA comme fallback stable
        device="auto",
        enable_fallback=True
    )
    
    print("üîÑ Test de chargement des mod√®les disponibles...")
    
    # Mod√®les √† tester (dans l'ordre de priorit√©)
    models_to_test = [
        ("kim-7b-instruct", "KIM 7B (Principal)"),
        ("llava-v1.6-mistral-7b", "LLaVA-NeXT 7B (Fallback)"),
        ("qwen2-vl-7b-instruct", "Qwen2-VL 7B (Alternative)")
    ]
    
    successful_loads = []
    failed_loads = []
    
    for model_id, description in models_to_test:
        print(f"\n--- Test: {description} ---")
        
        try:
            start_time = time.time()
            success = await vlm.load_model(model_id)
            load_time = time.time() - start_time
            
            if success:
                print(f"‚úÖ {model_id} charg√© en {load_time:.2f}s")
                
                # Test basique de statut
                status = vlm.get_system_status()
                current_model = status["current_model"]
                print(f"  Mod√®le actuel: {current_model['model_id']}")
                print(f"  Type: {current_model['model_type']}")
                print(f"  Charg√©: {current_model['is_loaded']}")
                print(f"  Device: {current_model['device']}")
                print(f"  Tool-calling: {current_model['supports_tool_calling']}")
                
                successful_loads.append((model_id, load_time))
                
                # Test de d√©chargement propre
                vlm._unload_current_model()
                print(f"  ‚úÖ D√©chargement propre r√©ussi")
                
            else:
                print(f"‚ùå {model_id} n'a pas pu √™tre charg√©")
                failed_loads.append(model_id)
                
        except Exception as e:
            print(f"‚ùå Erreur {model_id}: {e}")
            failed_loads.append(model_id)
    
    # R√©sum√©
    print(f"\nüìä R√©sum√© chargement:")
    print(f"  ‚úÖ R√©ussis: {len(successful_loads)}")
    for model_id, load_time in successful_loads:
        print(f"    ‚Ä¢ {model_id} ({load_time:.2f}s)")
    
    print(f"  ‚ùå √âchou√©s: {len(failed_loads)}")
    for model_id in failed_loads:
        print(f"    ‚Ä¢ {model_id}")
    
    await vlm.shutdown()
    
    return len(successful_loads) > 0


async def test_model_switching():
    """Test du switching entre mod√®les."""
    
    print(f"\n=== TEST SWITCHING ENTRE MOD√àLES ===\n")
    
    # VLM avec mod√®le de d√©part
    vlm = DynamicVisionLanguageModel(
        default_model="llava-v1.6-mistral-7b",
        enable_fallback=True
    )
    
    # Chargement initial
    print("üîÑ Chargement mod√®le initial...")
    success = await vlm.load_model()
    
    if not success:
        print("‚ùå Impossible de charger le mod√®le initial")
        return False
    
    initial_model = vlm.current_model_id
    print(f"‚úÖ Mod√®le initial: {initial_model}")
    
    # S√©quence de switching
    switch_sequence = [
        "qwen2-vl-7b-instruct",
        "kim-7b-instruct", 
        "llava-v1.6-mistral-7b"
    ]
    
    successful_switches = 0
    
    for target_model in switch_sequence:
        print(f"\nüîÑ Switch vers: {target_model}")
        
        try:
            start_time = time.time()
            success = await vlm.switch_model(target_model)
            switch_time = time.time() - start_time
            
            if success:
                print(f"‚úÖ Switch r√©ussi en {switch_time:.2f}s")
                print(f"  Mod√®le actuel: {vlm.current_model_id}")
                print(f"  Type: {vlm.current_config.model_type.value}")
                successful_switches += 1
            else:
                print(f"‚ùå Switch √©chou√© vers {target_model}")
                print(f"  Mod√®le actuel: {vlm.current_model_id}")
                
        except Exception as e:
            print(f"‚ùå Erreur switch vers {target_model}: {e}")
    
    print(f"\nüìä R√©sum√© switching:")
    print(f"  ‚úÖ Switches r√©ussis: {successful_switches}/{len(switch_sequence)}")
    print(f"  Mod√®le final: {vlm.current_model_id}")
    
    await vlm.shutdown()
    
    return successful_switches > 0


async def test_analysis_with_different_models():
    """Test d'analyse avec diff√©rents mod√®les."""
    
    print(f"\n=== TEST ANALYSES MULTI-MOD√àLES ===\n")
    
    # Image de test
    test_image = create_test_image()
    
    # Requ√™te d'analyse
    analysis_request = AnalysisRequest(
        frame_data=test_image,
        context={
            "location": "Test Store - Multi-Model",
            "camera_id": "TEST_CAM",
            "test_mode": True
        },
        tools_available=["dino_features", "pose_estimator", "multimodal_fusion"]
    )
    
    # Mod√®les √† tester
    models_to_test = [
        "llava-v1.6-mistral-7b",
        "qwen2-vl-7b-instruct", 
        "kim-7b-instruct"
    ]
    
    vlm = DynamicVisionLanguageModel(enable_fallback=True)
    results = {}
    
    for model_id in models_to_test:
        print(f"\n--- Analyse avec {model_id} ---")
        
        try:
            # Switch vers le mod√®le
            success = await vlm.switch_model(model_id)
            
            if not success:
                print(f"‚ùå Impossible de charger {model_id}")
                results[model_id] = {"success": False, "error": "Chargement √©chou√©"}
                continue
            
            # Analyse
            start_time = time.time()
            result = await vlm.analyze_with_tools(analysis_request, use_advanced_tools=True)
            analysis_time = time.time() - start_time
            
            print(f"‚úÖ Analyse termin√©e en {analysis_time:.2f}s")
            print(f"  Suspicion: {result.suspicion_level.value}")
            print(f"  Action: {result.action_type.value}")  
            print(f"  Confiance: {result.confidence:.2f}")
            print(f"  Outils utilis√©s: {len(result.tools_used)}")
            print(f"  Description: {result.description[:100]}...")
            
            results[model_id] = {
                "success": True,
                "suspicion_level": result.suspicion_level.value,
                "confidence": result.confidence,
                "tools_count": len(result.tools_used),
                "analysis_time": analysis_time
            }
            
        except Exception as e:
            print(f"‚ùå Erreur analyse {model_id}: {e}")
            results[model_id] = {"success": False, "error": str(e)}
    
    # Comparaison des r√©sultats
    print(f"\nüìä COMPARAISON DES MOD√àLES")
    print(f"{'Mod√®le':<25} {'Succ√®s':<8} {'Suspicion':<10} {'Confiance':<10} {'Temps':<8}")
    print("-" * 70)
    
    for model_id, result in results.items():
        model_name = model_id.split('-')[0].upper()
        if result["success"]:
            print(f"{model_name:<25} {'‚úÖ':<8} {result['suspicion_level']:<10} {result['confidence']:<10.2f} {result['analysis_time']:<8.2f}s")
        else:
            print(f"{model_name:<25} {'‚ùå':<8} {'N/A':<10} {'N/A':<10} {'N/A':<8}")
    
    await vlm.shutdown()
    
    successful_analyses = sum(1 for r in results.values() if r["success"])
    return successful_analyses > 0


async def test_system_status_and_recommendations():
    """Test du statut syst√®me et des recommandations."""
    
    print(f"\n=== TEST STATUT & RECOMMANDATIONS ===\n")
    
    vlm = DynamicVisionLanguageModel()
    
    try:
        # Chargement d'un mod√®le
        await vlm.load_model("llava-v1.6-mistral-7b")
        
        # Statut complet
        print("üîç Statut syst√®me complet:")
        status = vlm.get_system_status()
        
        print(f"\nüì± Mod√®le actuel:")
        current = status["current_model"]
        print(f"  ID: {current['model_id']}")
        print(f"  Type: {current['model_type']}")
        print(f"  Charg√©: {current['is_loaded']}")
        print(f"  Device: {current['device']}")
        print(f"  Tool-calling: {current['supports_tool_calling']}")
        
        print(f"\nüéØ Mod√®les disponibles:")
        for model_id, info in status["available_models"].items():
            status_icon = "‚úÖ" if info["available"] else "‚ùå"
            print(f"  {status_icon} {model_id} ({info['type']}) - {info['message']}")
        
        print(f"\nüõ†Ô∏è  Outils:")
        print(f"  Total outils: {len(status['available_tools'])}")
        tools_working = sum(1 for working in status["tools_status"].values() if working)
        print(f"  Outils fonctionnels: {tools_working}/{len(status['tools_status'])}")
        
        print(f"\n‚öôÔ∏è  Syst√®me:")
        sys_info = status["system"]
        print(f"  Device: {sys_info['device']}")
        print(f"  CUDA disponible: {sys_info['cuda_available']}")
        print(f"  Fallback activ√©: {sys_info['enable_fallback']}")
        
        # Recommandations
        print(f"\nüéØ Recommandations d'usage:")
        recommendations = vlm.get_model_recommendations()
        
        for use_case, model_id in recommendations.items():
            print(f"  {use_case}: {model_id}")
        
        await vlm.shutdown()
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur test statut: {e}")
        await vlm.shutdown()
        return False


async def main():
    """Test principal du syst√®me multi-mod√®les."""
    
    print("üöÄ TESTS SYST√àME MULTI-MOD√àLES VLM")
    print("Support KIM, LLaVA et Qwen2-VL\n")
    
    tests = [
        ("Registre des mod√®les", test_model_registry),
        ("Chargement dynamique", test_dynamic_model_loading), 
        ("Switching entre mod√®les", test_model_switching),
        ("Analyses multi-mod√®les", test_analysis_with_different_models),
        ("Statut et recommandations", test_system_status_and_recommendations)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"üß™ {test_name}...")
        
        try:
            success = await test_func()
            results.append((test_name, success))
            
            if success:
                print(f"‚úÖ {test_name}: R√âUSSI\n")
            else:
                print(f"‚ùå {test_name}: √âCHOU√â\n")
                
        except Exception as e:
            print(f"‚ùå {test_name}: ERREUR - {e}\n")
            results.append((test_name, False))
    
    # R√©sum√© final
    print("=" * 60)
    successful_tests = sum(1 for _, success in results if success)
    total_tests = len(results)
    success_rate = (successful_tests / total_tests) * 100
    
    if successful_tests == total_tests:
        print("üéâ TOUS LES TESTS MULTI-MOD√àLES R√âUSSIS!")
        print(f"‚úÖ {successful_tests}/{total_tests} tests pass√©s ({success_rate:.0f}%)")
        
        print(f"\nüéØ FONCTIONNALIT√âS VALID√âES:")
        print("‚Ä¢ ‚úÖ Registre de mod√®les (KIM, LLaVA, Qwen2-VL)")
        print("‚Ä¢ ‚úÖ Chargement dynamique avec fallbacks")
        print("‚Ä¢ ‚úÖ Switching √† chaud entre mod√®les")
        print("‚Ä¢ ‚úÖ Analyses comparatives multi-mod√®les")
        print("‚Ä¢ ‚úÖ Monitoring et recommandations")
        print("‚Ä¢ ‚úÖ Int√©gration avec les 8 outils avanc√©s")
        
        print(f"\nüöÄ UTILISATION:")
        print("1. vlm = DynamicVisionLanguageModel(default_model='kim-7b-instruct')")
        print("2. await vlm.switch_model('qwen2-vl-7b-instruct')")
        print("3. result = await vlm.analyze_with_tools(request)")
        
    else:
        print("‚ö†Ô∏è  CERTAINS TESTS ONT √âCHOU√â")
        print(f"üìä {successful_tests}/{total_tests} tests pass√©s ({success_rate:.0f}%)")
        
        print(f"\n‚úÖ Tests r√©ussis:")
        for test_name, success in results:
            if success:
                print(f"  ‚Ä¢ {test_name}")
        
        print(f"\n‚ùå Tests √©chou√©s:")
        for test_name, success in results:
            if not success:
                print(f"  ‚Ä¢ {test_name}")
    
    print(f"\nüí° NOTE: Certains mod√®les (KIM) n√©cessitent des versions")
    print("    sp√©cialis√©es de transformers ou des installations custom.")
    print("    Les fallbacks LLaVA/Qwen sont utilis√©s en cas d'indisponibilit√©.")
    
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())