"""
ğŸš€ Gestionnaire de ModÃ¨les Automatique
=====================================

GÃ¨re le tÃ©lÃ©chargement et l'initialisation automatique de tous les modÃ¨les
sauf les VLM qui sont chargÃ©s seulement Ã  la demande.
"""

import os
import sys
import requests
import torch
from pathlib import Path
from typing import Dict, List, Optional, Callable
from loguru import logger
import hashlib
import json
from tqdm import tqdm

class ModelManager:
    """Gestionnaire automatique des modÃ¨les IA"""
    
    def __init__(self, models_dir: str = "models"):
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(exist_ok=True, parents=True)
        self.models_config = self._load_models_config()
        self.downloaded_models = {}
        
    def _load_models_config(self) -> Dict:
        """Configuration des modÃ¨les Ã  tÃ©lÃ©charger automatiquement"""
        return {
            "yolo": {
                "name": "YOLOv11 Nano",
                "filename": "yolo11n.pt",
                "url": "https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt",
                "size_mb": 5.4,
                "sha256": None,  # Optionnel pour vÃ©rification
                "auto_download": True,
                "required_for": ["object_detection", "surveillance"]
            },
            "yolo_medium": {
                "name": "YOLOv11 Medium",
                "filename": "yolo11m.pt", 
                "url": "https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt",
                "size_mb": 49.7,
                "auto_download": False,  # Plus lourd, pas automatique
                "required_for": ["high_accuracy_detection"]
            },
            "sam2_base": {
                "name": "SAM2 Base",
                "filename": "sam2_base.pt",
                "url": None,  # Via transformers hub
                "huggingface_id": "facebook/sam2-hiera-base-plus",
                "auto_download": True,
                "required_for": ["segmentation", "advanced_tools"]
            },
            "dino_v2": {
                "name": "DINO v2 Features", 
                "filename": "dinov2_vitb14.pth",
                "huggingface_id": "facebook/dinov2-base",
                "auto_download": True,
                "required_for": ["feature_extraction", "advanced_tools"]
            }
        }
    
    def download_file(self, url: str, filepath: Path, description: str = "") -> bool:
        """TÃ©lÃ©charge un fichier avec barre de progression"""
        try:
            logger.info(f"ğŸ“¥ TÃ©lÃ©chargement {description}...")
            
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(filepath, 'wb') as file, tqdm(
                desc=f"ğŸ“¦ {description}",
                total=total_size,
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
            ) as pbar:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        file.write(chunk)
                        pbar.update(len(chunk))
            
            logger.success(f"âœ… {description} tÃ©lÃ©chargÃ©: {filepath}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur tÃ©lÃ©chargement {description}: {e}")
            if filepath.exists():
                filepath.unlink()  # Supprimer fichier partiel
            return False
    
    def download_from_huggingface(self, model_id: str, filename: str, description: str = "") -> bool:
        """TÃ©lÃ©charge un modÃ¨le depuis Hugging Face Hub"""
        try:
            from transformers import AutoModel, AutoTokenizer
            logger.info(f"ğŸ“¥ TÃ©lÃ©chargement {description} depuis HF Hub...")
            
            # Cela va tÃ©lÃ©charger et cacher automatiquement
            model = AutoModel.from_pretrained(model_id)
            
            # Marquer comme tÃ©lÃ©chargÃ©
            cache_file = self.models_dir / f"{filename}.downloaded"
            cache_file.write_text(f"Downloaded from {model_id}")
            
            logger.success(f"âœ… {description} tÃ©lÃ©chargÃ© et mis en cache")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur tÃ©lÃ©chargement {description} depuis HF: {e}")
            return False
    
    def is_model_available(self, model_key: str) -> bool:
        """VÃ©rifie si un modÃ¨le est disponible localement"""
        config = self.models_config.get(model_key)
        if not config:
            return False
            
        if config.get("huggingface_id"):
            # VÃ©rifier cache file HF
            cache_file = self.models_dir / f"{config['filename']}.downloaded"
            return cache_file.exists()
        else:
            # VÃ©rifier fichier direct
            model_path = self.models_dir / config["filename"]
            return model_path.exists()
    
    def get_model_path(self, model_key: str) -> Optional[Path]:
        """Retourne le chemin vers un modÃ¨le s'il existe"""
        config = self.models_config.get(model_key)
        if not config:
            return None
            
        model_path = self.models_dir / config["filename"]
        return model_path if model_path.exists() else None
    
    def download_model(self, model_key: str, force: bool = False) -> bool:
        """TÃ©lÃ©charge un modÃ¨le spÃ©cifique"""
        config = self.models_config.get(model_key)
        if not config:
            logger.error(f"âŒ Configuration modÃ¨le inconnue: {model_key}")
            return False
        
        # VÃ©rifier si dÃ©jÃ  tÃ©lÃ©chargÃ©
        if not force and self.is_model_available(model_key):
            logger.info(f"âœ… ModÃ¨le {config['name']} dÃ©jÃ  disponible")
            return True
        
        # TÃ©lÃ©chargement selon le type
        if config.get("huggingface_id"):
            return self.download_from_huggingface(
                config["huggingface_id"],
                config["filename"],
                config["name"]
            )
        elif config.get("url"):
            model_path = self.models_dir / config["filename"]
            return self.download_file(
                config["url"],
                model_path,
                config["name"]
            )
        else:
            logger.error(f"âŒ Aucune source de tÃ©lÃ©chargement pour {model_key}")
            return False
    
    def download_essential_models(self) -> Dict[str, bool]:
        """TÃ©lÃ©charge tous les modÃ¨les marquÃ©s comme auto_download"""
        results = {}
        
        logger.info("ğŸš€ TÃ©lÃ©chargement des modÃ¨les essentiels...")
        
        for model_key, config in self.models_config.items():
            if config.get("auto_download", False):
                logger.info(f"ğŸ“¦ Traitement {config['name']}...")
                results[model_key] = self.download_model(model_key)
            else:
                logger.debug(f"â­ï¸ Ignore {config['name']} (pas en auto-download)")
                
        # RÃ©sumÃ©
        successful = sum(1 for success in results.values() if success)
        total = len(results)
        
        if successful == total:
            logger.success(f"ğŸ‰ Tous les modÃ¨les tÃ©lÃ©chargÃ©s avec succÃ¨s ({successful}/{total})")
        else:
            logger.warning(f"âš ï¸ Certains modÃ¨les ont Ã©chouÃ© ({successful}/{total} rÃ©ussis)")
            
        return results
    
    def check_system_requirements(self) -> Dict[str, bool]:
        """VÃ©rifie les prÃ©requis systÃ¨me"""
        requirements = {}
        
        # CUDA disponible
        requirements["cuda_available"] = torch.cuda.is_available()
        if requirements["cuda_available"]:
            requirements["gpu_count"] = torch.cuda.device_count()
            requirements["gpu_memory"] = torch.cuda.get_device_properties(0).total_memory
        else:
            requirements["gpu_count"] = 0
            requirements["gpu_memory"] = 0
            
        # Espace disque
        try:
            import shutil
            disk_usage = shutil.disk_usage(self.models_dir)
            requirements["disk_free_gb"] = disk_usage.free / (1024**3)
        except:
            requirements["disk_free_gb"] = 0
            
        # RAM systÃ¨me  
        try:
            import psutil
            requirements["ram_total_gb"] = psutil.virtual_memory().total / (1024**3)
            requirements["ram_available_gb"] = psutil.virtual_memory().available / (1024**3)
        except:
            requirements["ram_total_gb"] = 0
            requirements["ram_available_gb"] = 0
            
        return requirements
    
    def generate_setup_report(self) -> str:
        """GÃ©nÃ¨re un rapport de setup complet"""
        report = []
        report.append("ğŸ¯ RAPPORT SETUP MODÃˆLES")
        report.append("=" * 50)
        
        # PrÃ©requis systÃ¨me
        requirements = self.check_system_requirements()
        report.append(f"\nğŸ–¥ï¸ SYSTÃˆME:")
        report.append(f"   CUDA: {'âœ…' if requirements['cuda_available'] else 'âŒ'}")
        report.append(f"   GPU: {requirements['gpu_count']} device(s)")
        if requirements['gpu_memory'] > 0:
            report.append(f"   GPU Memory: {requirements['gpu_memory'] / (1024**3):.1f} GB")
        report.append(f"   RAM disponible: {requirements['ram_available_gb']:.1f} GB")
        report.append(f"   Espace disque: {requirements['disk_free_gb']:.1f} GB")
        
        # Status des modÃ¨les
        report.append(f"\nğŸ“¦ MODÃˆLES:")
        for model_key, config in self.models_config.items():
            available = self.is_model_available(model_key)
            auto_dl = config.get("auto_download", False)
            status = "âœ…" if available else ("ğŸ”„" if auto_dl else "â­ï¸")
            
            size_info = f"({config.get('size_mb', 0):.1f}MB)" if config.get('size_mb') else ""
            report.append(f"   {status} {config['name']} {size_info}")
            
            if auto_dl and not available:
                report.append(f"      â†’ Sera tÃ©lÃ©chargÃ© automatiquement")
        
        return "\n".join(report)
    
    def initialize_yolo_with_auto_download(self):
        """Initialise YOLO avec tÃ©lÃ©chargement automatique si nÃ©cessaire"""
        try:
            from ultralytics import YOLO
            
            # VÃ©rifier si modÃ¨le YOLO existe
            if not self.is_model_available("yolo"):
                logger.info("ğŸ”„ YOLO model manquant, tÃ©lÃ©chargement automatique...")
                success = self.download_model("yolo")
                if not success:
                    logger.error("âŒ Ã‰chec tÃ©lÃ©chargement YOLO")
                    return None
            
            # Charger le modÃ¨le
            model_path = self.get_model_path("yolo")
            if model_path and model_path.exists():
                logger.info(f"ğŸ“¥ Chargement YOLO depuis {model_path}")
                return YOLO(str(model_path))
            else:
                # Fallback : laisser ultralytics tÃ©lÃ©charger
                logger.info("ğŸ”„ Fallback: YOLO tÃ©lÃ©chargement via ultralytics")
                return YOLO("yolo11n.pt")
                
        except Exception as e:
            logger.error(f"âŒ Erreur initialisation YOLO: {e}")
            return None


# Instance globale
model_manager = ModelManager()


def ensure_models_ready() -> bool:
    """Assure que tous les modÃ¨les essentiels sont prÃªts"""
    logger.info("ğŸš€ VÃ©rification des modÃ¨les essentiels...")
    
    # Afficher rapport
    print(model_manager.generate_setup_report())
    
    # TÃ©lÃ©charger les modÃ¨les essentiels
    results = model_manager.download_essential_models()
    
    # VÃ©rifier succÃ¨s
    all_success = all(results.values()) if results else True
    
    if all_success:
        logger.success("âœ… Tous les modÃ¨les essentiels sont prÃªts!")
    else:
        failed_models = [k for k, v in results.items() if not v]
        logger.warning(f"âš ï¸ ModÃ¨les Ã©chouÃ©s: {failed_models}")
    
    return all_success


if __name__ == "__main__":
    # Test du gestionnaire
    ensure_models_ready()