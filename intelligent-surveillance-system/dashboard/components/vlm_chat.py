"""Interface de chat avancÃ©e avec VLM."""

import streamlit as st
import asyncio
from typing import Dict, List, Optional, Any, Callable
from datetime import datetime
import json
import uuid
import base64
from pathlib import Path

from services.session_manager import get_session_manager
from config.settings import get_dashboard_config

class VLMChatInterface:
    """Interface de chat avancÃ©e avec le VLM."""
    
    def __init__(self):
        self.session = get_session_manager()
        self.config = get_dashboard_config()
        self.vlm_callback: Optional[Callable] = None
        self.context_data = {}
        
        # Questions prÃ©dÃ©finies
        self.predefined_questions = {
            "Analyse gÃ©nÃ©rale": [
                "Que voyez-vous dans cette vidÃ©o ?",
                "Y a-t-il des comportements suspects ?",
                "Quel est le niveau de risque global ?",
                "RÃ©sumez les Ã©vÃ©nements principaux"
            ],
            "DÃ©tection spÃ©cifique": [
                "Combien de personnes sont visibles ?",
                "Y a-t-il des objets abandonnÃ©s ?",
                "DÃ©tectez-vous des gestes suspects ?",
                "Y a-t-il des mouvements anormaux ?"
            ],
            "SÃ©curitÃ©": [
                "Ã‰valuez le niveau de menace",
                "Y a-t-il violation de zones interdites ?",
                "DÃ©tectez-vous des intrusions ?",
                "Analysez les comportements Ã  risque"
            ],
            "Contextuel": [
                "Que s'est-il passÃ© Ã  ce moment prÃ©cis ?",
                "Expliquez cette sÃ©quence d'Ã©vÃ©nements",
                "Pourquoi cette alerte a-t-elle Ã©tÃ© dÃ©clenchÃ©e ?",
                "Analysez cette zone spÃ©cifique"
            ]
        }
    
    def render_chat_interface(self):
        """Affiche l'interface de chat complÃ¨te."""
        
        st.subheader("ğŸ’¬ Chat avec l'IA de Surveillance")
        
        # Onglets pour organiser l'interface
        tab1, tab2, tab3 = st.tabs(["ğŸ’¬ Conversation", "â“ Questions", "ğŸ“Š Contexte"])
        
        with tab1:
            self._render_conversation_tab()
        
        with tab2:
            self._render_questions_tab()
        
        with tab3:
            self._render_context_tab()
    
    def _render_conversation_tab(self):
        """Onglet conversation principale."""
        
        # Historique des messages
        messages = self.session.get_chat_history()
        
        if not messages:
            st.info("ğŸ‘‹ Bonjour ! Je suis votre assistant IA de surveillance. Posez-moi des questions sur les vidÃ©os analysÃ©es.")
        
        # Container pour les messages avec hauteur fixe
        chat_container = st.container()
        
        with chat_container:
            for message in messages:
                self._render_message(message)
        
        # Zone de saisie
        self._render_input_area()
    
    def _render_message(self, message: Dict[str, Any]):
        """Affiche un message individuel."""
        
        role = message.get('role', 'user')
        content = message.get('content', '')
        timestamp = message.get('timestamp', '')
        metadata = message.get('metadata', {})
        
        # Formatage timestamp
        try:
            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            time_str = dt.strftime("%H:%M:%S")
        except:
            time_str = ""
        
        if role == 'user':
            # Message utilisateur
            with st.chat_message("user"):
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.write(content)
                with col2:
                    if time_str:
                        st.caption(time_str)
        
        else:
            # Message assistant
            with st.chat_message("assistant"):
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.write(content)
                    
                    # MÃ©tadonnÃ©es si disponibles
                    if metadata:
                        with st.expander("ğŸ“Š DÃ©tails de l'analyse", expanded=False):
                            if 'confidence' in metadata:
                                st.progress(metadata['confidence'], "Confiance")
                            
                            if 'analysis_time' in metadata:
                                st.metric("Temps d'analyse", f"{metadata['analysis_time']:.2f}s")
                            
                            if 'tools_used' in metadata:
                                st.write("ğŸ”§ Outils utilisÃ©s:", ", ".join(metadata['tools_used']))
                
                with col2:
                    if time_str:
                        st.caption(time_str)
                    
                    # Boutons d'actions
                    self._render_message_actions(message)
    
    def _render_message_actions(self, message: Dict[str, Any]):
        """Affiche les actions pour un message."""
        
        message_id = message.get('id', '')
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ‘", key=f"like_{message_id}", help="Utile"):
                self._rate_message(message_id, "like")
        
        with col2:
            if st.button("ğŸ‘", key=f"dislike_{message_id}", help="Pas utile"):
                self._rate_message(message_id, "dislike")
    
    def _render_input_area(self):
        """Zone de saisie des messages."""
        
        # Chat input principal
        user_input = st.chat_input("Posez votre question sur la surveillance...")
        
        # Boutons raccourcis
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("ğŸ” Analyser maintenant", use_container_width=True):
                self._quick_analyze()
        
        with col2:
            if st.button("âš ï¸ Quelles alertes ?", use_container_width=True):
                user_input = "Quelles sont les alertes actives et leur niveau de prioritÃ© ?"
        
        with col3:
            if st.button("ğŸ“Š Ã‰tat systÃ¨me", use_container_width=True):
                user_input = "Quel est l'Ã©tat actuel du systÃ¨me de surveillance ?"
        
        with col4:
            if st.button("ğŸ§¹ Effacer chat", use_container_width=True, type="secondary"):
                self._clear_chat()
        
        # Traitement de l'input
        if user_input:
            self._process_user_input(user_input)
    
    def _render_questions_tab(self):
        """Onglet questions prÃ©dÃ©finies."""
        
        st.write("SÃ©lectionnez une question prÃ©dÃ©finie ou parcourez par catÃ©gorie :")
        
        # SÃ©lection par catÃ©gorie
        selected_category = st.selectbox(
            "CatÃ©gorie",
            list(self.predefined_questions.keys())
        )
        
        # Questions de la catÃ©gorie
        if selected_category:
            questions = self.predefined_questions[selected_category]
            
            for i, question in enumerate(questions):
                col1, col2 = st.columns([4, 1])
                
                with col1:
                    st.write(f"**{i+1}.** {question}")
                
                with col2:
                    if st.button("â–¶ï¸", key=f"ask_{selected_category}_{i}"):
                        self._process_user_input(question)
                        st.rerun()
        
        # Section questions personnalisÃ©es
        with st.expander("â• Ajouter une question personnalisÃ©e"):
            new_category = st.text_input("Nouvelle catÃ©gorie (optionnel)")
            new_question = st.text_input("Question personnalisÃ©e")
            
            if st.button("ğŸ’¾ Sauvegarder"):
                if new_question:
                    category = new_category or "PersonnalisÃ©es"
                    if category not in self.predefined_questions:
                        self.predefined_questions[category] = []
                    
                    self.predefined_questions[category].append(new_question)
                    st.success("Question ajoutÃ©e !")
                    st.rerun()
    
    def _render_context_tab(self):
        """Onglet contexte et donnÃ©es."""
        
        st.write("**Contexte actuel pour l'IA :**")
        
        # Analyses vidÃ©o rÃ©centes
        video_analyses = self.session.get_all_video_analyses()
        if video_analyses:
            st.write("ğŸ“¹ **Analyses vidÃ©o disponibles:**")
            for video_id, analysis in video_analyses.items():
                with st.expander(f"VidÃ©o {video_id[:8]}..."):
                    st.json(analysis)
        
        # Ã‰tat des camÃ©ras
        cameras_state = self.session.get_all_cameras_state()
        if cameras_state:
            st.write("ğŸ¥ **Ã‰tat des camÃ©ras:**")
            for cam_id, state in cameras_state.items():
                st.write(f"- **{state.get('name', cam_id)}**: "
                        f"{'ğŸŸ¢ Actif' if state.get('enabled', False) else 'ğŸ”´ Inactif'}")
        
        # Alertes rÃ©centes
        alerts = self.session.get_active_alerts()
        if alerts:
            st.write("ğŸš¨ **Alertes actives:**")
            for alert in alerts[-5:]:  # 5 derniÃ¨res
                level_emoji = {
                    'LOW': 'ğŸ”µ',
                    'MEDIUM': 'ğŸŸ¡', 
                    'HIGH': 'ğŸŸ ',
                    'CRITICAL': 'ğŸ”´'
                }.get(alert.get('level', 'LOW'), 'âšª')
                
                st.write(f"{level_emoji} {alert.get('message', 'N/A')}")
        
        # Contexte personnalisÃ©
        with st.expander("âš™ï¸ Contexte personnalisÃ©"):
            custom_context = st.text_area(
                "Informations additionnelles pour l'IA",
                value=self.context_data.get('custom', ''),
                placeholder="Ex: Nous surveillons un magasin ouvert de 9h Ã  21h..."
            )
            
            if st.button("ğŸ’¾ Sauvegarder contexte"):
                self.context_data['custom'] = custom_context
                st.success("Contexte sauvegardÃ© !")
    
    def _process_user_input(self, user_input: str):
        """Traite l'input utilisateur."""
        
        if not user_input.strip():
            return
        
        # Ajout du message utilisateur
        self.session.add_chat_message("user", user_input)
        
        # PrÃ©paration du contexte
        context = self._build_context()
        
        # Appel au VLM
        with st.spinner("ğŸ¤” L'IA analyse votre question..."):
            try:
                response = self._get_vlm_response(user_input, context)
                
                # Ajout de la rÃ©ponse
                self.session.add_chat_message(
                    "assistant",
                    response.get('content', 'DÃ©solÃ©, je ne peux pas rÃ©pondre pour le moment.'),
                    response.get('metadata', {})
                )
                
            except Exception as e:
                error_msg = f"âŒ Erreur lors de l'analyse: {str(e)}"
                self.session.add_chat_message("assistant", error_msg)
                st.error(error_msg)
        
        st.rerun()
    
    def _build_context(self) -> Dict[str, Any]:
        """Construit le contexte pour le VLM."""
        
        context = {
            'timestamp': datetime.now().isoformat(),
            'session_id': self.session.get_session_id()
        }
        
        # Analyses vidÃ©o
        video_analyses = self.session.get_all_video_analyses()
        if video_analyses:
            context['video_analyses'] = video_analyses
        
        # Ã‰tat des camÃ©ras
        cameras_state = self.session.get_all_cameras_state()
        if cameras_state:
            context['cameras_state'] = cameras_state
        
        # Alertes
        alerts = self.session.get_active_alerts()
        if alerts:
            context['active_alerts'] = alerts
        
        # Contexte personnalisÃ©
        if 'custom' in self.context_data:
            context['custom_context'] = self.context_data['custom']
        
        return context
    
    def _get_vlm_response(self, question: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Obtient une rÃ©ponse du VLM."""
        
        if self.vlm_callback:
            # Appel au VLM via callback
            start_time = datetime.now()
            
            response = self.vlm_callback(question, context)
            
            analysis_time = (datetime.now() - start_time).total_seconds()
            
            # Enrichissement avec mÃ©tadonnÃ©es
            if isinstance(response, str):
                response = {'content': response}
            
            response['metadata'] = {
                'analysis_time': analysis_time,
                'context_size': len(str(context)),
                **response.get('metadata', {})
            }
            
            return response
        
        else:
            # RÃ©ponse simulÃ©e en mode dÃ©mo
            return {
                'content': f"ğŸ¤– RÃ©ponse simulÃ©e Ã : {question}\n\nEn mode dÃ©mo, le VLM n'est pas connectÃ©. Voici ce que je vois dans le contexte:\n- {len(context.get('video_analyses', {}))} analyses vidÃ©o disponibles\n- {len(context.get('cameras_state', {}))} camÃ©ras configurÃ©es\n- {len(context.get('active_alerts', []))} alertes actives",
                'metadata': {
                    'analysis_time': 0.5,
                    'demo_mode': True,
                    'confidence': 0.8
                }
            }
    
    def _quick_analyze(self):
        """Lance une analyse rapide."""
        self._process_user_input("Analysez la situation actuelle et donnez-moi un rÃ©sumÃ© des Ã©vÃ©nements importants.")
    
    def _clear_chat(self):
        """Efface l'historique du chat."""
        self.session.clear_chat_history()
        st.success("ğŸ’¬ Historique effacÃ©")
        st.rerun()
    
    def _rate_message(self, message_id: str, rating: str):
        """Note un message."""
        # TODO: ImplÃ©menter systÃ¨me de notation
        st.success(f"Merci pour votre retour ! ({rating})")
    
    def set_vlm_callback(self, callback: Callable[[str, Dict], Dict]):
        """DÃ©finit le callback VLM."""
        self.vlm_callback = callback
    
    def add_system_message(self, content: str, level: str = "info"):
        """Ajoute un message systÃ¨me."""
        
        level_prefixes = {
            'info': 'ğŸ’¡',
            'warning': 'âš ï¸',
            'error': 'âŒ',
            'success': 'âœ…'
        }
        
        prefix = level_prefixes.get(level, 'ğŸ’¡')
        formatted_content = f"{prefix} **SystÃ¨me**: {content}"
        
        self.session.add_chat_message(
            "assistant",
            formatted_content,
            {'system_message': True, 'level': level}
        )
    
    def export_chat_history(self, format: str = 'json') -> str:
        """Exporte l'historique du chat."""
        
        history = self.session.get_chat_history()
        
        if format.lower() == 'json':
            return json.dumps(history, indent=2, ensure_ascii=False)
        
        elif format.lower() == 'txt':
            lines = []
            for msg in history:
                timestamp = msg.get('timestamp', '')
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')
                
                lines.append(f"[{timestamp}] {role.upper()}: {content}")
                lines.append("")
            
            return "\n".join(lines)
        
        return json.dumps(history, indent=2, ensure_ascii=False)

# Instance globale
def get_vlm_chat() -> VLMChatInterface:
    """RÃ©cupÃ¨re l'instance de chat VLM."""
    if 'vlm_chat' not in st.session_state:
        st.session_state.vlm_chat = VLMChatInterface()
    
    return st.session_state.vlm_chat

# Fonctions utilitaires

def render_chat_sidebar():
    """Affiche un chat compact dans la sidebar."""
    
    chat = get_vlm_chat()
    
    with st.sidebar:
        st.subheader("ğŸ’¬ Chat Rapide")
        
        # Derniers messages
        messages = chat.session.get_chat_history()
        if messages:
            last_msg = messages[-1]
            role = last_msg.get('role', 'user')
            content = last_msg.get('content', '')
            
            if role == 'assistant':
                st.success(content[:100] + "..." if len(content) > 100 else content)
            else:
                st.info(content[:100] + "..." if len(content) > 100 else content)
        
        # Input rapide
        quick_input = st.text_input("Question rapide", key="sidebar_chat_input")
        
        if st.button("â¤ Envoyer", use_container_width=True):
            if quick_input:
                chat._process_user_input(quick_input)
                st.rerun()

def render_quick_questions_bar():
    """Barre de questions rapides."""
    
    st.write("**Questions rapides:**")
    
    col1, col2, col3, col4 = st.columns(4)
    
    chat = get_vlm_chat()
    
    with col1:
        if st.button("ğŸ” Que se passe-t-il ?", use_container_width=True):
            chat._process_user_input("Analysez la situation actuelle et rÃ©sumez les Ã©vÃ©nements.")
    
    with col2:
        if st.button("âš ï¸ Niveau de risque ?", use_container_width=True):
            chat._process_user_input("Quel est le niveau de risque actuel ?")
    
    with col3:
        if st.button("ğŸ‘¥ Combien de personnes ?", use_container_width=True):
            chat._process_user_input("Combien de personnes sont visibles sur les camÃ©ras ?")
    
    with col4:
        if st.button("ğŸš¨ Alertes actives ?", use_container_width=True):
            chat._process_user_input("Quelles sont les alertes actives et leur prioritÃ© ?")