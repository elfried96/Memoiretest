{
  "method": "video_analysis",
  "timestamp": "2025-09-10T14:41:20.967627",
  "plan": {
    "description": "Analyser des vidéos de surveillance réelles",
    "steps": [
      "1. Collecter des vidéos de test (normales + suspectes)",
      "2. Créer un ground truth manuel (annoter les comportements)",
      "3. Faire tourner votre système sur ces vidéos",
      "4. Comparer les résultats avec vos annotations",
      "5. Calculer précision, recall, F1-score"
    ],
    "code_example": "\n# Utiliser votre script d'évaluation:\npython evaluate_system.py --video_dir /path/to/your/videos --ground_truth annotations.json\n\n# Ou directement en Python:\nfrom evaluate_system import SystemEvaluator\nevaluator = SystemEvaluator()\nresults = evaluator.evaluate_video(\"video_test.mp4\", ground_truth_data)\nprint(f\"Précision: {results['precision']:.2%}\")\nprint(f\"Recall: {results['recall']:.2%}\")\n            ",
    "metrics_you_get": [
      "Temps de traitement par frame",
      "FPS (images par seconde)",
      "Précision de détection des comportements suspects",
      "Taux de faux positifs/négatifs",
      "Latence du système global"
    ]
  },
  "next_steps": [
    "1. Enregistrer ou trouver 5-10 vidéos de test",
    "2. Annoter manuellement les comportements (ground truth)",
    "3. Modifier evaluate_system.py pour accept video directory",
    "4. Lancer l'évaluation: python evaluate_system.py --videos ./test_videos",
    "5. Analyser les résultats et calculer métriques finales"
  ],
  "tools_needed": [
    "Caméra/videos de test",
    "Outil d'annotation (LabelImg, CVAT)",
    "evaluate_system.py (déjà créé)",
    "Calculs statistiques (pandas, sklearn.metrics)"
  ]
}