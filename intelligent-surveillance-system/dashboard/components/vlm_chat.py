"""Interface de chat avanc√©e avec VLM."""

import streamlit as st
import asyncio
from typing import Dict, List, Optional, Any, Callable
from datetime import datetime
import json
import uuid
import base64
from pathlib import Path

from services.session_manager import get_session_manager
from config.settings import get_dashboard_config

class VLMChatInterface:
    """Interface de chat avanc√©e avec le VLM."""
    
    def __init__(self):
        self.session = get_session_manager()
        self.config = get_dashboard_config()
        self.vlm_callback: Optional[Callable] = None
        self.context_data = {}
        
        # Questions pr√©d√©finies
        self.predefined_questions = {
            "Analyse g√©n√©rale": [
                "Que voyez-vous dans cette vid√©o ?",
                "Y a-t-il des comportements suspects ?",
                "Quel est le niveau de risque global ?",
                "R√©sumez les √©v√©nements principaux"
            ],
            "D√©tection sp√©cifique": [
                "Combien de personnes sont visibles ?",
                "Y a-t-il des objets abandonn√©s ?",
                "D√©tectez-vous des gestes suspects ?",
                "Y a-t-il des mouvements anormaux ?"
            ],
            "S√©curit√©": [
                "√âvaluez le niveau de menace",
                "Y a-t-il violation de zones interdites ?",
                "D√©tectez-vous des intrusions ?",
                "Analysez les comportements √† risque"
            ],
            "Contextuel": [
                "Que s'est-il pass√© √† ce moment pr√©cis ?",
                "Expliquez cette s√©quence d'√©v√©nements",
                "Pourquoi cette alerte a-t-elle √©t√© d√©clench√©e ?",
                "Analysez cette zone sp√©cifique"
            ]
        }
    
    def render_chat_interface(self):
        """Affiche l'interface de chat compl√®te."""
        
        st.subheader("Chat avec l'IA de Surveillance")
        
        # Onglets pour organiser l'interface
        tab1, tab2, tab3 = st.tabs(["Conversation", "Questions", "Contexte"])
        
        with tab1:
            self._render_conversation_tab()
        
        with tab2:
            self._render_questions_tab()
        
        with tab3:
            self._render_context_tab()
    
    def _render_conversation_tab(self):
        """Onglet conversation principale."""
        
        # Historique des messages
        messages = self.session.get_chat_history()
        
        if not messages:
            st.info("üëã Bonjour ! Je suis votre assistant IA de surveillance. Posez-moi des questions sur les vid√©os analys√©es.")
        
        # Container pour les messages avec hauteur fixe
        chat_container = st.container()
        
        with chat_container:
            for message in messages:
                self._render_message(message)
        
        # Zone de saisie
        self._render_input_area()
    
    def _render_message(self, message: Dict[str, Any]):
        """Affiche un message individuel."""
        
        role = message.get('role', 'user')
        content = message.get('content', '')
        timestamp = message.get('timestamp', '')
        metadata = message.get('metadata', {})
        
        # Formatage timestamp
        try:
            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            time_str = dt.strftime("%H:%M:%S")
        except:
            time_str = ""
        
        if role == 'user':
            # Message utilisateur
            with st.chat_message("user"):
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.write(content)
                with col2:
                    if time_str:
                        st.caption(time_str)
        
        else:
            # Message assistant
            with st.chat_message("assistant"):
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.write(content)
                    
                    # M√©tadonn√©es si disponibles
                    if metadata:
                        with st.expander("D√©tails de l'analyse", expanded=False):
                            if 'confidence' in metadata:
                                st.progress(metadata['confidence'], "Confiance")
                            
                            if 'analysis_time' in metadata:
                                st.metric("Temps d'analyse", f"{metadata['analysis_time']:.2f}s")
                            
                            if 'tools_used' in metadata:
                                st.write("Outils utilis√©s:", ", ".join(metadata['tools_used']))
                
                with col2:
                    if time_str:
                        st.caption(time_str)
                    
                    # Boutons d'actions
                    self._render_message_actions(message)
    
    def _render_message_actions(self, message: Dict[str, Any]):
        """Affiche les actions pour un message."""
        
        message_id = message.get('id', '')
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üëç", key=f"like_{message_id}", help="Utile"):
                self._rate_message(message_id, "like")
        
        with col2:
            if st.button("üëé", key=f"dislike_{message_id}", help="Pas utile"):
                self._rate_message(message_id, "dislike")
    
    def _render_input_area(self):
        """Zone de saisie des messages."""
        
        # Chat input principal
        user_input = st.chat_input("Posez votre question sur la surveillance...")
        
        # Boutons raccourcis
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("Analyser maintenant", use_container_width=True):
                self._quick_analyze()
        
        with col2:
            if st.button("Quelles alertes ?", use_container_width=True):
                user_input = "Quelles sont les alertes actives et leur niveau de priorit√© ?"
        
        with col3:
            if st.button("√âtat syst√®me", use_container_width=True):
                user_input = "Quel est l'√©tat actuel du syst√®me de surveillance ?"
        
        with col4:
            if st.button("Effacer chat", use_container_width=True, type="secondary"):
                self._clear_chat()
        
        # Traitement de l'input
        if user_input:
            self._process_user_input(user_input)
    
    def _render_questions_tab(self):
        """Onglet questions pr√©d√©finies."""
        
        st.write("S√©lectionnez une question pr√©d√©finie ou parcourez par cat√©gorie :")
        
        # S√©lection par cat√©gorie
        selected_category = st.selectbox(
            "Cat√©gorie",
            list(self.predefined_questions.keys())
        )
        
        # Questions de la cat√©gorie
        if selected_category:
            questions = self.predefined_questions[selected_category]
            
            for i, question in enumerate(questions):
                col1, col2 = st.columns([4, 1])
                
                with col1:
                    st.write(f"**{i+1}.** {question}")
                
                with col2:
                    if st.button("‚ñ∂", key=f"ask_{selected_category}_{i}"):
                        self._process_user_input(question)
                        st.rerun()
        
        # Section questions personnalis√©es
        with st.expander("Ajouter une question personnalis√©e"):
            new_category = st.text_input("Nouvelle cat√©gorie (optionnel)")
            new_question = st.text_input("Question personnalis√©e")
            
            if st.button("Sauvegarder"):
                if new_question:
                    category = new_category or "Personnalis√©es"
                    if category not in self.predefined_questions:
                        self.predefined_questions[category] = []
                    
                    self.predefined_questions[category].append(new_question)
                    st.success("Question ajout√©e !")
                    st.rerun()
    
    def _render_context_tab(self):
        """Onglet contexte et donn√©es."""
        
        st.write("**Contexte actuel pour l'IA :**")
        
        # Analyses vid√©o r√©centes
        video_analyses = self.session.get_all_video_analyses()
        if video_analyses:
            st.write("**Analyses vid√©o disponibles:**")
            for video_id, analysis in video_analyses.items():
                with st.expander(f"Vid√©o {video_id[:8]}..."):
                    st.json(analysis)
        
        # √âtat des cam√©ras
        cameras_state = self.session.get_all_cameras_state()
        if cameras_state:
            st.write("**√âtat des cam√©ras:**")
            for cam_id, state in cameras_state.items():
                st.write(f"- **{state.get('name', cam_id)}**: "
                        f"{'Actif' if state.get('enabled', False) else 'Inactif'}")
        
        # Alertes r√©centes
        alerts = self.session.get_active_alerts()
        if alerts:
            st.write("**Alertes actives:**")
            for alert in alerts[-5:]:  # 5 derni√®res
                level_emoji = {
                    'LOW': '',
                    'MEDIUM': '', 
                    'HIGH': '',
                    'CRITICAL': ''
                }.get(alert.get('level', 'LOW'), '')
                
                st.write(f"{level_emoji} {alert.get('message', 'N/A')}")
        
        # Contexte personnalis√©
        with st.expander("Contexte personnalis√©"):
            custom_context = st.text_area(
                "Informations additionnelles pour l'IA",
                value=self.context_data.get('custom', ''),
                placeholder="Ex: Nous surveillons un magasin ouvert de 9h √† 21h..."
            )
            
            if st.button("Sauvegarder contexte"):
                self.context_data['custom'] = custom_context
                st.success("Contexte sauvegard√© !")
    
    def _process_user_input(self, user_input: str):
        """Traite l'input utilisateur."""
        
        if not user_input.strip():
            return
        
        # Ajout du message utilisateur
        self.session.add_chat_message("user", user_input)
        
        # Pr√©paration du contexte
        context = self._build_context()
        
        # Appel au VLM
        with st.spinner("ü§î L'IA analyse votre question..."):
            try:
                response = self._get_vlm_response(user_input, context)
                
                # Ajout de la r√©ponse
                self.session.add_chat_message(
                    "assistant",
                    response.get('content', 'D√©sol√©, je ne peux pas r√©pondre pour le moment.'),
                    response.get('metadata', {})
                )
                
            except Exception as e:
                error_msg = f"Erreur lors de l'analyse: {str(e)}"
                self.session.add_chat_message("assistant", error_msg)
                st.error(error_msg)
        
        st.rerun()
    
    def _build_context(self) -> Dict[str, Any]:
        """Construit le contexte pour le VLM."""
        
        context = {
            'timestamp': datetime.now().isoformat(),
            'session_id': self.session.get_session_id()
        }
        
        # Analyses vid√©o
        video_analyses = self.session.get_all_video_analyses()
        if video_analyses:
            context['video_analyses'] = video_analyses
        
        # √âtat des cam√©ras
        cameras_state = self.session.get_all_cameras_state()
        if cameras_state:
            context['cameras_state'] = cameras_state
        
        # Alertes
        alerts = self.session.get_active_alerts()
        if alerts:
            context['active_alerts'] = alerts
        
        # Contexte personnalis√©
        if 'custom' in self.context_data:
            context['custom_context'] = self.context_data['custom']
        
        return context
    
    def _get_vlm_response(self, question: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Obtient une r√©ponse du VLM."""
        
        if self.vlm_callback:
            # Appel au VLM via callback
            start_time = datetime.now()
            
            response = self.vlm_callback(question, context)
            
            analysis_time = (datetime.now() - start_time).total_seconds()
            
            # Enrichissement avec m√©tadonn√©es
            if isinstance(response, str):
                response = {'content': response}
            
            response['metadata'] = {
                'analysis_time': analysis_time,
                'context_size': len(str(context)),
                **response.get('metadata', {})
            }
            
            return response
        
        else:
            # R√©ponse simul√©e en mode d√©mo
            return {
                'content': f" R√©ponse simul√©e √†: {question}\n\nEn mode d√©mo, le VLM n'est pas connect√©. Voici ce que je vois dans le contexte:\n- {len(context.get('video_analyses', {}))} analyses vid√©o disponibles\n- {len(context.get('cameras_state', {}))} cam√©ras configur√©es\n- {len(context.get('active_alerts', []))} alertes actives",
                'metadata': {
                    'analysis_time': 0.5,
                    'demo_mode': True,
                    'confidence': 0.8
                }
            }
    
    def _quick_analyze(self):
        """Lance une analyse rapide."""
        self._process_user_input("Analysez la situation actuelle et donnez-moi un r√©sum√© des √©v√©nements importants.")
    
    def _clear_chat(self):
        """Efface l'historique du chat."""
        self.session.clear_chat_history()
        st.success("Historique effac√©")
        st.rerun()
    
    def _rate_message(self, message_id: str, rating: str):
        """Note un message."""
        # TODO: Impl√©menter syst√®me de notation
        st.success(f"Merci pour votre retour ! ({rating})")
    
    def set_vlm_callback(self, callback: Callable[[str, Dict], Dict]):
        """D√©finit le callback VLM."""
        self.vlm_callback = callback
    
    def add_system_message(self, content: str, level: str = "info"):
        """Ajoute un message syst√®me."""
        
        level_prefixes = {
            'info': '',
            'warning': '',
            'error': '',
            'success': ''
        }
        
        prefix = level_prefixes.get(level, '')
        formatted_content = f"{prefix} **Syst√®me**: {content}"
        
        self.session.add_chat_message(
            "assistant",
            formatted_content,
            {'system_message': True, 'level': level}
        )
    
    def export_chat_history(self, format: str = 'json') -> str:
        """Exporte l'historique du chat."""
        
        history = self.session.get_chat_history()
        
        if format.lower() == 'json':
            return json.dumps(history, indent=2, ensure_ascii=False)
        
        elif format.lower() == 'txt':
            lines = []
            for msg in history:
                timestamp = msg.get('timestamp', '')
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')
                
                lines.append(f"[{timestamp}] {role.upper()}: {content}")
                lines.append("")
            
            return "\n".join(lines)
        
        return json.dumps(history, indent=2, ensure_ascii=False)

# Instance globale
def get_vlm_chat() -> VLMChatInterface:
    """R√©cup√®re l'instance de chat VLM."""
    if 'vlm_chat' not in st.session_state:
        st.session_state.vlm_chat = VLMChatInterface()
    
    return st.session_state.vlm_chat

# Fonctions utilitaires

def render_chat_sidebar():
    """Affiche un chat compact dans la sidebar."""
    
    chat = get_vlm_chat()
    
    with st.sidebar:
        st.subheader("Chat Rapide")
        
        # Derniers messages
        messages = chat.session.get_chat_history()
        if messages:
            last_msg = messages[-1]
            role = last_msg.get('role', 'user')
            content = last_msg.get('content', '')
            
            if role == 'assistant':
                st.success(content[:100] + "..." if len(content) > 100 else content)
            else:
                st.info(content[:100] + "..." if len(content) > 100 else content)
        
        # Input rapide
        quick_input = st.text_input("Question rapide", key="sidebar_chat_input")
        
        if st.button("‚û§ Envoyer", use_container_width=True):
            if quick_input:
                chat._process_user_input(quick_input)
                st.rerun()

def render_quick_questions_bar():
    """Barre de questions rapides."""
    
    st.write("**Questions rapides:**")
    
    col1, col2, col3, col4 = st.columns(4)
    
    chat = get_vlm_chat()
    
    with col1:
        if st.button("Que se passe-t-il ?", use_container_width=True):
            chat._process_user_input("Analysez la situation actuelle et r√©sumez les √©v√©nements.")
    
    with col2:
        if st.button("Niveau de risque ?", use_container_width=True):
            chat._process_user_input("Quel est le niveau de risque actuel ?")
    
    with col3:
        if st.button("Combien de personnes ?", use_container_width=True):
            chat._process_user_input("Combien de personnes sont visibles sur les cam√©ras ?")
    
    with col4:
        if st.button("Alertes actives ?", use_container_width=True):
            chat._process_user_input("Quelles sont les alertes actives et leur priorit√© ?")