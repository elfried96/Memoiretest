"""
üîí Dashboard de Surveillance Intelligente
========================================

Application Streamlit moderne pour la surveillance avec IA.
Architecture modulaire et optimis√©e.
"""

import streamlit as st
import sys
from pathlib import Path
import asyncio
from typing import Optional, Dict, Any
import atexit

# Configuration du path pour acc√©der aux modules du syst√®me
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "src"))

# Import des composants dashboard
from config.settings import get_dashboard_config, get_audio_config
from services.session_manager import get_session_manager
from components.camera_grid import get_camera_grid, cleanup_camera_resources
from components.vlm_chat import get_vlm_chat
from utils.audio_alerts import get_audio_system, play_alert

# Imports syst√®me de surveillance (si disponible)
try:
    from src.core.vlm.model import VisionLanguageModel
    from src.core.orchestrator.adaptive_orchestrator import AdaptiveOrchestrator
    VLM_AVAILABLE = True
except ImportError:
    VLM_AVAILABLE = False
    st.warning("‚ö†Ô∏è Modules VLM non trouv√©s - Mode d√©mo activ√©")

class SurveillanceDashboard:
    """Dashboard principal de surveillance."""
    
    def __init__(self):
        self.config = get_dashboard_config()
        self.audio_config = get_audio_config()
        self.session = get_session_manager()
        
        # Composants principaux
        self.camera_grid = get_camera_grid()
        self.vlm_chat = get_vlm_chat()
        self.audio_system = get_audio_system()
        
        # Syst√®me de surveillance (si disponible)
        self.vlm_model: Optional[VisionLanguageModel] = None
        self.orchestrator: Optional[AdaptiveOrchestrator] = None
        
        self._setup_callbacks()
        self._init_vlm_system()
    
    def _setup_callbacks(self):
        """Configure les callbacks entre composants."""
        
        # Callback VLM pour le chat
        self.vlm_chat.set_vlm_callback(self._handle_vlm_query)
        
        # Callback d√©tection pour les cam√©ras
        self.camera_grid.set_detection_callback(self._handle_detection)
    
    def _init_vlm_system(self):
        """Initialise le syst√®me VLM si disponible."""
        
        if not VLM_AVAILABLE:
            return
        
        try:
            # Chargement asynchrone du VLM
            if 'vlm_system' not in st.session_state:
                st.session_state.vlm_system = {
                    'loading': False,
                    'loaded': False,
                    'model': None,
                    'orchestrator': None
                }
        
        except Exception as e:
            st.error(f"Erreur initialisation VLM: {e}")
    
    def _handle_vlm_query(self, question: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Traite une requ√™te chat VLM."""
        
        try:
            if not VLM_AVAILABLE or not st.session_state.get('vlm_system', {}).get('loaded', False):
                # Mode d√©mo
                return self._demo_vlm_response(question, context)
            
            # Traitement r√©el avec VLM
            model = st.session_state.vlm_system.get('model')
            if model:
                # TODO: Impl√©menter appel VLM r√©el
                response = f"R√©ponse VLM √†: {question}"
                
                return {
                    'content': response,
                    'metadata': {
                        'confidence': 0.85,
                        'tools_used': ['vlm', 'context_analysis']
                    }
                }
            
        except Exception as e:
            return {
                'content': f"‚ùå Erreur VLM: {str(e)}",
                'metadata': {'error': True}
            }
        
        return self._demo_vlm_response(question, context)
    
    def _demo_vlm_response(self, question: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """G√©n√®re une r√©ponse d√©mo intelligente."""
        
        question_lower = question.lower()
        
        # Analyse du contexte
        video_count = len(context.get('video_analyses', {}))
        camera_count = len(context.get('cameras_state', {}))
        alert_count = len(context.get('active_alerts', []))
        
        # R√©ponses contextuelles
        if any(word in question_lower for word in ['risque', 'danger', 'menace']):
            level = "FAIBLE" if alert_count == 0 else ("MOYEN" if alert_count < 3 else "√âLEV√â")
            response = f"üîç **√âvaluation du risque: {level}**\n\n"
            response += f"- {camera_count} cam√©ras actives\n"
            response += f"- {alert_count} alertes en cours\n"
            response += f"- {video_count} analyses r√©centes\n\n"
            
            if alert_count == 0:
                response += "‚úÖ Aucune activit√© suspecte d√©tect√©e actuellement."
            else:
                response += "‚ö†Ô∏è Surveillance renforc√©e recommand√©e."
        
        elif any(word in question_lower for word in ['personnes', 'individus', 'gens']):
            response = f"üë• **Analyse des personnes d√©tect√©es:**\n\n"
            response += f"Bas√© sur {video_count} analyses r√©centes:\n"
            response += "- 2-4 personnes g√©n√©ralement visibles\n"
            response += "- Comportement normal observ√©\n"
            response += "- Aucun regroupement suspect\n\n"
            response += "üí° *Utilisez l'upload vid√©o pour une analyse pr√©cise.*"
        
        elif any(word in question_lower for word in ['alerte', 'alertes']):
            response = f"üö® **√âtat des alertes:**\n\n"
            
            if alert_count == 0:
                response += "‚úÖ Aucune alerte active\n"
                response += "üîç Syst√®me de surveillance op√©rationnel\n"
            else:
                alerts = context.get('active_alerts', [])
                for alert in alerts[-3:]:  # 3 derni√®res
                    level = alert.get('level', 'INFO')
                    message = alert.get('message', 'N/A')
                    emoji = {'LOW': 'üîµ', 'MEDIUM': 'üü°', 'HIGH': 'üü†', 'CRITICAL': 'üî¥'}.get(level, '‚ö™')
                    response += f"{emoji} {message}\n"
        
        elif any(word in question_lower for word in ['syst√®me', '√©tat', 'status']):
            response = f"üñ•Ô∏è **√âtat du syst√®me:**\n\n"
            response += f"üìπ Cam√©ras: {camera_count} configur√©es\n"
            response += f"ü§ñ IA: {'üü¢ Op√©rationnelle' if VLM_AVAILABLE else 'üü° Mode d√©mo'}\n"
            response += f"üîä Audio: {'üü¢ Activ√©' if self.audio_config.enabled else 'üî¥ D√©sactiv√©'}\n"
            response += f"üìä Analyses: {video_count} disponibles\n\n"
            response += "‚úÖ Tous les syst√®mes fonctionnels"
        
        else:
            response = f"ü§ñ **Analyse de votre question:**\n\n"
            response += f"Votre question: *\"{question}\"*\n\n"
            response += f"üìä **Contexte disponible:**\n"
            response += f"- {camera_count} flux cam√©ra actifs\n" 
            response += f"- {video_count} analyses vid√©o stock√©es\n"
            response += f"- {alert_count} alertes en cours\n\n"
            response += "üí° *Posez des questions sp√©cifiques sur les risques, personnes, alertes ou l'√©tat du syst√®me.*"
        
        return {
            'content': response,
            'metadata': {
                'demo_mode': True,
                'confidence': 0.8,
                'context_items': video_count + camera_count + alert_count
            }
        }
    
    def _handle_detection(self, camera_id: str, frame) -> Dict[str, Any]:
        """Traite une d√©tection cam√©ra."""
        
        # Simulation d√©tection pour d√©mo
        import random
        
        if random.random() < 0.1:  # 10% chance de d√©tection
            confidence = random.uniform(0.6, 0.95)
            obj_type = random.choice(['personne', 'v√©hicule', 'objet'])
            
            return {
                'objects': [{
                    'type': obj_type,
                    'confidence': confidence,
                    'bbox': [100, 100, 200, 200]  # Exemple
                }],
                'timestamp': st.session_state.get('current_time', 0)
            }
        
        return {}
    
    def run(self):
        """Lance le dashboard principal."""
        
        # Configuration de la page
        st.set_page_config(
            page_title=self.config.page_title,
            layout=self.config.layout,
            initial_sidebar_state=self.config.initial_sidebar_state,
            page_icon="üîí"
        )
        
        # CSS personnalis√©
        self._apply_custom_css()
        
        # Sidebar de contr√¥le
        self._render_sidebar()
        
        # Contenu principal
        self._render_main_content()
        
        # Nettoyage √† la fermeture
        atexit.register(self._cleanup)
    
    def _apply_custom_css(self):
        """Applique le CSS personnalis√©."""
        
        st.markdown("""
        <style>
        .main-header {
            background: linear-gradient(90deg, #1f4e79, #2d5aa0);
            padding: 1rem;
            border-radius: 10px;
            color: white;
            margin-bottom: 2rem;
        }
        
        .metric-container {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 8px;
            border: 1px solid #dee2e6;
        }
        
        .alert-high {
            background-color: #ffebee;
            border-left: 4px solid #f44336;
            padding: 1rem;
            border-radius: 4px;
        }
        
        .alert-medium {
            background-color: #fff8e1;
            border-left: 4px solid #ff9800;
            padding: 1rem;
            border-radius: 4px;
        }
        
        .alert-low {
            background-color: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 1rem;
            border-radius: 4px;
        }
        
        .camera-cell {
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            padding: 0.5rem;
            margin: 0.25rem;
        }
        
        .camera-active {
            border-color: #4caf50;
        }
        
        .camera-inactive {
            border-color: #f44336;
        }
        </style>
        """, unsafe_allow_html=True)
    
    def _render_sidebar(self):
        """Affiche la sidebar de contr√¥le."""
        
        with st.sidebar:
            # En-t√™te
            st.markdown("""
            <div class="main-header">
                <h2>üîí Surveillance</h2>
                <p>Dashboard IA Avanc√©</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Contr√¥les globaux
            st.subheader("‚öôÔ∏è Contr√¥les")
            
            # Seuil d'alerte
            alert_threshold = st.slider(
                "Seuil d'alerte global",
                0, 100, 
                self.session.get_user_data('alert_threshold', 70),
                help="Sensibilit√© des alertes automatiques"
            )
            
            if alert_threshold != self.session.get_user_data('alert_threshold', 70):
                self.session.set_user_data('alert_threshold', alert_threshold)
            
            # Audio
            audio_enabled = st.checkbox(
                "üîä Sons d'alerte",
                self.audio_config.enabled
            )
            
            if audio_enabled != self.audio_config.enabled:
                self.audio_config.enabled = audio_enabled
            
            # Volume audio
            if audio_enabled:
                volume = st.slider(
                    "Volume",
                    0.0, 1.0,
                    self.audio_config.volume,
                    step=0.1
                )
                self.audio_config.volume = volume
            
            st.divider()
            
            # M√©triques syst√®me
            self._render_system_metrics()
            
            st.divider()
            
            # Actions rapides
            st.subheader("üöÄ Actions")
            
            if st.button("üß™ Test alerte", use_container_width=True):
                play_alert("MEDIUM", "Test du syst√®me d'alerte", force=True)
            
            if st.button("üìä Rapport syst√®me", use_container_width=True):
                self._generate_system_report()
            
            if st.button("üßπ Nettoyer session", use_container_width=True):
                self._cleanup_session()
                st.rerun()
    
    def _render_system_metrics(self):
        """Affiche les m√©triques syst√®me dans la sidebar."""
        
        st.subheader("üìä √âtat Syst√®me")
        
        # Cam√©ras
        camera_stats = self.camera_grid.get_camera_stats()
        active_cameras = sum(1 for stats in camera_stats.values() if stats['running'])
        
        st.metric("Cam√©ras actives", f"{active_cameras}/{len(camera_stats)}")
        
        # Alertes
        alerts = self.session.get_active_alerts()
        critical_alerts = len([a for a in alerts if a.get('level') == 'CRITICAL'])
        
        if critical_alerts > 0:
            st.metric("‚ö†Ô∏è Alertes critiques", critical_alerts, delta=critical_alerts)
        else:
            st.metric("Alertes actives", len(alerts))
        
        # Analyses VLM
        analyses = len(self.session.get_all_video_analyses())
        st.metric("Analyses VLM", analyses)
        
        # Messages chat
        chat_messages = len(self.session.get_chat_history())
        st.metric("Messages chat", chat_messages)
    
    def _render_main_content(self):
        """Affiche le contenu principal."""
        
        # En-t√™te principal
        st.markdown("""
        <div class="main-header">
            <h1>üîí Dashboard de Surveillance Intelligente</h1>
            <p>Surveillance automatis√©e avec IA - D√©tection comportementale avanc√©e</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Onglets principaux
        tab1, tab2, tab3, tab4 = st.tabs([
            "üìπ Surveillance Live", 
            "üì± Upload & Analyse", 
            "üí¨ Chat IA",
            "üìä Rapports"
        ])
        
        with tab1:
            self._render_live_surveillance()
        
        with tab2:
            self._render_video_analysis()
        
        with tab3:
            self._render_chat_interface()
        
        with tab4:
            self._render_reports()
    
    def _render_live_surveillance(self):
        """Onglet surveillance en temps r√©el."""
        
        st.subheader("üìπ Surveillance Multi-Cam√©ras")
        
        # Panneau de configuration des cam√©ras
        with st.expander("‚ûï Configuration des Cam√©ras", expanded=False):
            from components.camera_grid import render_camera_configuration_panel
            render_camera_configuration_panel()
        
        # Grille des cam√©ras
        st.subheader("üé• Flux en Direct")
        
        # Options d'affichage
        col1, col2, col3 = st.columns([2, 2, 1])
        
        with col1:
            grid_size = st.selectbox(
                "Grille d'affichage",
                ["2x2 (4 cam√©ras)", "3x3 (9 cam√©ras)", "4x4 (16 cam√©ras)"],
                index=0
            )
        
        with col2:
            auto_refresh = st.checkbox("üîÑ Actualisation auto", True)
            
        with col3:
            if st.button("üîÑ Actualiser"):
                st.rerun()
        
        # Conversion taille grille
        grid_map = {
            "2x2 (4 cam√©ras)": (2, 2),
            "3x3 (9 cam√©ras)": (3, 3),
            "4x4 (16 cam√©ras)": (4, 4)
        }
        
        selected_grid = grid_map[grid_size]
        
        # Affichage grille
        self.camera_grid.render_grid(selected_grid)
        
        # Alertes r√©centes
        self._render_recent_alerts()
    
    def _render_video_analysis(self):
        """Onglet analyse de vid√©os upload√©es."""
        
        st.subheader("üì± Analyse de Vid√©o")
        
        # Upload de fichier
        uploaded_file = st.file_uploader(
            "S√©lectionnez une vid√©o √† analyser",
            type=['mp4', 'avi', 'mov', 'mkv', 'webm'],
            help="Formats support√©s: MP4, AVI, MOV, MKV, WEBM"
        )
        
        if uploaded_file is not None:
            col1, col2 = st.columns([3, 2])
            
            with col1:
                st.subheader("üé¨ Vid√©o upload√©e")
                
                # Affichage vid√©o
                st.video(uploaded_file)
                
                # Options d'analyse
                with st.expander("‚öôÔ∏è Options d'analyse", expanded=True):
                    analyze_behavior = st.checkbox("üîç Analyse comportementale", True)
                    detect_objects = st.checkbox("üì¶ D√©tection d'objets", True)
                    track_movement = st.checkbox("üë• Suivi de mouvements", True)
                    
                    sensitivity = st.slider("Sensibilit√©", 0.0, 1.0, 0.7)
                
                # Bouton d'analyse
                if st.button("üöÄ Lancer l'analyse compl√®te", type="primary", use_container_width=True):
                    self._analyze_uploaded_video(uploaded_file, {
                        'behavior': analyze_behavior,
                        'objects': detect_objects,
                        'movement': track_movement,
                        'sensitivity': sensitivity
                    })
            
            with col2:
                st.subheader("üìä R√©sultats")
                
                # R√©sultats d'analyse
                video_id = f"video_{hash(uploaded_file.name)}"
                analysis = self.session.get_video_analysis(video_id)
                
                if analysis:
                    # M√©triques principales
                    confidence = analysis.get('confidence', 0)
                    suspicion = analysis.get('suspicion_level', 'LOW')
                    
                    col_a, col_b = st.columns(2)
                    
                    with col_a:
                        st.metric("Confiance", f"{confidence:.1%}")
                    
                    with col_b:
                        suspicion_colors = {
                            'LOW': 'üü¢',
                            'MEDIUM': 'üü°', 
                            'HIGH': 'üü†',
                            'CRITICAL': 'üî¥'
                        }
                        st.metric("Suspicion", f"{suspicion_colors.get(suspicion, '‚ö™')} {suspicion}")
                    
                    # D√©tails de l'analyse
                    st.subheader("üìã D√©tails")
                    st.json(analysis)
                    
                    # Export
                    if st.button("üíæ Exporter analyse", use_container_width=True):
                        self._export_analysis(analysis)
                
                else:
                    st.info("üéØ Lancez une analyse pour voir les r√©sultats")
    
    def _render_chat_interface(self):
        """Onglet interface de chat."""
        self.vlm_chat.render_chat_interface()
    
    def _render_reports(self):
        """Onglet rapports et statistiques."""
        
        st.subheader("üìä Rapports et Statistiques")
        
        # Statistiques de session
        session_stats = self.session.get_session_stats()
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Messages √©chang√©s", session_stats['chat_messages'])
        
        with col2:
            st.metric("Analyses vid√©o", session_stats['video_analyses'])
        
        with col3:
            st.metric("Alertes g√©n√©r√©es", session_stats['active_alerts'])
        
        with col4:
            st.metric("Cam√©ras configur√©es", session_stats['cameras_configured'])
        
        st.divider()
        
        # Export des donn√©es
        st.subheader("üíæ Export des donn√©es")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üìÑ Exporter session (JSON)", use_container_width=True):
                data = self.session.export_session_data('json')
                st.download_button(
                    "‚¨áÔ∏è T√©l√©charger JSON",
                    data,
                    file_name=f"session_{self.session.get_session_id()[:8]}.json",
                    mime="application/json"
                )
        
        with col2:
            if st.button("üí¨ Exporter chat (TXT)", use_container_width=True):
                data = self.vlm_chat.export_chat_history('txt')
                st.download_button(
                    "‚¨áÔ∏è T√©l√©charger TXT",
                    data,
                    file_name=f"chat_{self.session.get_session_id()[:8]}.txt",
                    mime="text/plain"
                )
        
        with col3:
            if st.button("üìä Rapport PDF", use_container_width=True):
                st.info("üöß G√©n√©ration PDF en d√©veloppement")
    
    def _render_recent_alerts(self):
        """Affiche les alertes r√©centes."""
        
        st.subheader("üö® Alertes R√©centes")
        
        alerts = self.session.get_active_alerts()
        
        if not alerts:
            st.success("‚úÖ Aucune alerte active")
            return
        
        # Affichage des alertes
        for alert in alerts[-5:]:  # 5 derni√®res
            level = alert.get('level', 'LOW')
            message = alert.get('message', 'N/A')
            timestamp = alert.get('timestamp', '')
            source = alert.get('source', 'system')
            
            # Couleur selon le niveau
            if level == 'CRITICAL':
                st.error(f"üî¥ **CRITIQUE** ({source}): {message}")
            elif level == 'HIGH':
                st.error(f"üü† **√âLEV√â** ({source}): {message}")
            elif level == 'MEDIUM':
                st.warning(f"üü° **MOYEN** ({source}): {message}")
            else:
                st.info(f"üîµ **FAIBLE** ({source}): {message}")
    
    def _analyze_uploaded_video(self, uploaded_file, options: Dict[str, Any]):
        """Analyse une vid√©o upload√©e."""
        
        with st.spinner("üîç Analyse en cours..."):
            try:
                # Simulation d'analyse (remplacer par vraie analyse)
                import time
                import random
                
                time.sleep(2)  # Simulation du temps d'analyse
                
                # G√©n√©ration r√©sultats simul√©s
                analysis_result = {
                    'video_name': uploaded_file.name,
                    'file_size': uploaded_file.size,
                    'analysis_options': options,
                    'confidence': random.uniform(0.7, 0.95),
                    'suspicion_level': random.choice(['LOW', 'MEDIUM', 'HIGH']),
                    'detected_objects': [
                        {'type': 'person', 'confidence': 0.92, 'count': random.randint(1, 5)},
                        {'type': 'vehicle', 'confidence': 0.78, 'count': random.randint(0, 2)}
                    ],
                    'behaviors': [
                        {'type': 'normal_walking', 'confidence': 0.89},
                        {'type': 'loitering', 'confidence': random.uniform(0.3, 0.7)}
                    ],
                    'timeline': [
                        {'time': '00:05', 'event': 'Personne entre dans le champ'},
                        {'time': '00:12', 'event': 'Mouvement vers la droite'},
                        {'time': '00:18', 'event': 'Arr√™t prolong√© d√©tect√©'}
                    ],
                    'analysis_time': 2.3,
                    'timestamp': st.session_state.get('current_time', time.time())
                }
                
                # Stockage de l'analyse
                video_id = f"video_{hash(uploaded_file.name)}"
                self.session.store_video_analysis(video_id, analysis_result)
                
                # Ajout message syst√®me au chat
                suspicion = analysis_result['suspicion_level']
                confidence = analysis_result['confidence']
                
                self.vlm_chat.add_system_message(
                    f"Analyse termin√©e: {uploaded_file.name} - Suspicion {suspicion} ({confidence:.1%} confiance)",
                    'success' if suspicion == 'LOW' else 'warning'
                )
                
                # Alerte audio si suspicion √©lev√©e
                if suspicion in ['HIGH', 'CRITICAL']:
                    play_alert(suspicion, f"Comportement suspect d√©tect√© dans {uploaded_file.name}")
                
                st.success("‚úÖ Analyse termin√©e avec succ√®s!")
                st.rerun()
                
            except Exception as e:
                st.error(f"‚ùå Erreur lors de l'analyse: {str(e)}")
    
    def _export_analysis(self, analysis: Dict[str, Any]):
        """Exporte une analyse."""
        
        import json
        data = json.dumps(analysis, indent=2, ensure_ascii=False)
        
        st.download_button(
            "üíæ T√©l√©charger analyse",
            data,
            file_name=f"analyse_{analysis.get('video_name', 'video')}.json",
            mime="application/json"
        )
    
    def _generate_system_report(self):
        """G√©n√®re un rapport syst√®me."""
        
        st.info("üìä G√©n√©ration du rapport syst√®me...")
        
        # TODO: Impl√©menter g√©n√©ration rapport complet
        report = {
            'timestamp': st.session_state.get('current_time', 0),
            'system_status': 'operational',
            'cameras': self.camera_grid.get_camera_stats(),
            'session': self.session.get_session_stats(),
            'audio': self.audio_system.get_status()
        }
        
        st.json(report)
    
    def _cleanup_session(self):
        """Nettoie la session."""
        
        self.session.clear_chat_history()
        self.session.clear_alerts()
        
        # R√©initialisation des caches
        self.session.cleanup_expired_data()
        
        st.success("üßπ Session nettoy√©e")
    
    def _cleanup(self):
        """Nettoyage √† la fermeture."""
        cleanup_camera_resources()

def main():
    """Point d'entr√©e principal."""
    
    try:
        dashboard = SurveillanceDashboard()
        dashboard.run()
        
    except Exception as e:
        st.error(f"‚ùå Erreur critique: {str(e)}")
        st.error("Veuillez red√©marrer l'application")

if __name__ == "__main__":
    main()