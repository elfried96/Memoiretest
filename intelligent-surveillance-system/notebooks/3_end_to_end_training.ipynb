{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "end_to_end_header"
      },
      "source": [
        "# üîÑ Entra√Ænement Complet End-to-End - Syst√®me de Surveillance\n",
        "\n",
        "Ce notebook pr√©sente l'entra√Ænement complet du syst√®me de surveillance intelligente, combinant :\n",
        "- Fine-tuning du mod√®le VLM (Vision-Language Model)\n",
        "- Transfer learning du d√©tecteur YOLO\n",
        "- Entra√Ænement du syst√®me de validation crois√©e\n",
        "- Int√©gration et optimisation compl√®te\n",
        "\n",
        "## üìã Plan d'Entra√Ænement\n",
        "1. **Pr√©paration des donn√©es** - Datasets multi-modaux\n",
        "2. **Entra√Ænement YOLO** - D√©tection d'objets surveillanc√©e\n",
        "3. **Fine-tuning VLM** - Analyse comportementale intelligente\n",
        "4. **Syst√®me de validation** - R√©duction des faux positifs\n",
        "5. **Int√©gration compl√®te** - Pipeline de production\n",
        "6. **√âvaluation & benchmarking** - M√©triques de performance\n",
        "\n",
        "## üéØ Objectifs de Performance\n",
        "- **Pr√©cision d√©tection**: >90%\n",
        "- **Faux positifs**: <3%\n",
        "- **Latence**: <1.5s par frame\n",
        "- **Concurrent streams**: >10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_cell"
      },
      "source": [
        "## üõ†Ô∏è Configuration et Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_dependencies"
      },
      "outputs": [],
      "source": [
        "# Installation des d√©pendances compl√®tes\n",
        "!pip install -q ultralytics transformers accelerate peft datasets\n",
        "!pip install -q opencv-python pillow matplotlib seaborn\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -q wandb tensorboard scikit-learn\n",
        "!pip install -q bitsandbytes scipy\n",
        "\n",
        "# Installation des utilitaires de tracking\n",
        "!pip install -q lapx motmetrics\n",
        "\n",
        "print(\"‚úÖ Installation termin√©e\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repository"
      },
      "outputs": [],
      "source": [
        "# Cloner le repository si n√©cessaire\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/intelligent-surveillance-system'):\n",
        "    !git clone https://github.com/your-username/intelligent-surveillance-system.git\n",
        "    os.chdir('/content/intelligent-surveillance-system')\n",
        "else:\n",
        "    os.chdir('/content/intelligent-surveillance-system')\n",
        "    !git pull origin main\n",
        "\n",
        "print(f\"üìÅ Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports_setup"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration path\n",
        "sys.path.append('/content/intelligent-surveillance-system/src')\n",
        "\n",
        "# Imports essentiels\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from dataclasses import dataclass, field\n",
        "import time\n",
        "import gc\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Imports surveillance system\n",
        "from core.types import Frame, DetectedObject, BoundingBox, SuspicionLevel\n",
        "from detection.yolo.detector import YOLODetector\n",
        "from core.vlm.model import VisionLanguageModel\n",
        "from validation.cross_validator import CrossValidator\n",
        "from utils.performance import PerformanceMonitor\n",
        "\n",
        "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
        "print(f\"üîß Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
        "print(f\"üîß CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"üîß GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\" if torch.cuda.is_available() else \"CPU Mode\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_preparation_header"
      },
      "source": [
        "## üìä 1. Pr√©paration Compl√®te des Donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset_config"
      },
      "outputs": [],
      "source": [
        "# Configuration des datasets\n",
        "@dataclass\n",
        "class DatasetConfig:\n",
        "    \"\"\"Configuration pour les datasets d'entra√Ænement.\"\"\"\n",
        "    base_path: str = \"/content/intelligent-surveillance-system/data/datasets\"\n",
        "    \n",
        "    # Datasets YOLO\n",
        "    yolo_images_train: str = field(default_factory=lambda: \"surveillance_detection/images/train\")\n",
        "    yolo_labels_train: str = field(default_factory=lambda: \"surveillance_detection/labels/train\")\n",
        "    yolo_images_val: str = field(default_factory=lambda: \"surveillance_detection/images/val\")\n",
        "    yolo_labels_val: str = field(default_factory=lambda: \"surveillance_detection/labels/val\")\n",
        "    \n",
        "    # Dataset VLM\n",
        "    vlm_images: str = field(default_factory=lambda: \"vlm_surveillance/images\")\n",
        "    vlm_conversations: str = field(default_factory=lambda: \"vlm_surveillance/conversations.json\")\n",
        "    \n",
        "    # Dataset comportemental\n",
        "    behavior_sequences: str = field(default_factory=lambda: \"behavior_analysis/sequences\")\n",
        "    behavior_annotations: str = field(default_factory=lambda: \"behavior_analysis/annotations\")\n",
        "    \n",
        "    # Param√®tres d'entra√Ænement\n",
        "    batch_size: int = 8  # Optimis√© pour Colab\n",
        "    num_workers: int = 2\n",
        "    train_split: float = 0.8\n",
        "    val_split: float = 0.15\n",
        "    test_split: float = 0.05\n",
        "\n",
        "config = DatasetConfig()\n",
        "print(\"üìã Configuration des donn√©es initialis√©e\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_datasets"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class DatasetManager:\n",
        "    \"\"\"Gestionnaire pour la cr√©ation et organisation des datasets.\"\"\"\n",
        "    \n",
        "    def __init__(self, config: DatasetConfig):\n",
        "        self.config = config\n",
        "        self.base_path = Path(config.base_path)\n",
        "        \n",
        "    def create_directory_structure(self):\n",
        "        \"\"\"Cr√©e la structure de r√©pertoires pour les datasets.\"\"\"\n",
        "        directories = [\n",
        "            \"surveillance_detection/images/train\",\n",
        "            \"surveillance_detection/images/val\", \n",
        "            \"surveillance_detection/images/test\",\n",
        "            \"surveillance_detection/labels/train\",\n",
        "            \"surveillance_detection/labels/val\",\n",
        "            \"surveillance_detection/labels/test\",\n",
        "            \"vlm_surveillance/images\",\n",
        "            \"behavior_analysis/sequences\",\n",
        "            \"behavior_analysis/annotations\",\n",
        "            \"synthetic/generated_scenes\",\n",
        "            \"synthetic/augmented_data\"\n",
        "        ]\n",
        "        \n",
        "        for directory in directories:\n",
        "            (self.base_path / directory).mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        print(\"‚úÖ Structure de r√©pertoires cr√©√©e\")\n",
        "    \n",
        "    def generate_synthetic_data(self, num_samples: int = 1000):\n",
        "        \"\"\"G√©n√®re des donn√©es synth√©tiques pour l'entra√Ænement.\"\"\"\n",
        "        print(f\"üé≠ G√©n√©ration de {num_samples} √©chantillons synth√©tiques...\")\n",
        "        \n",
        "        # Classes de surveillance\n",
        "        classes = {\n",
        "            0: \"person\", 1: \"handbag\", 2: \"backpack\", 3: \"suitcase\",\n",
        "            4: \"bottle\", 5: \"cup\", 6: \"cell_phone\", 7: \"book\"\n",
        "        }\n",
        "        \n",
        "        # G√©n√©ration d'images synth√©tiques\n",
        "        for i in tqdm(range(num_samples), desc=\"G√©n√©ration images\"):\n",
        "            # Cr√©ation d'une sc√®ne de magasin basique\n",
        "            image = self._create_store_scene(640, 640)\n",
        "            \n",
        "            # Ajout d'objets al√©atoirement\n",
        "            annotations = self._add_random_objects(image, classes)\n",
        "            \n",
        "            # Sauvegarde\n",
        "            split = \"train\" if i < num_samples * 0.8 else \"val\"\n",
        "            \n",
        "            image_path = self.base_path / f\"surveillance_detection/images/{split}/synthetic_{i:06d}.jpg\"\n",
        "            label_path = self.base_path / f\"surveillance_detection/labels/{split}/synthetic_{i:06d}.txt\"\n",
        "            \n",
        "            cv2.imwrite(str(image_path), image)\n",
        "            \n",
        "            # √âcriture des annotations YOLO\n",
        "            with open(label_path, 'w') as f:\n",
        "                for ann in annotations:\n",
        "                    f.write(f\"{ann['class_id']} {ann['x_center']} {ann['y_center']} {ann['width']} {ann['height']}\\n\")\n",
        "        \n",
        "        print(f\"‚úÖ {num_samples} √©chantillons synth√©tiques g√©n√©r√©s\")\n",
        "    \n",
        "    def _create_store_scene(self, width: int, height: int) -> np.ndarray:\n",
        "        \"\"\"Cr√©e une sc√®ne de magasin basique.\"\"\"\n",
        "        # Background basique avec d√©grad√©\n",
        "        image = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "        \n",
        "        # Couleur de fond (simulant un magasin)\n",
        "        background_color = np.random.randint(200, 255, 3)\n",
        "        image[:] = background_color\n",
        "        \n",
        "        # Ajout de \"rayons\" (rectangles)\n",
        "        for _ in range(np.random.randint(2, 5)):\n",
        "            x1, y1 = np.random.randint(0, width//2), np.random.randint(0, height//2)\n",
        "            x2, y2 = x1 + np.random.randint(50, 150), y1 + np.random.randint(100, 200)\n",
        "            color = np.random.randint(100, 200, 3)\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), color.tolist(), -1)\n",
        "        \n",
        "        return image\n",
        "    \n",
        "    def _add_random_objects(self, image: np.ndarray, classes: Dict[int, str]) -> List[Dict]:\n",
        "        \"\"\"Ajoute des objets al√©atoires √† l'image.\"\"\"\n",
        "        height, width = image.shape[:2]\n",
        "        annotations = []\n",
        "        \n",
        "        num_objects = np.random.randint(1, 4)\n",
        "        \n",
        "        for _ in range(num_objects):\n",
        "            class_id = np.random.choice(list(classes.keys()))\n",
        "            \n",
        "            # Dimensions al√©atoires\n",
        "            obj_width = np.random.randint(30, 100)\n",
        "            obj_height = np.random.randint(40, 150)\n",
        "            \n",
        "            # Position al√©atoire\n",
        "            x = np.random.randint(obj_width//2, width - obj_width//2)\n",
        "            y = np.random.randint(obj_height//2, height - obj_height//2)\n",
        "            \n",
        "            # Couleur al√©atoire pour l'objet\n",
        "            color = np.random.randint(0, 255, 3)\n",
        "            \n",
        "            # Dessiner l'objet (rectangle ou ellipse)\n",
        "            if np.random.random() > 0.5:\n",
        "                cv2.rectangle(image, \n",
        "                            (x - obj_width//2, y - obj_height//2),\n",
        "                            (x + obj_width//2, y + obj_height//2),\n",
        "                            color.tolist(), -1)\n",
        "            else:\n",
        "                cv2.ellipse(image, (x, y), (obj_width//2, obj_height//2), \n",
        "                           0, 0, 360, color.tolist(), -1)\n",
        "            \n",
        "            # Annotation YOLO (format normalis√©)\n",
        "            x_center = x / width\n",
        "            y_center = y / height\n",
        "            norm_width = obj_width / width\n",
        "            norm_height = obj_height / height\n",
        "            \n",
        "            annotations.append({\n",
        "                'class_id': class_id,\n",
        "                'x_center': x_center,\n",
        "                'y_center': y_center,\n",
        "                'width': norm_width,\n",
        "                'height': norm_height\n",
        "            })\n",
        "        \n",
        "        return annotations\n",
        "    \n",
        "    def create_vlm_conversations(self, num_conversations: int = 500):\n",
        "        \"\"\"Cr√©e des conversations d'entra√Ænement pour le VLM.\"\"\"\n",
        "        print(f\"üí¨ Cr√©ation de {num_conversations} conversations VLM...\")\n",
        "        \n",
        "        conversations = []\n",
        "        \n",
        "        # Templates de conversations\n",
        "        templates = [\n",
        "            {\n",
        "                \"human\": \"Analysez cette sc√®ne de surveillance. Y a-t-il des comportements suspects ?\",\n",
        "                \"assistant\": \"Je vois {objects} dans cette sc√®ne. Le comportement semble {behavior}. Niveau de suspicion: {suspicion_level}. Actions recommand√©es: {actions}.\"\n",
        "            },\n",
        "            {\n",
        "                \"human\": \"Utilisez les outils d'analyse pour √©valuer cette situation.\",\n",
        "                \"assistant\": \"Je vais analyser cette sc√®ne avec les outils appropri√©s. [TOOL_CALL: object_detector] Bas√© sur l'analyse, je recommande {recommendation}.\"\n",
        "            },\n",
        "            {\n",
        "                \"human\": \"D√©crivez ce que vous observez et votre √©valuation du risque.\",\n",
        "                \"assistant\": \"Observation: {observation}. √âvaluation du risque: {risk_assessment}. Mesures pr√©ventives: {preventive_measures}.\"\n",
        "            }\n",
        "        ]\n",
        "        \n",
        "        for i in tqdm(range(num_conversations), desc=\"Conversations VLM\"):\n",
        "            template = np.random.choice(templates)\n",
        "            \n",
        "            # Variables al√©atoires\n",
        "            objects = np.random.choice([\"une personne avec un sac\", \"plusieurs personnes\", \"une personne seule\", \"un groupe\"])\n",
        "            behavior = np.random.choice([\"normal\", \"suspect\", \"inhabituel\", \"pr√©occupant\"])\n",
        "            suspicion_level = np.random.choice([\"FAIBLE\", \"MOYEN\", \"√âLEV√â\"])\n",
        "            actions = np.random.choice([\"surveillance passive\", \"surveillance accrue\", \"intervention\"])\n",
        "            \n",
        "            # Remplacement des variables\n",
        "            assistant_response = template[\"assistant\"].format(\n",
        "                objects=objects,\n",
        "                behavior=behavior,\n",
        "                suspicion_level=suspicion_level,\n",
        "                actions=actions,\n",
        "                recommendation=\"surveillance continue\",\n",
        "                observation=f\"Pr√©sence de {objects}\",\n",
        "                risk_assessment=f\"Risque {suspicion_level.lower()}\",\n",
        "                preventive_measures=actions\n",
        "            )\n",
        "            \n",
        "            conversation = {\n",
        "                \"id\": f\"conv_{i:06d}\",\n",
        "                \"image\": f\"synthetic_{i % 1000:06d}.jpg\",\n",
        "                \"conversations\": [\n",
        "                    {\"from\": \"human\", \"value\": template[\"human\"]},\n",
        "                    {\"from\": \"gpt\", \"value\": assistant_response}\n",
        "                ],\n",
        "                \"metadata\": {\n",
        "                    \"store_zone\": np.random.choice([\"electronics\", \"clothing\", \"groceries\", \"pharmacy\"]),\n",
        "                    \"time_of_day\": np.random.choice([\"morning\", \"afternoon\", \"evening\"]),\n",
        "                    \"ground_truth\": behavior,\n",
        "                    \"tools_available\": [\"object_detector\", \"tracker\", \"behavior_analyzer\"]\n",
        "                }\n",
        "            }\n",
        "            \n",
        "            conversations.append(conversation)\n",
        "        \n",
        "        # Sauvegarde\n",
        "        conversations_path = self.base_path / \"vlm_surveillance/conversations.json\"\n",
        "        with open(conversations_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump({\"conversations\": conversations}, f, ensure_ascii=False, indent=2)\n",
        "        \n",
        "        print(f\"‚úÖ {num_conversations} conversations VLM cr√©√©es\")\n",
        "\n",
        "# Initialisation du gestionnaire de donn√©es\n",
        "dataset_manager = DatasetManager(config)\n",
        "dataset_manager.create_directory_structure()\n",
        "\n",
        "print(\"üìä Gestionnaire de donn√©es initialis√©\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_training_data"
      },
      "outputs": [],
      "source": [
        "# G√©n√©ration des donn√©es d'entra√Ænement\n",
        "print(\"üéØ G√©n√©ration des donn√©es d'entra√Ænement compl√®tes...\")\n",
        "\n",
        "# G√©n√©ration des donn√©es synth√©tiques\n",
        "dataset_manager.generate_synthetic_data(num_samples=2000)  # R√©duit pour Colab\n",
        "\n",
        "# Cr√©ation des conversations VLM\n",
        "dataset_manager.create_vlm_conversations(num_conversations=1000)\n",
        "\n",
        "# Cr√©ation du fichier dataset.yaml pour YOLO\n",
        "dataset_yaml = {\n",
        "    'path': str(config.base_path / \"surveillance_detection\"),\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'test': 'images/test',\n",
        "    'names': {\n",
        "        0: 'person', 1: 'handbag', 2: 'backpack', 3: 'suitcase',\n",
        "        4: 'bottle', 5: 'cup', 6: 'cell_phone', 7: 'book'\n",
        "    }\n",
        "}\n",
        "\n",
        "import yaml\n",
        "with open(config.base_path + '/surveillance_detection/dataset.yaml', 'w') as f:\n",
        "    yaml.dump(dataset_yaml, f, default_flow_style=False)\n",
        "\n",
        "print(\"‚úÖ Donn√©es d'entra√Ænement compl√®tes g√©n√©r√©es\")\n",
        "\n",
        "# V√©rification des datasets cr√©√©s\n",
        "train_images = len(list(Path(config.base_path + '/surveillance_detection/images/train').glob('*.jpg')))\n",
        "val_images = len(list(Path(config.base_path + '/surveillance_detection/images/val').glob('*.jpg')))\n",
        "print(f\"üìà Dataset YOLO: {train_images} images train, {val_images} images val\")\n",
        "\n",
        "with open(config.base_path + '/vlm_surveillance/conversations.json', 'r') as f:\n",
        "    vlm_data = json.load(f)\n",
        "print(f\"üí¨ Dataset VLM: {len(vlm_data['conversations'])} conversations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yolo_training_header"
      },
      "source": [
        "## üéØ 2. Entra√Ænement YOLO Surveillance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yolo_training_setup"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "class YOLOTrainingManager:\n",
        "    \"\"\"Gestionnaire pour l'entra√Ænement YOLO optimis√© surveillance.\"\"\"\n",
        "    \n",
        "    def __init__(self, dataset_config: DatasetConfig):\n",
        "        self.config = dataset_config\n",
        "        self.model = None\n",
        "        self.training_results = {}\n",
        "        \n",
        "    def setup_model(self, model_size: str = \"n\"):\n",
        "        \"\"\"Configure le mod√®le YOLO pour la surveillance.\"\"\"\n",
        "        model_name = f\"yolov8{model_size}.pt\"\n",
        "        print(f\"üöÄ Chargement du mod√®le {model_name}...\")\n",
        "        \n",
        "        self.model = YOLO(model_name)\n",
        "        \n",
        "        # Configuration sp√©ciale surveillance\n",
        "        self.training_config = {\n",
        "            'epochs': 50,  # R√©duit pour Colab\n",
        "            'batch': 16 if torch.cuda.is_available() else 8,\n",
        "            'imgsz': 640,\n",
        "            'device': 0 if torch.cuda.is_available() else 'cpu',\n",
        "            'workers': 2,\n",
        "            'patience': 10,\n",
        "            'save': True,\n",
        "            'cache': 'ram' if torch.cuda.is_available() else False,\n",
        "            'project': 'surveillance_training',\n",
        "            'name': 'yolo_surveillance_v1',\n",
        "            \n",
        "            # Optimisations surveillance\n",
        "            'cls': 1.0,      # Classification loss weight\n",
        "            'box': 7.5,      # Box regression loss weight  \n",
        "            'dfl': 1.5,      # DFL loss weight\n",
        "            'pose': 12.0,    # Pose loss weight\n",
        "            'kobj': 1.0,     # Keypoint objectness loss weight\n",
        "            'label_smoothing': 0.0,\n",
        "            'nbs': 64,       # Nominal batch size\n",
        "            'overlap_mask': True,\n",
        "            'mask_ratio': 4,\n",
        "            'dropout': 0.0,\n",
        "            'val': True,\n",
        "            'plots': True,\n",
        "            'verbose': True\n",
        "        }\n",
        "        \n",
        "        print(f\"‚úÖ Mod√®le configur√© avec {len(self.training_config)} param√®tres\")\n",
        "        return self.model\n",
        "    \n",
        "    def train(self, data_yaml_path: str):\n",
        "        \"\"\"Lance l'entra√Ænement YOLO.\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Mod√®le non configur√©. Appelez setup_model() d'abord.\")\n",
        "        \n",
        "        print(\"üèãÔ∏è‚Äç‚ôÇÔ∏è D√©marrage de l'entra√Ænement YOLO...\")\n",
        "        print(f\"üìä Dataset: {data_yaml_path}\")\n",
        "        print(f\"‚öôÔ∏è Configuration: {self.training_config['epochs']} epochs, batch size {self.training_config['batch']}\")\n",
        "        \n",
        "        # Entra√Ænement\n",
        "        results = self.model.train(\n",
        "            data=data_yaml_path,\n",
        "            **self.training_config\n",
        "        )\n",
        "        \n",
        "        self.training_results['yolo'] = results\n",
        "        print(\"‚úÖ Entra√Ænement YOLO termin√©\")\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def validate_model(self):\n",
        "        \"\"\"Valide le mod√®le entra√Æn√©.\"\"\"\n",
        "        print(\"üîç Validation du mod√®le YOLO...\")\n",
        "        \n",
        "        # Validation\n",
        "        validation_results = self.model.val()\n",
        "        \n",
        "        # Extraction des m√©triques\n",
        "        metrics = {\n",
        "            'mAP50': validation_results.box.map50,\n",
        "            'mAP50-95': validation_results.box.map,\n",
        "            'precision': validation_results.box.mp,\n",
        "            'recall': validation_results.box.mr,\n",
        "            'fitness': validation_results.fitness\n",
        "        }\n",
        "        \n",
        "        print(\"üìä M√©triques de validation:\")\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"  {metric}: {value:.4f}\")\n",
        "        \n",
        "        self.training_results['validation'] = metrics\n",
        "        return metrics\n",
        "    \n",
        "    def export_model(self, formats: List[str] = ['onnx', 'torchscript']):\n",
        "        \"\"\"Exporte le mod√®le dans diff√©rents formats.\"\"\"\n",
        "        print(f\"üì¶ Export du mod√®le en {formats}...\")\n",
        "        \n",
        "        export_results = {}\n",
        "        \n",
        "        for format_type in formats:\n",
        "            try:\n",
        "                if format_type == 'onnx':\n",
        "                    export_path = self.model.export(format='onnx')\n",
        "                elif format_type == 'torchscript':\n",
        "                    export_path = self.model.export(format='torchscript')\n",
        "                elif format_type == 'tflite':\n",
        "                    export_path = self.model.export(format='tflite')\n",
        "                \n",
        "                export_results[format_type] = export_path\n",
        "                print(f\"  ‚úÖ {format_type.upper()}: {export_path}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå Erreur export {format_type}: {e}\")\n",
        "                export_results[format_type] = None\n",
        "        \n",
        "        self.training_results['exports'] = export_results\n",
        "        return export_results\n",
        "\n",
        "# Initialisation du gestionnaire d'entra√Ænement YOLO\n",
        "yolo_trainer = YOLOTrainingManager(config)\n",
        "print(\"üéØ Gestionnaire d'entra√Ænement YOLO initialis√©\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yolo_train_execute"
      },
      "outputs": [],
      "source": [
        "# Configuration et entra√Ænement du mod√®le YOLO\n",
        "model_size = \"n\"  # nano pour Colab (plus rapide)\n",
        "yolo_model = yolo_trainer.setup_model(model_size=model_size)\n",
        "\n",
        "# Chemin vers le dataset YOLO\n",
        "dataset_yaml_path = str(Path(config.base_path) / \"surveillance_detection/dataset.yaml\")\n",
        "\n",
        "print(f\"üìã Dataset YAML: {dataset_yaml_path}\")\n",
        "print(f\"üîß Utilisation GPU: {torch.cuda.is_available()}\")\n",
        "print(f\"‚ö° M√©moire GPU disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\" if torch.cuda.is_available() else \"Mode CPU\")\n",
        "\n",
        "# Lancement de l'entra√Ænement\n",
        "try:\n",
        "    yolo_results = yolo_trainer.train(dataset_yaml_path)\n",
        "    print(\"üèÜ Entra√Ænement YOLO r√©ussi!\")\n",
        "    \n",
        "    # Validation\n",
        "    validation_metrics = yolo_trainer.validate_model()\n",
        "    \n",
        "    # Export en diff√©rents formats\n",
        "    export_results = yolo_trainer.export_model(['onnx', 'torchscript'])\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erreur lors de l'entra√Ænement YOLO: {e}\")\n",
        "    # Mode de r√©cup√©ration avec un mod√®le pr√©-entra√Æn√©\n",
        "    print(\"üîÑ Utilisation du mod√®le pr√©-entra√Æn√©...\")\n",
        "    yolo_model = YOLO('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlm_training_header"
      },
      "source": [
        "## üß† 3. Fine-tuning VLM pour Surveillance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlm_training_setup"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer, AutoProcessor, AutoModelForCausalLM,\n",
        "    TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
        "from datasets import Dataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class VLMTrainingManager:\n",
        "    \"\"\"Gestionnaire pour le fine-tuning du VLM.\"\"\"\n",
        "    \n",
        "    def __init__(self, dataset_config: DatasetConfig):\n",
        "        self.config = dataset_config\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.processor = None\n",
        "        self.training_results = {}\n",
        "        \n",
        "    def setup_model(self, model_name: str = \"llava-hf/llava-1.5-7b-hf\"):\n",
        "        \"\"\"Configure le mod√®le VLM avec LoRA.\"\"\"\n",
        "        print(f\"üß† Chargement du mod√®le VLM {model_name}...\")\n",
        "        \n",
        "        # Chargement avec quantization pour √©conomiser la m√©moire\n",
        "        from transformers import BitsAndBytesConfig\n",
        "        \n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "        )\n",
        "        \n",
        "        try:\n",
        "            # Mod√®le principal\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_name,\n",
        "                quantization_config=quantization_config,\n",
        "                device_map=\"auto\",\n",
        "                trust_remote_code=True,\n",
        "                torch_dtype=torch.float16\n",
        "            )\n",
        "            \n",
        "            # Tokenizer et processeur\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "            self.processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\n",
        "            \n",
        "            # Configuration des tokens sp√©ciaux\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erreur chargement {model_name}: {e}\")\n",
        "            print(\"üîÑ Utilisation mod√®le alternatif...\")\n",
        "            \n",
        "            # Mod√®le alternatif plus l√©ger\n",
        "            model_name = \"microsoft/DialoGPT-medium\"\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_name,\n",
        "                quantization_config=quantization_config,\n",
        "                device_map=\"auto\"\n",
        "            )\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "        \n",
        "        # Configuration LoRA\n",
        "        lora_config = LoraConfig(\n",
        "            r=16,\n",
        "            lora_alpha=32,\n",
        "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
        "            lora_dropout=0.1,\n",
        "            bias=\"none\",\n",
        "            task_type=TaskType.CAUSAL_LM,\n",
        "        )\n",
        "        \n",
        "        # Pr√©paration du mod√®le pour l'entra√Ænement\n",
        "        self.model = prepare_model_for_kbit_training(self.model)\n",
        "        self.model = get_peft_model(self.model, lora_config)\n",
        "        \n",
        "        print(f\"‚úÖ Mod√®le VLM configur√© avec LoRA\")\n",
        "        self.model.print_trainable_parameters()\n",
        "        \n",
        "        return self.model\n",
        "    \n",
        "    def prepare_dataset(self, conversations_path: str):\n",
        "        \"\"\"Pr√©pare le dataset pour l'entra√Ænement.\"\"\"\n",
        "        print(f\"üìä Pr√©paration du dataset: {conversations_path}\")\n",
        "        \n",
        "        # Chargement des conversations\n",
        "        with open(conversations_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        \n",
        "        conversations = data['conversations']\n",
        "        print(f\"üí¨ {len(conversations)} conversations charg√©es\")\n",
        "        \n",
        "        # Formatage des conversations\n",
        "        formatted_data = []\n",
        "        \n",
        "        for conv in tqdm(conversations, desc=\"Formatage conversations\"):\n",
        "            conversation_text = \"\"\n",
        "            \n",
        "            for msg in conv['conversations']:\n",
        "                if msg['from'] == 'human':\n",
        "                    conversation_text += f\"Human: {msg['value']}\\n\"\n",
        "                elif msg['from'] == 'gpt':\n",
        "                    conversation_text += f\"Assistant: {msg['value']}\\n\"\n",
        "            \n",
        "            formatted_data.append({\n",
        "                'text': conversation_text,\n",
        "                'metadata': conv.get('metadata', {})\n",
        "            })\n",
        "        \n",
        "        # Tokenization\n",
        "        def tokenize_function(examples):\n",
        "            return self.tokenizer(\n",
        "                examples['text'],\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=512,  # R√©duit pour √©conomiser la m√©moire\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "        \n",
        "        # Cr√©ation du dataset HuggingFace\n",
        "        dataset = Dataset.from_list(formatted_data)\n",
        "        tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "        \n",
        "        # Split train/val\n",
        "        train_size = int(0.9 * len(tokenized_dataset))\n",
        "        val_size = len(tokenized_dataset) - train_size\n",
        "        \n",
        "        train_dataset = tokenized_dataset.select(range(train_size))\n",
        "        val_dataset = tokenized_dataset.select(range(train_size, train_size + val_size))\n",
        "        \n",
        "        print(f\"üìà Dataset pr√©par√©: {len(train_dataset)} train, {len(val_dataset)} val\")\n",
        "        \n",
        "        return train_dataset, val_dataset\n",
        "    \n",
        "    def train(self, train_dataset, val_dataset, output_dir: str = \"./vlm_surveillance_model\"):\n",
        "        \"\"\"Lance l'entra√Ænement du VLM.\"\"\"\n",
        "        print(\"üèãÔ∏è‚Äç‚ôÇÔ∏è D√©marrage du fine-tuning VLM...\")\n",
        "        \n",
        "        # Configuration de l'entra√Ænement\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=output_dir,\n",
        "            num_train_epochs=3,  # R√©duit pour Colab\n",
        "            per_device_train_batch_size=2,  # Tr√®s petit pour √©conomiser la m√©moire\n",
        "            per_device_eval_batch_size=2,\n",
        "            gradient_accumulation_steps=8,  # Compense la petite batch size\n",
        "            warmup_steps=100,\n",
        "            logging_steps=10,\n",
        "            eval_steps=100,\n",
        "            save_steps=500,\n",
        "            evaluation_strategy=\"steps\",\n",
        "            save_strategy=\"steps\",\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"eval_loss\",\n",
        "            greater_is_better=False,\n",
        "            dataloader_pin_memory=False,\n",
        "            dataloader_num_workers=0,\n",
        "            fp16=True,  # Pr√©cision mixte\n",
        "            gradient_checkpointing=True,  # √âconomise la m√©moire\n",
        "            report_to=None,  # Pas de logging externe\n",
        "            remove_unused_columns=False,\n",
        "        )\n",
        "        \n",
        "        # Data collator\n",
        "        data_collator = DataCollatorForLanguageModeling(\n",
        "            tokenizer=self.tokenizer,\n",
        "            mlm=False  # Causal LM\n",
        "        )\n",
        "        \n",
        "        # Trainer\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            data_collator=data_collator,\n",
        "        )\n",
        "        \n",
        "        # Entra√Ænement\n",
        "        print(\"üöÄ Lancement de l'entra√Ænement...\")\n",
        "        training_result = trainer.train()\n",
        "        \n",
        "        # Sauvegarde\n",
        "        trainer.save_model(output_dir)\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "        \n",
        "        self.training_results['vlm'] = training_result\n",
        "        print(\"‚úÖ Fine-tuning VLM termin√©\")\n",
        "        \n",
        "        return training_result\n",
        "\n",
        "# Initialisation du gestionnaire VLM\n",
        "vlm_trainer = VLMTrainingManager(config)\n",
        "print(\"üß† Gestionnaire d'entra√Ænement VLM initialis√©\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlm_train_execute"
      },
      "outputs": [],
      "source": [
        "# Configuration et fine-tuning du VLM\n",
        "print(\"üß† Configuration du mod√®le VLM...\")\n",
        "\n",
        "try:\n",
        "    # Setup du mod√®le (avec fallback sur un mod√®le plus l√©ger si n√©cessaire)\n",
        "    vlm_model = vlm_trainer.setup_model()\n",
        "    \n",
        "    # Pr√©paration du dataset\n",
        "    conversations_path = str(Path(config.base_path) / \"vlm_surveillance/conversations.json\")\n",
        "    train_dataset, val_dataset = vlm_trainer.prepare_dataset(conversations_path)\n",
        "    \n",
        "    # Nettoyage m√©moire avant entra√Ænement\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    print(f\"üíæ M√©moire GPU utilis√©e: {torch.cuda.memory_allocated() / 1e9:.1f} GB\" if torch.cuda.is_available() else \"Mode CPU\")\n",
        "    \n",
        "    # Lancement du fine-tuning\n",
        "    vlm_results = vlm_trainer.train(train_dataset, val_dataset)\n",
        "    \n",
        "    print(\"üèÜ Fine-tuning VLM r√©ussi!\")\n",
        "    print(f\"üìä Loss finale: {vlm_results.training_loss:.4f}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erreur lors du fine-tuning VLM: {e}\")\n",
        "    print(\"üîÑ Utilisation du mod√®le VLM pr√©-configur√© pour la suite...\")\n",
        "    \n",
        "    # Fallback vers un mod√®le pr√©-configur√©\n",
        "    vlm_trainer.training_results['vlm'] = {'status': 'fallback_used'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "validation_training_header"
      },
      "source": [
        "## ‚úÖ 4. Entra√Ænement du Syst√®me de Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validation_system_setup"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "class ValidationSystemTrainer:\n",
        "    \"\"\"Gestionnaire pour l'entra√Ænement du syst√®me de validation crois√©e.\"\"\"\n",
        "    \n",
        "    def __init__(self, dataset_config: DatasetConfig):\n",
        "        self.config = dataset_config\n",
        "        self.models = {}\n",
        "        self.scalers = {}\n",
        "        self.training_results = {}\n",
        "        \n",
        "    def generate_validation_features(self, num_samples: int = 5000):\n",
        "        \"\"\"G√©n√®re des caract√©ristiques pour l'entra√Ænement du validateur.\"\"\"\n",
        "        print(f\"üîç G√©n√©ration de {num_samples} √©chantillons de validation...\")\n",
        "        \n",
        "        # Caract√©ristiques simul√©es bas√©es sur des d√©tections r√©elles\n",
        "        features = []\n",
        "        labels = []  # 0: Normal, 1: Faux positif\n",
        "        \n",
        "        for i in tqdm(range(num_samples), desc=\"G√©n√©ration features\"):\n",
        "            # Simulation d'une d√©tection\n",
        "            feature_vector = {\n",
        "                # M√©triques de d√©tection\n",
        "                'detection_confidence': np.random.uniform(0.1, 0.95),\n",
        "                'bbox_area': np.random.uniform(0.01, 0.3),\n",
        "                'bbox_aspect_ratio': np.random.uniform(0.3, 3.0),\n",
        "                'center_distance': np.random.uniform(0.0, 1.0),\n",
        "                \n",
        "                # M√©triques temporelles\n",
        "                'track_length': np.random.randint(1, 50),\n",
        "                'velocity_magnitude': np.random.uniform(0.0, 0.1),\n",
        "                'direction_consistency': np.random.uniform(0.0, 1.0),\n",
        "                'temporal_stability': np.random.uniform(0.5, 1.0),\n",
        "                \n",
        "                # M√©triques contextuelles\n",
        "                'scene_complexity': np.random.uniform(0.1, 1.0),\n",
        "                'lighting_quality': np.random.uniform(0.3, 1.0),\n",
        "                'occlusion_level': np.random.uniform(0.0, 0.8),\n",
        "                'crowd_density': np.random.uniform(0.0, 1.0),\n",
        "                \n",
        "                # M√©triques multi-mod√®les\n",
        "                'model_agreement': np.random.uniform(0.0, 1.0),\n",
        "                'vlm_confidence': np.random.uniform(0.0, 1.0),\n",
        "                'behavior_score': np.random.uniform(0.0, 1.0),\n",
        "            }\n",
        "            \n",
        "            # Logique pour d√©terminer si c'est un faux positif\n",
        "            # R√®gles heuristiques bas√©es sur l'exp√©rience\n",
        "            is_false_positive = (\n",
        "                feature_vector['detection_confidence'] < 0.3 or\n",
        "                feature_vector['bbox_area'] < 0.02 or\n",
        "                feature_vector['track_length'] < 3 or\n",
        "                feature_vector['model_agreement'] < 0.4 or\n",
        "                (feature_vector['occlusion_level'] > 0.7 and feature_vector['lighting_quality'] < 0.5)\n",
        "            )\n",
        "            \n",
        "            # Ajout de bruit pour plus de r√©alisme\n",
        "            if np.random.random() < 0.1:  # 10% de bruit\n",
        "                is_false_positive = not is_false_positive\n",
        "            \n",
        "            features.append(list(feature_vector.values()))\n",
        "            labels.append(int(is_false_positive))\n",
        "        \n",
        "        # Conversion en arrays\n",
        "        X = np.array(features)\n",
        "        y = np.array(labels)\n",
        "        \n",
        "        # Noms des features pour l'interpr√©tation\n",
        "        feature_names = list(feature_vector.keys())\n",
        "        \n",
        "        print(f\"‚úÖ Features g√©n√©r√©es: {X.shape}\")\n",
        "        print(f\"üìä Distribution des labels: {np.bincount(y)} (0: Normal, 1: Faux positif)\")\n",
        "        \n",
        "        return X, y, feature_names\n",
        "    \n",
        "    def train_validation_models(self, X, y, feature_names):\n",
        "        \"\"\"Entra√Æne plusieurs mod√®les de validation.\"\"\"\n",
        "        print(\"ü§ñ Entra√Ænement des mod√®les de validation...\")\n",
        "        \n",
        "        # Split des donn√©es\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "        \n",
        "        # Normalisation des features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "        \n",
        "        self.scalers['main'] = scaler\n",
        "        \n",
        "        # Mod√®les √† entra√Æner\n",
        "        models_config = {\n",
        "            'random_forest': RandomForestClassifier(\n",
        "                n_estimators=100,\n",
        "                max_depth=10,\n",
        "                random_state=42,\n",
        "                class_weight='balanced'\n",
        "            ),\n",
        "            'gradient_boosting': GradientBoostingClassifier(\n",
        "                n_estimators=100,\n",
        "                learning_rate=0.1,\n",
        "                max_depth=6,\n",
        "                random_state=42\n",
        "            ),\n",
        "            'logistic_regression': LogisticRegression(\n",
        "                random_state=42,\n",
        "                class_weight='balanced',\n",
        "                max_iter=1000\n",
        "            )\n",
        "        }\n",
        "        \n",
        "        results = {}\n",
        "        \n",
        "        for model_name, model in models_config.items():\n",
        "            print(f\"üîß Entra√Ænement {model_name}...\")\n",
        "            \n",
        "            # Entra√Ænement\n",
        "            if model_name == 'logistic_regression':\n",
        "                model.fit(X_train_scaled, y_train)\n",
        "                y_pred = model.predict(X_test_scaled)\n",
        "                y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "            else:\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred = model.predict(X_test)\n",
        "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "            \n",
        "            # √âvaluation\n",
        "            report = classification_report(y_test, y_pred, output_dict=True)\n",
        "            auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "            \n",
        "            results[model_name] = {\n",
        "                'model': model,\n",
        "                'classification_report': report,\n",
        "                'auc_score': auc_score,\n",
        "                'confusion_matrix': confusion_matrix(y_test, y_pred).tolist()\n",
        "            }\n",
        "            \n",
        "            print(f\"  üìä Accuracy: {report['accuracy']:.3f}\")\n",
        "            print(f\"  üìä AUC: {auc_score:.3f}\")\n",
        "            print(f\"  üìä Precision (FP): {report['1']['precision']:.3f}\")\n",
        "            print(f\"  üìä Recall (FP): {report['1']['recall']:.3f}\")\n",
        "        \n",
        "        self.models = {name: result['model'] for name, result in results.items()}\n",
        "        self.training_results['validation_models'] = results\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def save_models(self, output_dir: str = \"./validation_models\"):\n",
        "        \"\"\"Sauvegarde les mod√®les entra√Æn√©s.\"\"\"\n",
        "        output_path = Path(output_dir)\n",
        "        output_path.mkdir(exist_ok=True)\n",
        "        \n",
        "        print(f\"üíæ Sauvegarde des mod√®les dans {output_dir}...\")\n",
        "        \n",
        "        # Sauvegarde des mod√®les\n",
        "        for name, model in self.models.items():\n",
        "            model_path = output_path / f\"{name}_model.joblib\"\n",
        "            joblib.dump(model, model_path)\n",
        "            print(f\"  ‚úÖ {name}: {model_path}\")\n",
        "        \n",
        "        # Sauvegarde des scalers\n",
        "        for name, scaler in self.scalers.items():\n",
        "            scaler_path = output_path / f\"{name}_scaler.joblib\"\n",
        "            joblib.dump(scaler, scaler_path)\n",
        "            print(f\"  ‚úÖ {name} scaler: {scaler_path}\")\n",
        "        \n",
        "        # Sauvegarde des r√©sultats\n",
        "        results_path = output_path / \"training_results.json\"\n",
        "        with open(results_path, 'w') as f:\n",
        "            # Conversion des mod√®les en strings pour JSON\n",
        "            serializable_results = {}\n",
        "            for name, result in self.training_results['validation_models'].items():\n",
        "                serializable_results[name] = {\n",
        "                    'classification_report': result['classification_report'],\n",
        "                    'auc_score': result['auc_score'],\n",
        "                    'confusion_matrix': result['confusion_matrix']\n",
        "                }\n",
        "            json.dump(serializable_results, f, indent=2)\n",
        "        \n",
        "        print(f\"‚úÖ Mod√®les sauvegard√©s dans {output_dir}\")\n",
        "\n",
        "# Initialisation du gestionnaire de validation\n",
        "validation_trainer = ValidationSystemTrainer(config)\n",
        "print(\"‚úÖ Gestionnaire d'entra√Ænement de validation initialis√©\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validation_train_execute"
      },
      "outputs": [],
      "source": [
        "# Entra√Ænement du syst√®me de validation\n",
        "print(\"‚úÖ G√©n√©ration et entra√Ænement du syst√®me de validation...\")\n",
        "\n",
        "# G√©n√©ration des features de validation\n",
        "X, y, feature_names = validation_trainer.generate_validation_features(num_samples=3000)\n",
        "\n",
        "# Entra√Ænement des mod√®les de validation\n",
        "validation_results = validation_trainer.train_validation_models(X, y, feature_names)\n",
        "\n",
        "# Sauvegarde des mod√®les\n",
        "validation_trainer.save_models(\"./validation_models\")\n",
        "\n",
        "# Affichage des performances\n",
        "print(\"\\nüìä R√©sum√© des performances des mod√®les de validation:\")\n",
        "for model_name, results in validation_results.items():\n",
        "    print(f\"\\nü§ñ {model_name.upper()}:\")\n",
        "    print(f\"  ‚Ä¢ Accuracy: {results['classification_report']['accuracy']:.3f}\")\n",
        "    print(f\"  ‚Ä¢ AUC: {results['auc_score']:.3f}\")\n",
        "    print(f\"  ‚Ä¢ Precision (FP): {results['classification_report']['1']['precision']:.3f}\")\n",
        "    print(f\"  ‚Ä¢ Recall (FP): {results['classification_report']['1']['recall']:.3f}\")\n",
        "    print(f\"  ‚Ä¢ F1-Score (FP): {results['classification_report']['1']['f1-score']:.3f}\")\n",
        "\n",
        "print(\"\\n‚úÖ Entra√Ænement du syst√®me de validation termin√©!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "integration_header"
      },
      "source": [
        "## üîó 5. Int√©gration et Pipeline Complet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "complete_pipeline_setup"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import threading\n",
        "from queue import Queue, Empty\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Optional, Callable\n",
        "\n",
        "@dataclass\n",
        "class PipelineConfig:\n",
        "    \"\"\"Configuration pour le pipeline complet.\"\"\"\n",
        "    max_concurrent_streams: int = 4  # R√©duit pour Colab\n",
        "    frame_buffer_size: int = 100\n",
        "    detection_threshold: float = 0.25\n",
        "    validation_threshold: float = 0.7\n",
        "    max_processing_time: float = 2.0  # secondes\n",
        "    enable_gpu_acceleration: bool = torch.cuda.is_available()\n",
        "    save_alerts: bool = True\n",
        "    alert_callback: Optional[Callable] = None\n",
        "\n",
        "class CompleteSurveillancePipeline:\n",
        "    \"\"\"Pipeline complet de surveillance intelligente.\"\"\"\n",
        "    \n",
        "    def __init__(self, pipeline_config: PipelineConfig):\n",
        "        self.config = pipeline_config\n",
        "        self.is_running = False\n",
        "        self.stats = {\n",
        "            'frames_processed': 0,\n",
        "            'detections_made': 0,\n",
        "            'alerts_generated': 0,\n",
        "            'false_positives_filtered': 0,\n",
        "            'average_processing_time': 0.0,\n",
        "            'gpu_memory_usage': 0.0\n",
        "        }\n",
        "        \n",
        "        # Components\n",
        "        self.yolo_detector = None\n",
        "        self.vlm_model = None\n",
        "        self.validation_models = {}\n",
        "        self.performance_monitor = PerformanceMonitor()\n",
        "        \n",
        "        # Threading\n",
        "        self.frame_queue = Queue(maxsize=self.config.frame_buffer_size)\n",
        "        self.result_queue = Queue()\n",
        "        self.worker_threads = []\n",
        "        \n",
        "    def initialize_components(self):\n",
        "        \"\"\"Initialise tous les composants du pipeline.\"\"\"\n",
        "        print(\"üöÄ Initialisation du pipeline complet...\")\n",
        "        \n",
        "        try:\n",
        "            # D√©tecteur YOLO\n",
        "            print(\"üéØ Initialisation d√©tecteur YOLO...\")\n",
        "            self.yolo_detector = YOLODetector(\n",
        "                model_path=\"yolov8n.pt\",  # Mod√®le entra√Æn√© ou pr√©-entra√Æn√©\n",
        "                device=\"cuda\" if self.config.enable_gpu_acceleration else \"cpu\",\n",
        "                confidence_threshold=self.config.detection_threshold\n",
        "            )\n",
        "            self.yolo_detector.load_model()\n",
        "            \n",
        "            # VLM (si disponible)\n",
        "            print(\"üß† Initialisation VLM...\")\n",
        "            if hasattr(vlm_trainer, 'model') and vlm_trainer.model is not None:\n",
        "                self.vlm_model = vlm_trainer.model\n",
        "                print(\"  ‚úÖ VLM fine-tun√© charg√©\")\n",
        "            else:\n",
        "                print(\"  ‚ö†Ô∏è VLM non disponible, utilisation des r√®gles heuristiques\")\n",
        "            \n",
        "            # Mod√®les de validation\n",
        "            print(\"‚úÖ Chargement mod√®les de validation...\")\n",
        "            if hasattr(validation_trainer, 'models'):\n",
        "                self.validation_models = validation_trainer.models\n",
        "                self.validation_scaler = validation_trainer.scalers.get('main')\n",
        "                print(f\"  ‚úÖ {len(self.validation_models)} mod√®les de validation charg√©s\")\n",
        "            \n",
        "            print(\"‚úÖ Pipeline complet initialis√©\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erreur initialisation pipeline: {e}\")\n",
        "            raise\n",
        "    \n",
        "    def extract_validation_features(self, frame, detections):\n",
        "        \"\"\"Extrait les features pour la validation.\"\"\"\n",
        "        if not detections:\n",
        "            return np.array([])\n",
        "        \n",
        "        features_list = []\n",
        "        \n",
        "        for detection in detections:\n",
        "            # Calcul des features de base\n",
        "            bbox = detection.bbox\n",
        "            area = bbox.width * bbox.height\n",
        "            aspect_ratio = bbox.width / bbox.height if bbox.height > 0 else 1.0\n",
        "            \n",
        "            # Center distance (distance du centre de l'image)\n",
        "            center_x = bbox.x + bbox.width / 2\n",
        "            center_y = bbox.y + bbox.height / 2\n",
        "            center_distance = np.sqrt(\n",
        "                (center_x - 0.5)**2 + (center_y - 0.5)**2\n",
        "            )\n",
        "            \n",
        "            # Features simul√©es (dans un vrai syst√®me, elles viendraient du tracking)\n",
        "            features = [\n",
        "                detection.confidence,  # detection_confidence\n",
        "                area,                  # bbox_area\n",
        "                aspect_ratio,         # bbox_aspect_ratio\n",
        "                center_distance,      # center_distance\n",
        "                np.random.randint(5, 30),      # track_length (simul√©)\n",
        "                np.random.uniform(0.0, 0.05),  # velocity_magnitude (simul√©)\n",
        "                np.random.uniform(0.7, 1.0),   # direction_consistency (simul√©)\n",
        "                np.random.uniform(0.8, 1.0),   # temporal_stability (simul√©)\n",
        "                np.random.uniform(0.3, 0.8),   # scene_complexity (simul√©)\n",
        "                np.random.uniform(0.5, 1.0),   # lighting_quality (simul√©)\n",
        "                np.random.uniform(0.0, 0.5),   # occlusion_level (simul√©)\n",
        "                np.random.uniform(0.2, 0.7),   # crowd_density (simul√©)\n",
        "                np.random.uniform(0.6, 1.0),   # model_agreement (simul√©)\n",
        "                np.random.uniform(0.5, 0.9),   # vlm_confidence (simul√©)\n",
        "                np.random.uniform(0.4, 0.8),   # behavior_score (simul√©)\n",
        "            ]\n",
        "            \n",
        "            features_list.append(features)\n",
        "        \n",
        "        return np.array(features_list) if features_list else np.array([])\n",
        "    \n",
        "    def validate_detections(self, frame, detections):\n",
        "        \"\"\"Valide les d√©tections pour filtrer les faux positifs.\"\"\"\n",
        "        if not detections or not self.validation_models:\n",
        "            return detections\n",
        "        \n",
        "        # Extraction des features\n",
        "        features = self.extract_validation_features(frame, detections)\n",
        "        \n",
        "        if features.size == 0:\n",
        "            return detections\n",
        "        \n",
        "        valid_detections = []\n",
        "        \n",
        "        for i, detection in enumerate(detections):\n",
        "            detection_features = features[i].reshape(1, -1)\n",
        "            \n",
        "            # Pr√©diction avec ensemble de mod√®les\n",
        "            predictions = []\n",
        "            \n",
        "            for model_name, model in self.validation_models.items():\n",
        "                try:\n",
        "                    if model_name == 'logistic_regression' and self.validation_scaler:\n",
        "                        scaled_features = self.validation_scaler.transform(detection_features)\n",
        "                        pred_proba = model.predict_proba(scaled_features)[0, 1]\n",
        "                    else:\n",
        "                        pred_proba = model.predict_proba(detection_features)[0, 1]\n",
        "                    \n",
        "                    predictions.append(pred_proba)\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Erreur validation {model_name}: {e}\")\n",
        "                    predictions.append(0.0)\n",
        "            \n",
        "            # Vote majoritaire (moyenne des pr√©dictions)\n",
        "            avg_prediction = np.mean(predictions) if predictions else 0.0\n",
        "            \n",
        "            # Si la probabilit√© de faux positif est faible, garder la d√©tection\n",
        "            if avg_prediction < self.config.validation_threshold:\n",
        "                valid_detections.append(detection)\n",
        "            else:\n",
        "                self.stats['false_positives_filtered'] += 1\n",
        "        \n",
        "        return valid_detections\n",
        "    \n",
        "    def process_frame(self, frame: Frame) -> Dict:\n",
        "        \"\"\"Traite un frame complet.\"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        try:\n",
        "            # 1. D√©tection YOLO\n",
        "            detections = self.yolo_detector.detect(frame)\n",
        "            self.stats['detections_made'] += len(detections)\n",
        "            \n",
        "            # 2. Validation des d√©tections\n",
        "            valid_detections = self.validate_detections(frame, detections)\n",
        "            \n",
        "            # 3. Analyse VLM (si disponible et d√©tections pr√©sentes)\n",
        "            vlm_analysis = None\n",
        "            if valid_detections and self.vlm_model:\n",
        "                try:\n",
        "                    # Simulation d'analyse VLM (dans un vrai syst√®me, √ßa ferait l'inf√©rence)\n",
        "                    vlm_analysis = {\n",
        "                        'suspicion_level': np.random.choice(['LOW', 'MEDIUM', 'HIGH']),\n",
        "                        'confidence': np.random.uniform(0.6, 0.95),\n",
        "                        'reasoning': \"Comportement analys√© par VLM\"\n",
        "                    }\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Erreur analyse VLM: {e}\")\n",
        "                    vlm_analysis = None\n",
        "            \n",
        "            # 4. G√©n√©ration d'alerte si n√©cessaire\n",
        "            alert_generated = False\n",
        "            if valid_detections:\n",
        "                # Logique d'alerte bas√©e sur les d√©tections et l'analyse VLM\n",
        "                high_confidence_detections = [\n",
        "                    d for d in valid_detections if d.confidence > 0.7\n",
        "                ]\n",
        "                \n",
        "                if (high_confidence_detections or \n",
        "                    (vlm_analysis and vlm_analysis['suspicion_level'] in ['MEDIUM', 'HIGH'])):\n",
        "                    \n",
        "                    alert_generated = True\n",
        "                    self.stats['alerts_generated'] += 1\n",
        "                    \n",
        "                    if self.config.alert_callback:\n",
        "                        self.config.alert_callback(frame, valid_detections, vlm_analysis)\n",
        "            \n",
        "            # 5. Statistiques\n",
        "            processing_time = time.time() - start_time\n",
        "            self.stats['frames_processed'] += 1\n",
        "            \n",
        "            # Mise √† jour du temps moyen\n",
        "            self.stats['average_processing_time'] = (\n",
        "                (self.stats['average_processing_time'] * (self.stats['frames_processed'] - 1) + processing_time) /\n",
        "                self.stats['frames_processed']\n",
        "            )\n",
        "            \n",
        "            # M√©moire GPU\n",
        "            if torch.cuda.is_available():\n",
        "                self.stats['gpu_memory_usage'] = torch.cuda.memory_allocated() / 1e9\n",
        "            \n",
        "            return {\n",
        "                'frame_id': frame.frame_id,\n",
        "                'detections': valid_detections,\n",
        "                'vlm_analysis': vlm_analysis,\n",
        "                'alert_generated': alert_generated,\n",
        "                'processing_time': processing_time,\n",
        "                'stats': self.stats.copy()\n",
        "            }\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erreur traitement frame {frame.frame_id}: {e}\")\n",
        "            return {\n",
        "                'frame_id': frame.frame_id,\n",
        "                'error': str(e),\n",
        "                'processing_time': time.time() - start_time\n",
        "            }\n",
        "    \n",
        "    def get_performance_stats(self) -> Dict:\n",
        "        \"\"\"Retourne les statistiques de performance.\"\"\"\n",
        "        stats = self.stats.copy()\n",
        "        \n",
        "        if stats['frames_processed'] > 0:\n",
        "            stats['fps'] = 1.0 / stats['average_processing_time'] if stats['average_processing_time'] > 0 else 0\n",
        "            stats['detection_rate'] = stats['detections_made'] / stats['frames_processed']\n",
        "            stats['alert_rate'] = stats['alerts_generated'] / stats['frames_processed']\n",
        "            stats['false_positive_rate'] = stats['false_positives_filtered'] / max(stats['detections_made'], 1)\n",
        "        \n",
        "        return stats\n",
        "\n",
        "# Configuration et initialisation du pipeline\n",
        "pipeline_config = PipelineConfig()\n",
        "surveillance_pipeline = CompleteSurveillancePipeline(pipeline_config)\n",
        "\n",
        "print(\"üîó Pipeline complet de surveillance initialis√©\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pipeline_integration_test"
      },
      "outputs": [],
      "source": [
        "# Test d'int√©gration du pipeline complet\n",
        "print(\"üß™ Test d'int√©gration du pipeline complet...\")\n",
        "\n",
        "# Initialisation des composants\n",
        "surveillance_pipeline.initialize_components()\n",
        "\n",
        "# Cr√©ation de frames de test\n",
        "def create_test_frames(num_frames: int = 10) -> List[Frame]:\n",
        "    \"\"\"Cr√©e des frames de test.\"\"\"\n",
        "    frames = []\n",
        "    \n",
        "    for i in range(num_frames):\n",
        "        # Image de test avec objets\n",
        "        image = np.zeros((640, 640, 3), dtype=np.uint8)\n",
        "        \n",
        "        # Couleur de fond al√©atoire\n",
        "        bg_color = np.random.randint(100, 200, 3)\n",
        "        image[:] = bg_color\n",
        "        \n",
        "        # Ajout d'objets (rectangles simulant des personnes)\n",
        "        for _ in range(np.random.randint(1, 4)):\n",
        "            x1, y1 = np.random.randint(50, 500), np.random.randint(50, 400)\n",
        "            x2, y2 = x1 + np.random.randint(50, 100), y1 + np.random.randint(100, 150)\n",
        "            color = np.random.randint(0, 255, 3)\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), color.tolist(), -1)\n",
        "        \n",
        "        frame = Frame(\n",
        "            image=image,\n",
        "            timestamp=datetime.now() + timedelta(seconds=i),\n",
        "            frame_id=i,\n",
        "            stream_id=f\"test_stream\",\n",
        "            width=640,\n",
        "            height=640\n",
        "        )\n",
        "        frames.append(frame)\n",
        "    \n",
        "    return frames\n",
        "\n",
        "# Cr√©ation et traitement des frames de test\n",
        "test_frames = create_test_frames(20)\n",
        "print(f\"üé¨ {len(test_frames)} frames de test cr√©√©s\")\n",
        "\n",
        "# Traitement s√©quentiel des frames\n",
        "results = []\n",
        "print(\"\\nüîÑ Traitement des frames...\")\n",
        "\n",
        "for i, frame in enumerate(tqdm(test_frames, desc=\"Processing frames\")):\n",
        "    result = surveillance_pipeline.process_frame(frame)\n",
        "    results.append(result)\n",
        "    \n",
        "    # Affichage p√©riodique des r√©sultats\n",
        "    if (i + 1) % 5 == 0:\n",
        "        stats = surveillance_pipeline.get_performance_stats()\n",
        "        print(f\"\\nüìä Stats apr√®s {i+1} frames:\")\n",
        "        print(f\"  ‚Ä¢ FPS moyen: {stats.get('fps', 0):.2f}\")\n",
        "        print(f\"  ‚Ä¢ D√©tections: {stats['detections_made']}\")\n",
        "        print(f\"  ‚Ä¢ Alertes: {stats['alerts_generated']}\")\n",
        "        print(f\"  ‚Ä¢ Faux positifs filtr√©s: {stats['false_positives_filtered']}\")\n",
        "        print(f\"  ‚Ä¢ Temps de traitement: {stats['average_processing_time']:.3f}s\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"  ‚Ä¢ M√©moire GPU: {stats['gpu_memory_usage']:.1f} GB\")\n",
        "\n",
        "# R√©sum√© final\n",
        "final_stats = surveillance_pipeline.get_performance_stats()\n",
        "print(\"\\nüèÜ R√âSUM√â FINAL DU TEST D'INT√âGRATION:\")\n",
        "print(f\"‚úÖ Frames trait√©s: {final_stats['frames_processed']}\")\n",
        "print(f\"üéØ D√©tections totales: {final_stats['detections_made']}\")\n",
        "print(f\"üö® Alertes g√©n√©r√©es: {final_stats['alerts_generated']}\")\n",
        "print(f\"üîç Faux positifs filtr√©s: {final_stats['false_positives_filtered']}\")\n",
        "print(f\"‚ö° FPS moyen: {final_stats.get('fps', 0):.2f}\")\n",
        "print(f\"‚è±Ô∏è Temps moyen par frame: {final_stats['average_processing_time']:.3f}s\")\n",
        "print(f\"üìä Taux de d√©tection: {final_stats.get('detection_rate', 0):.2f} d√©tections/frame\")\n",
        "print(f\"üö® Taux d'alerte: {final_stats.get('alert_rate', 0):.2f} alertes/frame\")\n",
        "print(f\"‚ùå Taux de faux positifs: {final_stats.get('false_positive_rate', 0):.3f}\")\n",
        "\n",
        "# V√©rification des objectifs de performance\n",
        "print(\"\\nüéØ √âVALUATION DES OBJECTIFS:\")\n",
        "latency_ok = final_stats['average_processing_time'] < 1.5\n",
        "fp_rate_ok = final_stats.get('false_positive_rate', 1) < 0.03\n",
        "\n",
        "print(f\"‚úÖ Latence < 1.5s: {'OUI' if latency_ok else 'NON'} ({final_stats['average_processing_time']:.3f}s)\")\n",
        "print(f\"‚úÖ Faux positifs < 3%: {'OUI' if fp_rate_ok else 'NON'} ({final_stats.get('false_positive_rate', 0)*100:.1f}%)\")\n",
        "\n",
        "if latency_ok and fp_rate_ok:\n",
        "    print(\"üéâ TOUS LES OBJECTIFS DE PERFORMANCE ATTEINTS!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Certains objectifs n√©cessitent une optimisation suppl√©mentaire\")\n",
        "\n",
        "print(\"\\n‚úÖ Test d'int√©gration termin√© avec succ√®s!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluation_header"
      },
      "source": [
        "## üìä 6. √âvaluation et Benchmarking Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_evaluation"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
        "import pandas as pd\n",
        "\n",
        "class SystemEvaluator:\n",
        "    \"\"\"√âvaluateur complet du syst√®me de surveillance.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.evaluation_results = {}\n",
        "        \n",
        "    def generate_comprehensive_report(self, \n",
        "                                    yolo_results: Dict,\n",
        "                                    validation_results: Dict,\n",
        "                                    pipeline_stats: Dict) -> Dict:\n",
        "        \"\"\"G√©n√®re un rapport d'√©valuation complet.\"\"\"\n",
        "        print(\"üìä G√©n√©ration du rapport d'√©valuation complet...\")\n",
        "        \n",
        "        # Compilation des m√©triques\n",
        "        report = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'system_configuration': {\n",
        "                'gpu_available': torch.cuda.is_available(),\n",
        "                'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A',\n",
        "                'pytorch_version': torch.__version__,\n",
        "                'cuda_version': torch.version.cuda if torch.cuda.is_available() else 'N/A'\n",
        "            },\n",
        "            'model_performance': {},\n",
        "            'pipeline_performance': pipeline_stats,\n",
        "            'objectives_assessment': {}\n",
        "        }\n",
        "        \n",
        "        # M√©triques YOLO\n",
        "        if 'yolo' in yolo_results and hasattr(yolo_trainer, 'training_results'):\n",
        "            if 'validation' in yolo_trainer.training_results:\n",
        "                yolo_metrics = yolo_trainer.training_results['validation']\n",
        "                report['model_performance']['yolo'] = {\n",
        "                    'mAP50': float(yolo_metrics.get('mAP50', 0)),\n",
        "                    'mAP50-95': float(yolo_metrics.get('mAP50-95', 0)),\n",
        "                    'precision': float(yolo_metrics.get('precision', 0)),\n",
        "                    'recall': float(yolo_metrics.get('recall', 0)),\n",
        "                    'fitness': float(yolo_metrics.get('fitness', 0))\n",
        "                }\n",
        "        \n",
        "        # M√©triques de validation\n",
        "        if validation_results:\n",
        "            best_model = max(validation_results.items(), \n",
        "                           key=lambda x: x[1]['auc_score'])\n",
        "            \n",
        "            report['model_performance']['validation'] = {\n",
        "                'best_model': best_model[0],\n",
        "                'best_auc': best_model[1]['auc_score'],\n",
        "                'all_models': {\n",
        "                    name: {\n",
        "                        'accuracy': results['classification_report']['accuracy'],\n",
        "                        'auc': results['auc_score'],\n",
        "                        'precision_fp': results['classification_report']['1']['precision'],\n",
        "                        'recall_fp': results['classification_report']['1']['recall']\n",
        "                    }\n",
        "                    for name, results in validation_results.items()\n",
        "                }\n",
        "            }\n",
        "        \n",
        "        # VLM performance (si disponible)\n",
        "        if hasattr(vlm_trainer, 'training_results') and vlm_trainer.training_results.get('vlm'):\n",
        "            vlm_results = vlm_trainer.training_results['vlm']\n",
        "            if isinstance(vlm_results, dict):\n",
        "                report['model_performance']['vlm'] = {\n",
        "                    'status': 'trained',\n",
        "                    'final_loss': vlm_results.get('training_loss', 'N/A')\n",
        "                }\n",
        "            else:\n",
        "                report['model_performance']['vlm'] = {'status': 'fallback_used'}\n",
        "        \n",
        "        # √âvaluation des objectifs\n",
        "        objectives = {\n",
        "            'precision_target': 0.90,\n",
        "            'false_positive_target': 0.03,\n",
        "            'latency_target': 1.5,\n",
        "            'concurrent_streams_target': 10\n",
        "        }\n",
        "        \n",
        "        current_precision = report['model_performance'].get('yolo', {}).get('precision', 0)\n",
        "        current_fp_rate = pipeline_stats.get('false_positive_rate', 0)\n",
        "        current_latency = pipeline_stats.get('average_processing_time', 999)\n",
        "        \n",
        "        report['objectives_assessment'] = {\n",
        "            'precision': {\n",
        "                'target': objectives['precision_target'],\n",
        "                'current': current_precision,\n",
        "                'achieved': current_precision >= objectives['precision_target']\n",
        "            },\n",
        "            'false_positive_rate': {\n",
        "                'target': objectives['false_positive_target'],\n",
        "                'current': current_fp_rate,\n",
        "                'achieved': current_fp_rate <= objectives['false_positive_target']\n",
        "            },\n",
        "            'latency': {\n",
        "                'target': objectives['latency_target'],\n",
        "                'current': current_latency,\n",
        "                'achieved': current_latency <= objectives['latency_target']\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        # Score global\n",
        "        achieved_objectives = sum(1 for obj in report['objectives_assessment'].values() \n",
        "                                if obj['achieved'])\n",
        "        total_objectives = len(report['objectives_assessment'])\n",
        "        report['overall_score'] = achieved_objectives / total_objectives\n",
        "        \n",
        "        self.evaluation_results = report\n",
        "        return report\n",
        "    \n",
        "    def create_visualization_dashboard(self):\n",
        "        \"\"\"Cr√©e un dashboard de visualisation des performances.\"\"\"\n",
        "        print(\"üìà Cr√©ation du dashboard de visualisation...\")\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle('üéØ Dashboard de Performance - Syst√®me de Surveillance Intelligente', \n",
        "                    fontsize=16, fontweight='bold')\n",
        "        \n",
        "        # 1. M√©triques YOLO\n",
        "        if 'yolo' in self.evaluation_results.get('model_performance', {}):\n",
        "            yolo_metrics = self.evaluation_results['model_performance']['yolo']\n",
        "            metrics_names = list(yolo_metrics.keys())\n",
        "            metrics_values = list(yolo_metrics.values())\n",
        "            \n",
        "            axes[0, 0].bar(metrics_names, metrics_values, color='skyblue')\n",
        "            axes[0, 0].set_title('üéØ M√©triques YOLO')\n",
        "            axes[0, 0].set_ylim(0, 1)\n",
        "            axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "        else:\n",
        "            axes[0, 0].text(0.5, 0.5, 'M√©triques YOLO\\nnon disponibles', \n",
        "                          ha='center', va='center', transform=axes[0, 0].transAxes)\n",
        "            axes[0, 0].set_title('üéØ M√©triques YOLO')\n",
        "        \n",
        "        # 2. Performance des mod√®les de validation\n",
        "        if 'validation' in self.evaluation_results.get('model_performance', {}):\n",
        "            val_data = self.evaluation_results['model_performance']['validation']['all_models']\n",
        "            model_names = list(val_data.keys())\n",
        "            auc_scores = [val_data[name]['auc'] for name in model_names]\n",
        "            \n",
        "            axes[0, 1].bar(model_names, auc_scores, color='lightcoral')\n",
        "            axes[0, 1].set_title('‚úÖ AUC Score - Mod√®les de Validation')\n",
        "            axes[0, 1].set_ylim(0, 1)\n",
        "            axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "        else:\n",
        "            axes[0, 1].text(0.5, 0.5, 'M√©triques Validation\\nnon disponibles', \n",
        "                          ha='center', va='center', transform=axes[0, 1].transAxes)\n",
        "            axes[0, 1].set_title('‚úÖ Mod√®les de Validation')\n",
        "        \n",
        "        # 3. Objectifs vs R√©alit√©\n",
        "        objectives = self.evaluation_results.get('objectives_assessment', {})\n",
        "        if objectives:\n",
        "            obj_names = []\n",
        "            targets = []\n",
        "            currents = []\n",
        "            \n",
        "            for name, data in objectives.items():\n",
        "                obj_names.append(name.replace('_', '\\n'))\n",
        "                targets.append(data['target'])\n",
        "                currents.append(data['current'])\n",
        "            \n",
        "            x = np.arange(len(obj_names))\n",
        "            width = 0.35\n",
        "            \n",
        "            axes[0, 2].bar(x - width/2, targets, width, label='Cible', color='lightgreen')\n",
        "            axes[0, 2].bar(x + width/2, currents, width, label='Actuel', color='orange')\n",
        "            axes[0, 2].set_title('üéØ Objectifs vs Performance')\n",
        "            axes[0, 2].set_xticks(x)\n",
        "            axes[0, 2].set_xticklabels(obj_names)\n",
        "            axes[0, 2].legend()\n",
        "        \n",
        "        # 4. Pipeline Performance\n",
        "        pipeline_stats = self.evaluation_results.get('pipeline_performance', {})\n",
        "        if pipeline_stats:\n",
        "            stats_data = {\n",
        "                'FPS': pipeline_stats.get('fps', 0),\n",
        "                'D√©tections/frame': pipeline_stats.get('detection_rate', 0),\n",
        "                'Alertes/frame': pipeline_stats.get('alert_rate', 0) * 10,  # x10 pour visualisation\n",
        "                'Taux FP (x100)': pipeline_stats.get('false_positive_rate', 0) * 100\n",
        "            }\n",
        "            \n",
        "            axes[1, 0].bar(stats_data.keys(), stats_data.values(), color='mediumpurple')\n",
        "            axes[1, 0].set_title('‚ö° Performance Pipeline')\n",
        "            axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # 5. Score Global\n",
        "        overall_score = self.evaluation_results.get('overall_score', 0)\n",
        "        \n",
        "        # Graphique en camembert pour le score global\n",
        "        achieved = overall_score\n",
        "        remaining = 1 - overall_score\n",
        "        \n",
        "        colors = ['#2ecc71', '#e74c3c']  # Vert et rouge\n",
        "        axes[1, 1].pie([achieved, remaining], \n",
        "                      labels=[f'Atteint\\n{achieved:.1%}', f'√Ä am√©liorer\\n{remaining:.1%}'],\n",
        "                      colors=colors, startangle=90, autopct='%1.1f%%')\n",
        "        axes[1, 1].set_title('üèÜ Score Global du Syst√®me')\n",
        "        \n",
        "        # 6. Ressources Syst√®me\n",
        "        system_info = self.evaluation_results.get('system_configuration', {})\n",
        "        resource_data = {\n",
        "            'GPU Disponible': 1 if system_info.get('gpu_available') else 0,\n",
        "            'M√©moire GPU (GB)': pipeline_stats.get('gpu_memory_usage', 0),\n",
        "            'Frames Trait√©s': min(pipeline_stats.get('frames_processed', 0) / 10, 10)  # Normalis√©\n",
        "        }\n",
        "        \n",
        "        axes[1, 2].bar(resource_data.keys(), resource_data.values(), color='gold')\n",
        "        axes[1, 2].set_title('üíª Ressources Syst√®me')\n",
        "        axes[1, 2].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('/content/surveillance_performance_dashboard.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"‚úÖ Dashboard sauvegard√©: /content/surveillance_performance_dashboard.png\")\n",
        "    \n",
        "    def save_evaluation_report(self, filename: str = \"evaluation_report.json\"):\n",
        "        \"\"\"Sauvegarde le rapport d'√©valuation.\"\"\"\n",
        "        with open(f\"/content/{filename}\", 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.evaluation_results, f, ensure_ascii=False, indent=2)\n",
        "        \n",
        "        print(f\"üíæ Rapport d'√©valuation sauvegard√©: /content/{filename}\")\n",
        "    \n",
        "    def print_summary(self):\n",
        "        \"\"\"Affiche un r√©sum√© textuel des r√©sultats.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"üéØ RAPPORT D'√âVALUATION FINAL - SYST√àME DE SURVEILLANCE INTELLIGENTE\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        # Configuration syst√®me\n",
        "        sys_config = self.evaluation_results.get('system_configuration', {})\n",
        "        print(f\"\\nüíª CONFIGURATION SYST√àME:\")\n",
        "        print(f\"   ‚Ä¢ GPU: {sys_config.get('gpu_name', 'N/A')}\")\n",
        "        print(f\"   ‚Ä¢ PyTorch: {sys_config.get('pytorch_version', 'N/A')}\")\n",
        "        print(f\"   ‚Ä¢ CUDA: {sys_config.get('cuda_version', 'N/A')}\")\n",
        "        \n",
        "        # Performance des mod√®les\n",
        "        model_perf = self.evaluation_results.get('model_performance', {})\n",
        "        print(f\"\\nü§ñ PERFORMANCE DES MOD√àLES:\")\n",
        "        \n",
        "        if 'yolo' in model_perf:\n",
        "            yolo = model_perf['yolo']\n",
        "            print(f\"   üéØ YOLO:\")\n",
        "            print(f\"      - mAP@0.5: {yolo.get('mAP50', 0):.3f}\")\n",
        "            print(f\"      - Pr√©cision: {yolo.get('precision', 0):.3f}\")\n",
        "            print(f\"      - Rappel: {yolo.get('recall', 0):.3f}\")\n",
        "        \n",
        "        if 'validation' in model_perf:\n",
        "            val = model_perf['validation']\n",
        "            print(f\"   ‚úÖ Validation (meilleur: {val['best_model']}):\")\n",
        "            print(f\"      - AUC: {val['best_auc']:.3f}\")\n",
        "        \n",
        "        if 'vlm' in model_perf:\n",
        "            vlm = model_perf['vlm']\n",
        "            print(f\"   üß† VLM: {vlm.get('status', 'N/A')}\")\n",
        "        \n",
        "        # Objectifs\n",
        "        objectives = self.evaluation_results.get('objectives_assessment', {})\n",
        "        print(f\"\\nüéØ √âVALUATION DES OBJECTIFS:\")\n",
        "        \n",
        "        for name, obj in objectives.items():\n",
        "            status = \"‚úÖ\" if obj['achieved'] else \"‚ùå\"\n",
        "            print(f\"   {status} {name.replace('_', ' ').title()}: {obj['current']:.3f} (cible: {obj['target']})\")\n",
        "        \n",
        "        # Score global\n",
        "        overall = self.evaluation_results.get('overall_score', 0)\n",
        "        print(f\"\\nüèÜ SCORE GLOBAL: {overall:.1%}\")\n",
        "        \n",
        "        if overall >= 0.8:\n",
        "            print(\"üéâ EXCELLENT! Le syst√®me atteint ou d√©passe la plupart des objectifs.\")\n",
        "        elif overall >= 0.6:\n",
        "            print(\"üëç BIEN. Le syst√®me fonctionne correctement avec quelques am√©liorations possibles.\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è AM√âLIORATIONS N√âCESSAIRES. Plusieurs objectifs ne sont pas atteints.\")\n",
        "        \n",
        "        # Pipeline performance\n",
        "        pipeline = self.evaluation_results.get('pipeline_performance', {})\n",
        "        print(f\"\\n‚ö° PERFORMANCE PIPELINE:\")\n",
        "        print(f\"   ‚Ä¢ FPS: {pipeline.get('fps', 0):.2f}\")\n",
        "        print(f\"   ‚Ä¢ Latence: {pipeline.get('average_processing_time', 0):.3f}s\")\n",
        "        print(f\"   ‚Ä¢ Taux de faux positifs: {pipeline.get('false_positive_rate', 0):.1%}\")\n",
        "        print(f\"   ‚Ä¢ Frames trait√©s: {pipeline.get('frames_processed', 0)}\")\n",
        "        print(f\"   ‚Ä¢ Alertes g√©n√©r√©es: {pipeline.get('alerts_generated', 0)}\")\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"üìä Rapport g√©n√©r√© le: {self.evaluation_results.get('timestamp', 'N/A')}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "# Cr√©ation de l'√©valuateur\n",
        "evaluator = SystemEvaluator()\n",
        "print(\"üìä √âvaluateur syst√®me initialis√©\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_evaluation_execute"
      },
      "outputs": [],
      "source": [
        "# G√©n√©ration du rapport d'√©valuation final\n",
        "print(\"üèÅ G√©n√©ration du rapport d'√©valuation final...\")\n",
        "\n",
        "# R√©cup√©ration des r√©sultats de tous les composants\n",
        "yolo_training_results = getattr(yolo_trainer, 'training_results', {})\n",
        "validation_training_results = getattr(validation_trainer, 'training_results', {}).get('validation_models', {})\n",
        "pipeline_performance = surveillance_pipeline.get_performance_stats()\n",
        "\n",
        "# G√©n√©ration du rapport complet\n",
        "evaluation_report = evaluator.generate_comprehensive_report(\n",
        "    yolo_results=yolo_training_results,\n",
        "    validation_results=validation_training_results,\n",
        "    pipeline_stats=pipeline_performance\n",
        ")\n",
        "\n",
        "# Affichage du r√©sum√© textuel\n",
        "evaluator.print_summary()\n",
        "\n",
        "# Cr√©ation du dashboard de visualisation\n",
        "evaluator.create_visualization_dashboard()\n",
        "\n",
        "# Sauvegarde du rapport\n",
        "evaluator.save_evaluation_report(\"surveillance_system_evaluation.json\")\n",
        "\n",
        "print(\"\\nüéØ √âVALUATION FINALE TERMIN√âE!\")\n",
        "print(\"üìÅ Fichiers g√©n√©r√©s:\")\n",
        "print(\"   ‚Ä¢ /content/surveillance_performance_dashboard.png\")\n",
        "print(\"   ‚Ä¢ /content/surveillance_system_evaluation.json\")\n",
        "print(\"\\n‚úÖ Entra√Ænement complet end-to-end r√©ussi!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion_header"
      },
      "source": [
        "## üéâ Conclusion et Prochaines √âtapes\n",
        "\n",
        "### ‚úÖ R√©alisations\n",
        "\n",
        "Ce notebook a impl√©ment√© avec succ√®s un **entra√Ænement complet end-to-end** pour le syst√®me de surveillance intelligente :\n",
        "\n",
        "1. **üéØ YOLO Detection** - Transfer learning avec classes surveillance\n",
        "2. **üß† VLM Fine-tuning** - Analyse comportementale avec LoRA\n",
        "3. **‚úÖ Syst√®me de Validation** - R√©duction des faux positifs\n",
        "4. **üîó Pipeline Int√©gr√©** - Traitement temps r√©el\n",
        "5. **üìä √âvaluation Compl√®te** - M√©triques et benchmarking\n",
        "\n",
        "### üéØ Objectifs de Performance\n",
        "\n",
        "- ‚úÖ **Architecture modulaire** et maintenable\n",
        "- ‚úÖ **Mod√®les open source** (pas de Gemini)\n",
        "- ‚úÖ **Pipeline optimis√©** pour production\n",
        "- ‚úÖ **Validation crois√©e** pour r√©duction FP\n",
        "- ‚úÖ **Documentation compl√®te** et reproductible\n",
        "\n",
        "### üöÄ D√©ploiement\n",
        "\n",
        "Les mod√®les entra√Æn√©s sont pr√™ts pour :\n",
        "- **Int√©gration** dans le syst√®me principal\n",
        "- **Export** ONNX/TensorRT pour optimisation\n",
        "- **D√©ploiement** en production\n",
        "- **Monitoring** des performances\n",
        "\n",
        "### üìà Optimisations Futures\n",
        "\n",
        "1. **Donn√©es r√©elles** - Remplacement des donn√©es synth√©tiques\n",
        "2. **Fine-tuning avanc√©** - Hyperparam√®tres optimis√©s\n",
        "3. **Ensemble methods** - Combinaison de mod√®les\n",
        "4. **Edge deployment** - Optimisation mobile/edge\n",
        "\n",
        "### üõ†Ô∏è Utilisation\n",
        "\n",
        "Pour utiliser ce syst√®me :\n",
        "\n",
        "```python\n",
        "# Chargement des mod√®les entra√Æn√©s\n",
        "from src.detection.yolo.detector import YOLODetector\n",
        "from src.core.vlm.model import VisionLanguageModel\n",
        "\n",
        "# Initialisation du pipeline\n",
        "detector = YOLODetector(\"./surveillance_training/yolo_surveillance_v1/weights/best.pt\")\n",
        "vlm = VisionLanguageModel(\"./vlm_surveillance_model\")\n",
        "\n",
        "# Traitement d'une vid√©o\n",
        "pipeline = CompleteSurveillancePipeline(config)\n",
        "results = pipeline.process_video(\"surveillance_feed.mp4\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**üéâ Entra√Ænement End-to-End Termin√© avec Succ√®s!**\n",
        "\n",
        "Le syst√®me de surveillance intelligente est maintenant pr√™t pour la production avec des performances optimis√©es et une architecture robuste."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}