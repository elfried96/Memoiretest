#!/usr/bin/env python3
"""Test benchmark Qwen2-VL uniquement."""

import os
import sys
import asyncio
import time
from pathlib import Path
from PIL import Image
import numpy as np

# Configuration cache - utiliser un dossier diffÃ©rent pour Ã©viter les conflits
os.environ['HF_HOME'] = '/home/elfried-kinzoun/.cache/huggingface_qwen'
os.environ['TRANSFORMERS_CACHE'] = '/home/elfried-kinzoun/.cache/transformers_qwen'

# Path
sys.path.append(str(Path(__file__).parent / "src"))

from src.core.vlm.dynamic_model import DynamicVisionLanguageModel
from src.core.types import AnalysisRequest


class Qwen2VLBenchmark:
    """Benchmark spÃ©cialisÃ© pour Qwen2-VL."""
    
    def __init__(self):
        # Configuration VLM avec Qwen2-VL uniquement
        self.vlm = DynamicVisionLanguageModel(
            default_model="qwen2-vl-7b-instruct",
            enable_fallback=False  # Pas de fallback
        )
        self.results = {}
    
    async def setup(self):
        """Initialisation du modÃ¨le."""
        print("ğŸš€ Benchmark Qwen2-VL")
        print("=" * 40)
        
        # Nettoyer le cache Kimi pour libÃ©rer de l'espace
        print("ğŸ§¹ Nettoyage cache Kimi-VL...")
        os.system("rm -rf ~/.cache/huggingface/hub/models--moonshotai--Kimi-VL-A3B-* 2>/dev/null")
        
        print("â³ Chargement Qwen2-VL-7B-Instruct...")
        start_time = time.time()
        
        success = await self.vlm.switch_model("qwen2-vl-7b-instruct")
        load_time = time.time() - start_time
        
        if success:
            print(f"âœ… Qwen2-VL chargÃ© en {load_time:.1f}s")
            print(f"ğŸ“Š ModÃ¨le: {self.vlm.current_model_id}")
            print(f"ğŸ”§ Device: {self.vlm.device}")
            return True
        else:
            print("âŒ Ã‰chec du chargement")
            return False
    
    def create_test_image(self, scenario: str) -> Image.Image:
        """CrÃ©er une image de test selon le scÃ©nario."""
        
        # Image simple 224x224 RGB
        if scenario == "simple":
            # Image unie bleue
            img_array = np.ones((224, 224, 3), dtype=np.uint8) * [100, 100, 255]
        
        elif scenario == "complex":
            # Motif complexe diffÃ©rent
            img_array = np.zeros((224, 224, 3), dtype=np.uint8)
            # Damier colorÃ©
            for i in range(224):
                for j in range(224):
                    if (i // 28 + j // 28) % 2 == 0:
                        img_array[i, j] = [255, 200, 100]
                    else:
                        img_array[i, j] = [100, 200, 255]
        
        elif scenario == "surveillance":
            # ScÃ¨ne surveillance diffÃ©rente
            img_array = np.ones((224, 224, 3), dtype=np.uint8) * [40, 60, 40]
            # Formes "objets suspects"
            img_array[30:80, 30:60] = [255, 100, 100]  # Objet rouge
            img_array[150:200, 160:190] = [100, 255, 100]  # Objet vert
            # Ligne "barriÃ¨re" 
            img_array[110:115, :] = [200, 200, 200]
        
        elif scenario == "text":
            # Test OCR - texte simulÃ©
            img_array = np.ones((224, 224, 3), dtype=np.uint8) * 255
            # Barres noires simulant du texte
            img_array[50:70, 50:150] = [0, 0, 0]
            img_array[80:100, 50:120] = [0, 0, 0]
            img_array[110:130, 50:180] = [0, 0, 0]
            img_array[140:160, 50:140] = [0, 0, 0]
        
        else:
            img_array = np.ones((224, 224, 3), dtype=np.uint8) * 128
        
        return Image.fromarray(img_array)
    
    async def test_scenario(self, scenario_name: str, prompt: str, image: Image.Image):
        """Tester un scÃ©nario spÃ©cifique."""
        
        print(f"\nğŸ“‹ Test: {scenario_name}")
        print("-" * 30)
        
        # CrÃ©er la requÃªte
        request = AnalysisRequest(
            image=image,
            prompt=prompt,
            enable_advanced_tools=True,
            max_tokens=256
        )
        
        # Mesure des performances
        start_time = time.time()
        
        try:
            response = await self.vlm.analyze_image(request)
            
            analysis_time = time.time() - start_time
            
            # RÃ©sultats
            result = {
                "temps_analyse": analysis_time,
                "succes": True,
                "suspicion": response.suspicion_level,
                "action": response.recommended_action,
                "confiance": response.confidence_score,
                "description": response.description[:100] + "..." if len(response.description) > 100 else response.description,
                "outils_utilises": len(response.tools_used),
                "erreur": None
            }
            
            print(f"â±ï¸  Temps: {analysis_time:.2f}s")
            print(f"ğŸ¯ Suspicion: {response.suspicion_level}")
            print(f"ğŸ”§ Action: {response.recommended_action}")
            print(f"ğŸ“Š Confiance: {response.confidence_score:.2f}")
            print(f"ğŸ› ï¸  Outils: {len(response.tools_used)}")
            print(f"ğŸ“ Description: {result['description']}")
            
        except Exception as e:
            analysis_time = time.time() - start_time
            result = {
                "temps_analyse": analysis_time,
                "succes": False,
                "erreur": str(e),
                "suspicion": None,
                "action": None,
                "confiance": 0.0,
                "description": None,
                "outils_utilises": 0
            }
            print(f"âŒ Erreur ({analysis_time:.2f}s): {e}")
        
        self.results[scenario_name] = result
        return result
    
    async def run_benchmark(self):
        """ExÃ©cuter tous les tests."""
        
        # VÃ©rification du setup
        if not await self.setup():
            return
        
        # ScÃ©narios de test (adaptÃ©s aux forces de Qwen2-VL)
        scenarios = [
            {
                "name": "surveillance_avancee",
                "prompt": "Analyze this surveillance scene. Detect any objects, people, or suspicious activities. Provide detailed reasoning.",
                "image_type": "surveillance"
            },
            {
                "name": "raisonnement_visuel", 
                "prompt": "Examine this image carefully. What patterns, relationships, or logical structures can you identify?",
                "image_type": "complex"
            },
            {
                "name": "detection_fine",
                "prompt": "Perform detailed object detection and classification in this image. List all elements you can identify.",
                "image_type": "simple"
            },
            {
                "name": "ocr_analyse",
                "prompt": "Analyze any text-like elements in this image. Can you identify writing, symbols, or structured information?",
                "image_type": "text"
            },
            {
                "name": "evaluation_securite_complexe",
                "prompt": "Assess the security implications of this scene. Consider multiple factors and provide risk analysis.",
                "image_type": "surveillance"
            }
        ]
        
        print(f"\nğŸ§ª Lancement de {len(scenarios)} tests...")
        
        for scenario in scenarios:
            image = self.create_test_image(scenario["image_type"])
            await self.test_scenario(
                scenario["name"],
                scenario["prompt"], 
                image
            )
            
            # Pause entre tests
            await asyncio.sleep(2)  # Plus long car Qwen peut Ãªtre plus lent
    
    def generate_report(self):
        """GÃ©nerer rapport de performance."""
        
        print("\nğŸ“Š RAPPORT QWEN2-VL")
        print("=" * 50)
        
        if not self.results:
            print("âŒ Aucun rÃ©sultat disponible")
            return
        
        # Statistiques globales
        total_tests = len(self.results)
        succes_tests = sum(1 for r in self.results.values() if r["succes"])
        temps_total = sum(r["temps_analyse"] for r in self.results.values())
        temps_moyen = temps_total / total_tests if total_tests > 0 else 0
        
        print(f"ğŸ“ˆ Tests rÃ©alisÃ©s: {total_tests}")
        print(f"âœ… Taux de succÃ¨s: {(succes_tests/total_tests)*100:.1f}%")
        print(f"â±ï¸  Temps moyen: {temps_moyen:.2f}s")
        print(f"âš¡ Temps total: {temps_total:.2f}s")
        
        # Analyse de la stabilitÃ©
        if succes_tests > 0:
            temps_succes = [r["temps_analyse"] for r in self.results.values() if r["succes"]]
            temps_min = min(temps_succes)
            temps_max = max(temps_succes)
            print(f"ğŸ“Š Plage temps: {temps_min:.2f}s - {temps_max:.2f}s")
        
        # DÃ©tail par test
        print(f"\nğŸ“‹ DÃ©tail des tests:")
        for name, result in self.results.items():
            status = "âœ…" if result["succes"] else "âŒ"
            print(f"  {status} {name}: {result['temps_analyse']:.2f}s")
            if result["succes"]:
                print(f"     â†’ Suspicion: {result['suspicion']}, Confiance: {result['confiance']:.2f}")
            else:
                print(f"     â†’ Erreur: {result['erreur']}")
        
        # Points forts de Qwen2-VL
        print(f"\nğŸ’¡ Analyse Qwen2-VL:")
        
        # Ã‰valuation performance
        if succes_tests == total_tests:
            print("  ğŸ¯ FiabilitÃ© excellente - Aucune erreur")
        elif succes_tests >= total_tests * 0.8:
            print("  ğŸ‘ FiabilitÃ© correcte - Majoritairement stable")
        else:
            print("  âš ï¸  FiabilitÃ© faible - InstabilitÃ© dÃ©tectÃ©e")
        
        # Ã‰valuation vitesse
        if temps_moyen < 3.0:
            print("  âš¡ RapiditÃ© excellente")
        elif temps_moyen < 8.0:
            print("  ğŸŒ Vitesse modÃ©rÃ©e mais acceptable")
        else:
            print("  ğŸŒ Lenteur significative")
        
        # Forces spÃ©cifiques
        print("\nğŸ¯ Points forts attendus de Qwen2-VL:")
        print("  â€¢ Raisonnement visuel sophistiquÃ©")
        print("  â€¢ Analyse dÃ©taillÃ©e des scÃ¨nes complexes")
        print("  â€¢ CapacitÃ© OCR intÃ©grÃ©e")
        print("  â€¢ StabilitÃ© des rÃ©ponses")


async def main():
    """Point d'entrÃ©e principal."""
    
    benchmark = Qwen2VLBenchmark()
    
    try:
        await benchmark.run_benchmark()
        benchmark.generate_report()
        
        print("\nğŸ’¾ Pour comparer avec Kimi-VL, lancez:")
        print("   python test_kimi_vl_only.py")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  Test interrompu")
    except Exception as e:
        print(f"\nâŒ Erreur globale: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())