"""SAM2 Segmentation for precise object segmentation."""

import torch
import torch.nn as nn
import numpy as np
import cv2
from typing import List, Dict, Any, Optional, Tuple, Union
import logging
from dataclasses import dataclass
import time
from enum import Enum

logger = logging.getLogger(__name__)

class PromptType(Enum):
    """Types de prompts supportés par SAM2."""
    BOUNDING_BOX = "bbox"
    POINTS = "points"  
    MASK = "mask"
    COMBINED = "combined"

@dataclass
class SegmentationPrompt:
    """Unified prompt structure for SAM2."""
    prompt_type: PromptType
    bounding_boxes: Optional[List[List[float]]] = None
    points: Optional[List[List[List[float]]]] = None
    point_labels: Optional[List[List[int]]] = None
    input_masks: Optional[np.ndarray] = None
    
@dataclass
class SegmentationResult:
    """Result from SAM2 segmentation."""
    masks: np.ndarray
    scores: np.ndarray
    boxes: np.ndarray
    processing_time: float
    prompt_type: PromptType
    metadata: Optional[Dict[str, Any]] = None
    
class SAM2Segmentator:
    """SAM2 segmentation for enhanced object detection precision."""
    
    def __init__(self, model_path: str = "facebook/sam2-hiera-large", device: str = "auto", lazy_loading: bool = True):
        self.device = self._select_device(device)
        self.model = None
        self.processor = None
        self.model_path = model_path
        self.lazy_loading = lazy_loading
        self._model_loaded = False
        
        # Chargement immédiat ou lazy selon paramètre
        if not lazy_loading:
            self._load_model()
        
    def _select_device(self, device: str) -> torch.device:
        """Select optimal device for computation."""
        if device == "auto":
            return torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return torch.device(device)
    
    def _ensure_model_loaded(self):
        """Ensure model is loaded (lazy loading)."""
        if not self._model_loaded:
            self._load_model()
    
    def _load_model(self):
        """Load SAM2 model with optimizations."""
        if self._model_loaded:
            return
            
        try:
            from sam2.build_sam import build_sam2
            from sam2.sam2_image_predictor import SAM2ImagePredictor
            
            logger.info(f"Loading SAM2 model...")
            
            # Utilisation du modèle SAM2 officiel
            # Mapping des noms de modèles
            model_cfg_map = {
                "facebook/sam2-hiera-large": "sam2_hiera_l.yaml",
                "sam2-hiera-large": "sam2_hiera_l.yaml",
                "sam2-hiera-base": "sam2_hiera_b.yaml", 
                "sam2-hiera-small": "sam2_hiera_s.yaml",
                "sam2-hiera-tiny": "sam2_hiera_t.yaml"
            }
            
            # Sélection du config
            config_name = model_cfg_map.get(self.model_path, "sam2_hiera_l.yaml")
            
            # Construction du modèle SAM2
            sam2_model = build_sam2(config_name, device=self.device)
            self.model = SAM2ImagePredictor(sam2_model)
            
            # Pas besoin de processor avec l'API SAM2 native
            self.processor = None
            
            logger.info(f"SAM2 model loaded on {self.device}")
            self._model_loaded = True
            
        except ImportError as e:
            logger.error(f"SAM2 library not available: {e}")
            self.model = None
            self._model_loaded = False
        except Exception as e:
            logger.error(f"Failed to load SAM2 model: {e}")
            self.model = None  
            self._model_loaded = False
    
    @torch.inference_mode()
    def segment_with_prompt(self, frame: np.ndarray, prompt: SegmentationPrompt, 
                           confidence_threshold: float = 0.8) -> SegmentationResult:
        """Universal segmentation method supporting all prompt types."""
        start_time = time.perf_counter()
        
        # Ensure model is loaded
        self._ensure_model_loaded()
        
        if self.model is None:
            return self._fallback_segmentation(frame, prompt.bounding_boxes or [], start_time)
        
        try:
            # Set image for SAM2
            self.model.set_image(frame)
            
            # Prepare prompts based on type
            if prompt.prompt_type == PromptType.BOUNDING_BOX and prompt.bounding_boxes:
                # Use first bounding box
                bbox = prompt.bounding_boxes[0]
                input_box = np.array([[bbox[0], bbox[1], bbox[2], bbox[3]]])
                masks, scores, logits = self.model.predict(
                    point_coords=None,
                    point_labels=None, 
                    box=input_box,
                    multimask_output=True,
                )
                
            elif prompt.prompt_type == PromptType.POINTS and prompt.points and prompt.point_labels:
                # Use points
                point_coords = np.array(prompt.points[0])
                point_labels = np.array(prompt.point_labels[0])
                masks, scores, logits = self.model.predict(
                    point_coords=point_coords,
                    point_labels=point_labels,
                    box=None,
                    multimask_output=True,
                )
                
            else:
                # Fallback: use center point
                h, w = frame.shape[:2]
                center_point = np.array([[w//2, h//2]])
                center_label = np.array([1])
                masks, scores, logits = self.model.predict(
                    point_coords=center_point,
                    point_labels=center_label,
                    box=None,
                    multimask_output=True,
                )
            
            # Filter by confidence
            if confidence_threshold > 0:
                valid_mask = scores >= confidence_threshold
                masks = masks[valid_mask]
                scores = scores[valid_mask]
            
            # Convert to expected format
            if len(masks) == 0:
                # No valid masks
                return self._fallback_segmentation(frame, prompt.bounding_boxes or [], start_time)
                
            # Take best mask
            best_idx = np.argmax(scores)
            best_mask = masks[best_idx]
            best_score = scores[best_idx]
            
            # Generate dummy box from mask
            y_indices, x_indices = np.where(best_mask)
            if len(y_indices) > 0:
                x1, x2 = x_indices.min(), x_indices.max()
                y1, y2 = y_indices.min(), y_indices.max()
                boxes = np.array([[x1, y1, x2, y2]])
            else:
                boxes = np.array([[0, 0, frame.shape[1], frame.shape[0]]])
            
            return SegmentationResult(
                masks=masks,
                scores=scores,
                boxes=boxes,
                processing_time=time.perf_counter() - start_time,
                prompt_type=prompt.prompt_type
            )
            
        except Exception as e:
            logger.error(f"SAM2 segmentation failed: {e}")
            return self._fallback_segmentation(frame, prompt.bounding_boxes or [], start_time)
    
    # Méthodes de convenance pour rétrocompatibilité
    @torch.inference_mode()
    def segment_objects(self, frame: np.ndarray, bounding_boxes: List[List[float]], 
                       confidence_threshold: float = 0.8) -> SegmentationResult:
        """Segment objects using SAM2 with bounding box prompts."""
        prompt = SegmentationPrompt(
            prompt_type=PromptType.BOUNDING_BOX,
            bounding_boxes=bounding_boxes
        )
        return self.segment_with_prompt(frame, prompt, confidence_threshold)
    
    @torch.inference_mode()  
    def segment_objects_old(self, frame: np.ndarray, bounding_boxes: List[List[float]], 
                       confidence_threshold: float = 0.8) -> SegmentationResult:
        """Legacy method - kept for backward compatibility."""
        start_time = time.perf_counter()
        
        self._ensure_model_loaded()
        
        if self.model is None:
            # Fallback to simple mask generation
            return self._fallback_segmentation(frame, bounding_boxes, start_time)
        
        try:
            # Format bounding boxes selon le standard HF : [[[x1, y1, x2, y2], ...]]
            formatted_boxes = [[bounding_boxes]]  # Wrap en 3 dimensions
            
            # Prepare inputs selon documentation HF
            inputs = self.processor(
                images=frame,
                input_boxes=formatted_boxes,
                return_tensors="pt"
            ).to(self.device)
            
            # Forward pass avec torch.inference_mode (déjà appliqué via décorateur)
            with torch.autocast(self.device.type, dtype=torch.bfloat16):
                outputs = self.model(**inputs)
            
            # Post-processing selon documentation HF
            masks = self.processor.post_process_masks(
                outputs.pred_masks.cpu(), 
                inputs["original_sizes"]
            )[0]
            
            # Extraction des scores IoU
            scores = outputs.iou_scores.cpu().numpy().squeeze()
            
            # Filter by confidence (si plusieurs masques générés)
            if len(scores.shape) > 0 and scores.shape[0] > 1:
                # Prendre le meilleur masque par défaut ou filtrer
                best_mask_idx = torch.argmax(outputs.iou_scores.squeeze())
                masks = masks[best_mask_idx:best_mask_idx+1]  # Garder dimension batch
                scores = np.array([scores[best_mask_idx]])
            else:
                scores = np.array([scores.item()] if scores.ndim == 0 else scores)
            
            # Convertir masks en numpy si tensor
            if isinstance(masks, torch.Tensor):
                masks = masks.numpy()
            
            processing_time = time.perf_counter() - start_time
            
            return SegmentationResult(
                masks=masks,
                scores=scores,
                boxes=np.array(bounding_boxes),
                processing_time=processing_time
            )
            
        except Exception as e:
            logger.error(f"SAM2 segmentation failed: {e}")
            return self._fallback_segmentation(frame, bounding_boxes, start_time)
    
    @torch.inference_mode()
    def segment_objects_with_points(self, frame: np.ndarray, 
                                   input_points: List[List[List[float]]], 
                                   input_labels: List[List[int]],
                                   confidence_threshold: float = 0.8) -> SegmentationResult:
        """Segment objects using SAM2 with point prompts (following HF documentation)."""
        start_time = time.perf_counter()
        
        if self.model is None:
            return self._fallback_segmentation(frame, [], start_time)
        
        try:
            # Format selon documentation HF: input_points = [[[[500, 375]]]]
            formatted_points = [input_points]  # Wrap pour batch dimension
            formatted_labels = [input_labels]  # Wrap pour batch dimension
            
            # Prepare inputs selon documentation HF
            inputs = self.processor(
                images=frame,
                input_points=formatted_points,
                input_labels=formatted_labels,
                return_tensors="pt"
            ).to(self.device)
            
            # Forward pass
            with torch.autocast(self.device.type, dtype=torch.bfloat16):
                outputs = self.model(**inputs)
            
            # Post-processing selon documentation HF
            masks = self.processor.post_process_masks(
                outputs.pred_masks.cpu(), 
                inputs["original_sizes"]
            )[0]
            
            # Extraction des scores IoU
            scores = outputs.iou_scores.cpu().numpy().squeeze()
            
            # Prendre le meilleur masque
            if len(scores.shape) > 0 and scores.shape[0] > 1:
                best_mask_idx = torch.argmax(outputs.iou_scores.squeeze())
                masks = masks[best_mask_idx:best_mask_idx+1]
                scores = np.array([scores[best_mask_idx]])
            else:
                scores = np.array([scores.item()] if scores.ndim == 0 else scores)
            
            if isinstance(masks, torch.Tensor):
                masks = masks.numpy()
            
            processing_time = time.perf_counter() - start_time
            
            return SegmentationResult(
                masks=masks,
                scores=scores,
                boxes=np.array([]),  # Pas de boxes avec points
                processing_time=processing_time
            )
            
        except Exception as e:
            logger.error(f"SAM2 point segmentation failed: {e}")
            return self._fallback_segmentation(frame, [], start_time)
    
    def _fallback_segmentation(self, frame: np.ndarray, bounding_boxes: List[List[float]], 
                             start_time: float) -> SegmentationResult:
        """Fallback segmentation using traditional CV methods."""
        masks = []
        scores = []
        
        for box in bounding_boxes:
            x1, y1, x2, y2 = map(int, box)
            roi = frame[y1:y2, x1:x2]
            
            # Simple edge-based segmentation
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            
            # Create mask
            mask = np.zeros_like(gray)
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                cv2.fillPoly(mask, [largest_contour], 255)
            
            # Resize mask to full frame
            full_mask = np.zeros(frame.shape[:2], dtype=np.uint8)
            full_mask[y1:y2, x1:x2] = mask
            
            masks.append(full_mask)
            scores.append(0.5)  # Default confidence
        
        processing_time = time.perf_counter() - start_time
        
        return SegmentationResult(
            masks=np.array(masks),
            scores=np.array(scores),
            boxes=np.array(bounding_boxes),
            processing_time=processing_time,
            prompt_type=PromptType.BOUNDING_BOX
        )
    
    def get_mask_properties(self, mask: np.ndarray) -> Dict[str, Any]:
        """Extract properties from segmentation mask."""
        area = np.sum(mask > 0)
        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            return {"area": 0, "perimeter": 0, "compactness": 0, "solidity": 0}
        
        largest_contour = max(contours, key=cv2.contourArea)
        perimeter = cv2.arcLength(largest_contour, True)
        
        # Compactness (4π * area / perimeter²)
        compactness = (4 * np.pi * area) / (perimeter * perimeter) if perimeter > 0 else 0
        
        # Solidity (area / convex hull area)
        hull = cv2.convexHull(largest_contour)
        hull_area = cv2.contourArea(hull)
        solidity = area / hull_area if hull_area > 0 else 0
        
        return {
            "area": float(area),
            "perimeter": float(perimeter),
            "compactness": float(compactness),
            "solidity": float(solidity)
        }
    
    # Helper methods pour créer des prompts facilement
    @staticmethod
    def create_bbox_prompt(bounding_boxes: List[List[float]]) -> SegmentationPrompt:
        """Create bounding box prompt."""
        return SegmentationPrompt(
            prompt_type=PromptType.BOUNDING_BOX,
            bounding_boxes=bounding_boxes
        )
    
    @staticmethod
    def create_point_prompt(points: List[List[List[float]]], labels: List[List[int]]) -> SegmentationPrompt:
        """Create point prompt with labels (1=positive, 0=negative)."""
        return SegmentationPrompt(
            prompt_type=PromptType.POINTS,
            points=points,
            point_labels=labels
        )
    
    @staticmethod
    def create_mask_prompt(input_mask: np.ndarray) -> SegmentationPrompt:
        """Create mask prompt from previous segmentation."""
        return SegmentationPrompt(
            prompt_type=PromptType.MASK,
            input_masks=input_mask
        )
    
    @staticmethod
    def create_combined_prompt(bounding_boxes: Optional[List[List[float]]] = None,
                              points: Optional[List[List[List[float]]]] = None,
                              point_labels: Optional[List[List[int]]] = None,
                              input_masks: Optional[np.ndarray] = None) -> SegmentationPrompt:
        """Create combined prompt with multiple input types."""
        return SegmentationPrompt(
            prompt_type=PromptType.COMBINED,
            bounding_boxes=bounding_boxes,
            points=points,
            point_labels=point_labels,
            input_masks=input_masks
        )
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get information about loaded model."""
        return {
            "model_name": self.model_path,
            "device": str(self.device),
            "model_loaded": self._model_loaded,
            "lazy_loading": self.lazy_loading,
            "processor_available": self.processor is not None,
            "model_available": self.model is not None
        }