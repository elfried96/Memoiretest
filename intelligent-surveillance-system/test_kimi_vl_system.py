#!/usr/bin/env python3
"""
Test complet du systÃ¨me Kimi-VL intÃ©grÃ© avec switching multi-VLM.
Script de test pour valider l'intÃ©gration Kimi-VL-A3B-Thinking.
"""

import asyncio
import base64
import time
from pathlib import Path
from PIL import Image
from io import BytesIO
import json

from src.core.vlm.dynamic_model import DynamicVisionLanguageModel
from src.core.vlm.model_registry import VLMModelRegistry
from src.core.types import AnalysisRequest
from src.core.orchestrator.vlm_orchestrator import (
    ModernVLMOrchestrator, 
    OrchestrationConfig, 
    OrchestrationMode
)


def create_test_image() -> str:
    """CrÃ©e une image de test simple encodÃ©e en base64."""
    # CrÃ©ation d'une image de test simple
    image = Image.new('RGB', (640, 480), color='lightblue')
    
    # Ajout de formes simples pour test
    from PIL import ImageDraw, ImageFont
    draw = ImageDraw.Draw(image)
    
    # Rectangle (simule une personne)
    draw.rectangle([200, 150, 300, 400], outline='red', width=3)
    draw.text((210, 130), "Person", fill='red')
    
    # Cercle (simule un objet)
    draw.ellipse([400, 200, 500, 300], outline='blue', width=2)
    draw.text((420, 180), "Object", fill='blue')
    
    # Ligne (simule un mouvement)
    draw.line([150, 100, 450, 350], fill='green', width=2)
    draw.text((300, 220), "Movement", fill='green')
    
    # Conversion en base64
    buffer = BytesIO()
    image.save(buffer, format='PNG')
    image_data = base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    return image_data


async def test_model_registry():
    """Test du registre des modÃ¨les."""
    print("ğŸ” Test du Model Registry...")
    
    registry = VLMModelRegistry()
    
    # Liste des modÃ¨les disponibles
    models = registry.list_available_models()
    print(f"ğŸ“¦ ModÃ¨les enregistrÃ©s: {len(models)}")
    
    for model_id, config in models.items():
        print(f"  â€¢ {model_id} ({config.model_type.value}): {config.description}")
    
    # Test de validation des modÃ¨les
    print("\nğŸ” Validation des modÃ¨les:")
    for model_id in ["kimi-vl-a3b-thinking", "kimi-vl-a3b-instruct", "llava-v1.6-mistral-7b"]:
        is_available, message = registry.validate_model_availability(model_id)
        status = "âœ…" if is_available else "âŒ"
        print(f"  {status} {model_id}: {message}")
    
    # Recommandations
    print("\nğŸ’¡ Recommandations:")
    recommendations = registry.get_model_recommendations()
    for use_case, model in recommendations.items():
        print(f"  â€¢ {use_case}: {model}")
    
    return registry


async def test_dynamic_vlm():
    """Test du VLM dynamique avec Kimi-VL."""
    print("\nğŸ§  Test du VLM Dynamique...")
    
    # Initialisation avec Kimi-VL-A3B-Thinking comme dÃ©faut
    vlm = DynamicVisionLanguageModel(
        default_model="kimi-vl-a3b-thinking",
        enable_fallback=True
    )
    
    # Tentative de chargement
    print("â³ Chargement Kimi-VL-A3B-Thinking...")
    success = await vlm.load_model()
    
    if success:
        print("âœ… Kimi-VL chargÃ© avec succÃ¨s!")
        
        # Test d'analyse
        test_image = create_test_image()
        request = AnalysisRequest(
            frame_data=test_image,
            context={
                "location": "Test Store", 
                "camera": "CAM_TEST",
                "test_mode": True
            },
            tools_available=["dino_features", "pose_estimator", "multimodal_fusion"]
        )
        
        print("ğŸ” Test d'analyse avec Kimi-VL...")
        start_time = time.time()
        result = await vlm.analyze_with_tools(request, use_advanced_tools=True)
        processing_time = time.time() - start_time
        
        print(f"ğŸ“Š RÃ©sultat ({processing_time:.2f}s):")
        print(f"  â€¢ Suspicion: {result.suspicion_level.value}")
        print(f"  â€¢ Action: {result.action_type.value}")
        print(f"  â€¢ Confiance: {result.confidence:.2f}")
        print(f"  â€¢ Description: {result.description}")
        print(f"  â€¢ Outils utilisÃ©s: {result.tools_used}")
        
    else:
        print("âŒ Ã‰chec chargement Kimi-VL, test des fallbacks...")
        
        # Test fallback vers LLaVA
        print("â³ Test fallback LLaVA...")
        success_llava = await vlm.switch_model("llava-v1.6-mistral-7b")
        
        if success_llava:
            print("âœ… Fallback LLaVA rÃ©ussi!")
        else:
            print("âŒ Tous les modÃ¨les indisponibles")
    
    # Statut systÃ¨me
    print("\nğŸ“ˆ Statut du systÃ¨me:")
    status = vlm.get_system_status()
    print(f"  â€¢ ModÃ¨le actuel: {status['current_model']['model_id']}")
    print(f"  â€¢ Type: {status['current_model']['model_type']}")
    print(f"  â€¢ Device: {status['current_model']['device']}")
    print(f"  â€¢ CUDA disponible: {status['system']['cuda_available']}")
    
    return vlm


async def test_model_switching():
    """Test du switching entre modÃ¨les."""
    print("\nğŸ”„ Test du Model Switching...")
    
    vlm = DynamicVisionLanguageModel(enable_fallback=True)
    
    # Test de switching entre modÃ¨les
    models_to_test = [
        "kimi-vl-a3b-thinking",   # ModÃ¨le principal
        "kimi-vl-a3b-instruct",   # Variant instruct
        "llava-v1.6-mistral-7b",   # Fallback stable
        "qwen2-vl-7b-instruct"     # Alternative
    ]
    
    test_image = create_test_image()
    request = AnalysisRequest(
        frame_data=test_image,
        context={"location": "Switching Test"},
        tools_available=["dino_features"]
    )
    
    for model_id in models_to_test:
        print(f"\nğŸ“± Test switching vers {model_id}...")
        
        success = await vlm.switch_model(model_id)
        
        if success:
            print(f"âœ… Switch rÃ©ussi vers {model_id}")
            
            # Test rapide d'analyse
            try:
                start_time = time.time()
                result = await vlm.analyze_with_tools(request, use_advanced_tools=False)
                processing_time = time.time() - start_time
                
                print(f"  ğŸ“Š Analyse ({processing_time:.2f}s): {result.suspicion_level.value}")
                
            except Exception as e:
                print(f"  âŒ Erreur analyse: {e}")
        else:
            print(f"âŒ Switch Ã©chouÃ© vers {model_id}")
    
    return vlm


async def test_orchestrator():
    """Test de l'orchestrateur avec Kimi-VL."""
    print("\nğŸ® Test de l'Orchestrateur...")
    
    # Configuration pour test avec Kimi-VL
    config = OrchestrationConfig(
        mode=OrchestrationMode.BALANCED,
        enable_advanced_tools=True,
        max_concurrent_tools=4,
        confidence_threshold=0.6
    )
    
    # Initialisation avec Kimi-VL par dÃ©faut
    orchestrator = ModernVLMOrchestrator(
        vlm_model_name="kimi-vl-a3b-thinking",
        config=config
    )
    
    # Test d'analyse complÃ¨te
    test_image = create_test_image()
    
    print("ğŸ” Analyse orchestrÃ©e...")
    try:
        start_time = time.time()
        result = await orchestrator.analyze_surveillance_frame(
            frame_data=test_image,
            detections=[],  # Pas de dÃ©tections YOLO pour ce test
            context={
                "location": "Orchestrator Test Zone",
                "camera": "CAM_ORCH_01",
                "security_level": "high"
            }
        )
        processing_time = time.time() - start_time
        
        print(f"ğŸ“Š RÃ©sultat orchestrÃ© ({processing_time:.2f}s):")
        print(f"  â€¢ Suspicion: {result.suspicion_level.value}")
        print(f"  â€¢ Action: {result.action_type.value}")
        print(f"  â€¢ Confiance: {result.confidence:.2f}")
        print(f"  â€¢ Description: {result.description}")
        print(f"  â€¢ Outils: {result.tools_used}")
        print(f"  â€¢ Recommandations: {result.recommendations}")
        
    except Exception as e:
        print(f"âŒ Erreur orchestration: {e}")
    
    # Statut complet
    print("\nğŸ“ˆ Statut orchestrateur:")
    status = orchestrator.get_system_status()
    
    print(f"  â€¢ Mode: {status['orchestrator']['mode']}")
    print(f"  â€¢ Outils avancÃ©s: {status['orchestrator']['enable_advanced_tools']}")
    print(f"  â€¢ Analyses totales: {status['performance']['total_analyses']}")
    print(f"  â€¢ Taux succÃ¨s: {status['performance']['success_rate_percent']:.1f}%")
    
    # Health check
    health = await orchestrator.health_check()
    print(f"  â€¢ Health check: {health}")
    
    return orchestrator


async def test_batch_processing():
    """Test du traitement par batch."""
    print("\nğŸ“¦ Test Batch Processing...")
    
    vlm = DynamicVisionLanguageModel(
        default_model="kimi-vl-a3b-thinking",
        enable_fallback=True
    )
    
    success = await vlm.load_model()
    if not success:
        print("âŒ ModÃ¨le non chargÃ©, skip batch test")
        return
    
    # CrÃ©ation de plusieurs images de test
    test_images = []
    for i in range(3):
        image_data = create_test_image()
        test_images.append(AnalysisRequest(
            frame_data=image_data,
            context={
                "batch_id": f"batch_frame_{i}",
                "location": f"Zone_{i+1}"
            },
            tools_available=["dino_features", "pose_estimator"]
        ))
    
    print(f"ğŸ”„ Traitement batch de {len(test_images)} images...")
    start_time = time.time()
    
    # Traitement sÃ©quentiel pour comparaison
    results = []
    for request in test_images:
        result = await vlm.analyze_with_tools(request, use_advanced_tools=True)
        results.append(result)
    
    processing_time = time.time() - start_time
    
    print(f"ğŸ“Š Batch terminÃ© ({processing_time:.2f}s):")
    for i, result in enumerate(results):
        print(f"  Frame {i+1}: {result.suspicion_level.value} (conf: {result.confidence:.2f})")
    
    average_time = processing_time / len(results)
    print(f"  â€¢ Temps moyen/frame: {average_time:.2f}s")


async def main():
    """Fonction principale de test."""
    print("ğŸš€ Test Complet du SystÃ¨me Kimi-VL Multi-VLM")
    print("=" * 60)
    
    try:
        # Tests individuels
        await test_model_registry()
        await test_dynamic_vlm()
        await test_model_switching()
        await test_orchestrator()
        await test_batch_processing()
        
        print("\n" + "=" * 60)
        print("âœ… Tests terminÃ©s avec succÃ¨s!")
        
        print("\nğŸ’¡ Recommandations d'utilisation:")
        print("1. ğŸ¯ Utilisez kimi-vl-a3b-thinking pour surveillance principale")
        print("2. ğŸ”„ LLaVA comme fallback stable") 
        print("3. ğŸ§  Qwen2-VL pour analyses complexes")
        print("4. âš™ï¸ Mode BALANCED pour production")
        print("5. ğŸ›¡ï¸ Activez les fallbacks automatiques")
        
    except Exception as e:
        print(f"\nâŒ Erreur durant les tests: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())