{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üéØ Transfer Learning YOLO pour Surveillance\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elfried-kinzoun/intelligent-surveillance-system/blob/main/notebooks/2_transfer_learning_yolo.ipynb)\n",
    "\n",
    "**Objectif**: Adapter YOLO v8 pour la d√©tection sp√©cialis√©e en surveillance avec classes personnalis√©es et optimisations.\n",
    "\n",
    "## üéØ Ce que vous allez apprendre :\n",
    "- üìä **Pr√©paration dataset** YOLO surveillance\n",
    "- üîÑ **Transfer learning** depuis COCO vers surveillance\n",
    "- üé® **Classes personnalis√©es** pour objets de surveillance\n",
    "- üìà **Optimisation hyperparam√®tres** pour votre cas d'usage\n",
    "- üöÄ **D√©ploiement** mod√®le optimis√©\n",
    "\n",
    "## ‚öôÔ∏è Configuration Recommand√©e :\n",
    "- **GPU**: T4 (Colab gratuit) ou A100 (Colab Pro)\n",
    "- **RAM**: 8+ GB\n",
    "- **Temps**: 1-2 heures selon dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üöÄ Configuration Initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Installation des d√©pendances sp√©cialis√©es pour YOLO\n",
    "!pip install -q ultralytics==8.0.0\n",
    "!pip install -q opencv-python-headless>=4.8.0\n",
    "!pip install -q pillow>=10.0.0\n",
    "!pip install -q matplotlib>=3.7.0\n",
    "!pip install -q seaborn>=0.12.0\n",
    "!pip install -q wandb  # Weights & Biases pour tracking\n",
    "!pip install -q albumentations>=1.3.0  # Augmentation de donn√©es\n",
    "!pip install -q roboflow  # Dataset management\n",
    "!pip install -q supervision  # Visualisation et m√©triques\n",
    "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Installation du projet principal\n",
    "!git clone -q https://github.com/elfried-kinzoun/intelligent-surveillance-system.git\n",
    "%cd intelligent-surveillance-system\n",
    "!pip install -q -e .\n",
    "\n",
    "print(\"‚úÖ Installation termin√©e!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# V√©rification GPU et configuration\n",
    "print(f\"üî• PyTorch: {torch.__version__}\")\n",
    "print(f\"üéØ Ultralytics: {ultralytics.__version__}\")\n",
    "print(f\"üéÆ CUDA disponible: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"üéØ GPU: {gpu_name}\")\n",
    "    print(f\"üíæ M√©moire GPU: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Configuration optimale selon GPU\n",
    "    if \"T4\" in gpu_name:\n",
    "        TRAINING_CONFIG = {\n",
    "            \"model_size\": \"yolov8n.pt\",  # Nano pour T4\n",
    "            \"batch_size\": 16,\n",
    "            \"image_size\": 640,\n",
    "            \"epochs\": 50,\n",
    "            \"patience\": 10\n",
    "        }\n",
    "        print(\"üí° Configuration T4 optimis√©e\")\n",
    "    elif \"A100\" in gpu_name or \"V100\" in gpu_name:\n",
    "        TRAINING_CONFIG = {\n",
    "            \"model_size\": \"yolov8m.pt\",  # Medium pour GPU puissants\n",
    "            \"batch_size\": 32,\n",
    "            \"image_size\": 800,\n",
    "            \"epochs\": 100,\n",
    "            \"patience\": 15\n",
    "        }\n",
    "        print(\"üöÄ Configuration haute performance\")\n",
    "    else:\n",
    "        TRAINING_CONFIG = {\n",
    "            \"model_size\": \"yolov8s.pt\",  # Small par d√©faut\n",
    "            \"batch_size\": 24,\n",
    "            \"image_size\": 640,\n",
    "            \"epochs\": 75,\n",
    "            \"patience\": 12\n",
    "        }\n",
    "        print(\"‚öôÔ∏è Configuration standard\")\nelse:\n",
    "    print(\"‚ö†Ô∏è GPU non disponible - Entra√Ænement CPU (tr√®s lent)\")\n",
    "    TRAINING_CONFIG = {\n",
    "        \"model_size\": \"yolov8n.pt\",\n",
    "        \"batch_size\": 4,\n",
    "        \"image_size\": 416,\n",
    "        \"epochs\": 10,\n",
    "        \"patience\": 5\n",
    "    }\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Configuration s√©lectionn√©e:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Configuration des chemins\n",
    "DATA_DIR = Path(\"./data/surveillance_dataset\")\n",
    "MODELS_DIR = Path(\"./models\")\n",
    "RESULTS_DIR = Path(\"./results\")\n",
    "\n",
    "# Cr√©ation des r√©pertoires\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÅ R√©pertoires configur√©s:\")\n",
    "print(f\"  Data: {DATA_DIR}\")\n",
    "print(f\"  Models: {MODELS_DIR}\")\n",
    "print(f\"  Results: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_wandb"
   },
   "outputs": [],
   "source": [
    "# Configuration Weights & Biases pour tracking\n",
    "import wandb\n",
    "\n",
    "PROJECT_NAME = \"surveillance-yolo-transfer\"\n",
    "RUN_NAME = f\"yolo-surveillance-{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "\n",
    "# Initialisation W&B (optionnel)\n",
    "try:\n",
    "    # D√©commentez si vous avez un compte W&B\n",
    "    # wandb.login()\n",
    "    \n",
    "    wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        name=RUN_NAME,\n",
    "        config=TRAINING_CONFIG,\n",
    "        mode=\"offline\"  # Changez en \"online\" si compte W&B configur√©\n",
    "    )\n",
    "    print(\"‚úÖ W&B configur√©\")\nexcept Exception as e:\n",
    "    print(f\"‚ö†Ô∏è W&B en mode offline: {e}\")\n",
    "    os.environ[\"WANDB_MODE\"] = \"offline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset"
   },
   "source": [
    "## üìä Pr√©paration du Dataset de Surveillance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "define_classes"
   },
   "outputs": [],
   "source": [
    "# D√©finition des classes sp√©cialis√©es pour la surveillance\n",
    "SURVEILLANCE_CLASSES = {\n",
    "    # Classes principales COCO adapt√©es\n",
    "    0: \"person\",\n",
    "    1: \"handbag\",\n",
    "    2: \"backpack\", \n",
    "    3: \"suitcase\",\n",
    "    4: \"bottle\",\n",
    "    5: \"cup\",\n",
    "    6: \"cell_phone\",\n",
    "    7: \"book\",\n",
    "    \n",
    "    # Classes sp√©cialis√©es surveillance\n",
    "    8: \"shopping_cart\",\n",
    "    9: \"shopping_basket\",\n",
    "    10: \"suspicious_object\",\n",
    "    11: \"security_camera\",\n",
    "    12: \"cash_register\",\n",
    "    13: \"product_shelf\",\n",
    "    14: \"entrance_exit\",\n",
    "    15: \"staff_uniform\"\n",
    "}\n",
    "\n",
    "# Configuration YAML pour YOLO\n",
    "dataset_yaml = f\"\"\"\n",
    "# Dataset de surveillance personnalis√©\n",
    "path: {DATA_DIR.absolute()}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "# Classes de surveillance\n",
    "names:\n",
    "\"\"\"\n",
    "\n",
    "for class_id, class_name in SURVEILLANCE_CLASSES.items():\n",
    "    dataset_yaml += f\"  {class_id}: {class_name}\\n\"\n",
    "\n",
    "print(\"üéØ Classes de surveillance d√©finies:\")\n",
    "for class_id, class_name in SURVEILLANCE_CLASSES.items():\n",
    "    print(f\"  {class_id}: {class_name}\")\n",
    "\n",
    "# Sauvegarde du fichier YAML\n",
    "yaml_path = DATA_DIR / \"dataset.yaml\"\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    f.write(dataset_yaml)\n",
    "\n",
    "print(f\"\\n‚úÖ Configuration dataset sauvegard√©e: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_synthetic_dataset"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "\n",
    "def create_surveillance_dataset(num_images=200):\n",
    "    \"\"\"\n",
    "    Cr√©e un dataset de surveillance synth√©tique pour la d√©monstration.\n",
    "    En production, utilisez vos vraies donn√©es annot√©es.\n",
    "    \"\"\"\n",
    "    \n",
    "    # URLs d'images de d√©monstration (stores, shopping, etc.)\n",
    "    base_images = [\n",
    "        \"https://images.unsplash.com/photo-1556742049-0cfed4f6a45d?w=640\",  # Store\n",
    "        \"https://images.unsplash.com/photo-1441986300917-64674bd600d8?w=640\",  # Shopping\n",
    "        \"https://images.unsplash.com/photo-1472851294608-062f824d29cc?w=640\",  # Retail\n",
    "        \"https://images.unsplash.com/photo-1560472354-b33ff0c44a43?w=640\",  # Supermarket\n",
    "        \"https://images.unsplash.com/photo-1578662996442-48f60103fc96?w=640\",  # Store aisle\n",
    "        \"https://images.unsplash.com/photo-1607083206869-4c7672e72a8a?w=640\",  # Shopping mall\n",
    "        \"https://images.unsplash.com/photo-1596810375465-7846b8b5e0cf?w=640\",  # Store interior\n",
    "        \"https://images.unsplash.com/photo-1534723328310-e82dad3ee43f?w=640\",  # Grocery\n",
    "    ]\n",
    "    \n",
    "    # Cr√©ation des dossiers\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        (DATA_DIR / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
    "        (DATA_DIR / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Division du dataset\n",
    "    train_size = int(0.7 * num_images)\n",
    "    val_size = int(0.2 * num_images)\n",
    "    test_size = num_images - train_size - val_size\n",
    "    \n",
    "    print(f\"üìä G√©n√©ration dataset ({num_images} images):\")\n",
    "    print(f\"  Train: {train_size} | Val: {val_size} | Test: {test_size}\")\n",
    "    \n",
    "    dataset_info = {\"train\": [], \"val\": [], \"test\": []}\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # D√©termination du split\n",
    "        if i < train_size:\n",
    "            split = \"train\"\n",
    "        elif i < train_size + val_size:\n",
    "            split = \"val\"\n",
    "        else:\n",
    "            split = \"test\"\n",
    "        \n",
    "        try:\n",
    "            # S√©lection d'une image de base al√©atoire\n",
    "            base_url = random.choice(base_images)\n",
    "            \n",
    "            # T√©l√©chargement (avec cache simple)\n",
    "            cache_file = DATA_DIR / f\"cache_{abs(hash(base_url)) % 1000}.jpg\"\n",
    "            if not cache_file.exists():\n",
    "                response = requests.get(base_url, timeout=10)\n",
    "                if response.status_code == 200:\n",
    "                    with open(cache_file, 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Erreur t√©l√©chargement: {base_url}\")\n",
    "                    continue\n",
    "            \n",
    "            # Chargement et pr√©paration de l'image\n",
    "            image = Image.open(cache_file).convert(\"RGB\")\n",
    "            image = image.resize((TRAINING_CONFIG[\"image_size\"], TRAINING_CONFIG[\"image_size\"]), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Nom de fichier unique\n",
    "            filename = f\"surveillance_{split}_{i:04d}.jpg\"\n",
    "            \n",
    "            # Sauvegarde de l'image\n",
    "            image_path = DATA_DIR / 'images' / split / filename\n",
    "            image.save(image_path, quality=90)\n",
    "            \n",
    "            # G√©n√©ration d'annotations synth√©tiques\n",
    "            annotations = generate_synthetic_annotations(image.size, i)\n",
    "            \n",
    "            # Sauvegarde des labels YOLO\n",
    "            label_path = DATA_DIR / 'labels' / split / filename.replace('.jpg', '.txt')\n",
    "            with open(label_path, 'w') as f:\n",
    "                for ann in annotations:\n",
    "                    f.write(f\"{ann['class_id']} {ann['x_center']:.6f} {ann['y_center']:.6f} {ann['width']:.6f} {ann['height']:.6f}\\n\")\n",
    "            \n",
    "            dataset_info[split].append({\n",
    "                \"filename\": filename,\n",
    "                \"annotations_count\": len(annotations),\n",
    "                \"classes\": [ann['class_id'] for ann in annotations]\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur image {i}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"  üì∑ {i + 1}/{num_images} images g√©n√©r√©es\")\n",
    "    \n",
    "    return dataset_info\n",
    "\n",
    "def generate_synthetic_annotations(image_size, seed):\n",
    "    \"\"\"\n",
    "    G√©n√®re des annotations synth√©tiques r√©alistes.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    annotations = []\n",
    "    width, height = image_size\n",
    "    \n",
    "    # Nombre d'objets al√©atoire (1-5)\n",
    "    num_objects = random.randint(1, 5)\n",
    "    \n",
    "    for _ in range(num_objects):\n",
    "        # S√©lection d'une classe selon des probabilit√©s r√©alistes\n",
    "        class_probs = {\n",
    "            0: 0.4,   # person (tr√®s commun)\n",
    "            1: 0.15,  # handbag\n",
    "            2: 0.1,   # backpack\n",
    "            4: 0.08,  # bottle\n",
    "            6: 0.05,  # cell_phone\n",
    "            8: 0.1,   # shopping_cart\n",
    "            13: 0.12  # product_shelf\n",
    "        }\n",
    "        \n",
    "        class_id = np.random.choice(\n",
    "            list(class_probs.keys()), \n",
    "            p=list(class_probs.values())\n",
    "        )\n",
    "        \n",
    "        # G√©n√©ration de bbox r√©aliste selon la classe\n",
    "        if class_id == 0:  # person\n",
    "            w = random.uniform(0.1, 0.3)  # Largeur relative\n",
    "            h = random.uniform(0.4, 0.8)  # Hauteur relative\n",
    "        elif class_id in [1, 2]:  # bags\n",
    "            w = random.uniform(0.05, 0.15)\n",
    "            h = random.uniform(0.05, 0.15)\n",
    "        elif class_id == 8:  # shopping_cart\n",
    "            w = random.uniform(0.15, 0.25)\n",
    "            h = random.uniform(0.2, 0.35)\n",
    "        elif class_id == 13:  # product_shelf\n",
    "            w = random.uniform(0.3, 0.8)\n",
    "            h = random.uniform(0.2, 0.6)\n",
    "        else:\n",
    "            w = random.uniform(0.03, 0.12)\n",
    "            h = random.uniform(0.03, 0.12)\n",
    "        \n",
    "        # Position al√©atoire en √©vitant les bords\n",
    "        x_center = random.uniform(w/2 + 0.05, 1 - w/2 - 0.05)\n",
    "        y_center = random.uniform(h/2 + 0.05, 1 - h/2 - 0.05)\n",
    "        \n",
    "        annotations.append({\n",
    "            \"class_id\": class_id,\n",
    "            \"x_center\": x_center,\n",
    "            \"y_center\": y_center,\n",
    "            \"width\": w,\n",
    "            \"height\": h\n",
    "        })\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "# G√©n√©ration du dataset\n",
    "print(\"üèóÔ∏è Cr√©ation du dataset de surveillance...\")\n",
    "dataset_info = create_surveillance_dataset(num_images=100)  # R√©duire pour d√©mo rapide\n",
    "\n",
    "print(\"\\nüìä Statistiques du dataset:\")\n",
    "for split, info in dataset_info.items():\n",
    "    total_annotations = sum(item[\"annotations_count\"] for item in info)\n",
    "    print(f\"  {split.upper()}: {len(info)} images, {total_annotations} annotations\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset cr√©√© avec succ√®s!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize_dataset"
   },
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def visualize_dataset_samples(num_samples=6):\n",
    "    \"\"\"\n",
    "    Visualise des √©chantillons du dataset avec annotations.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # S√©lection d'√©chantillons du train set\n",
    "    train_images = list((DATA_DIR / 'images' / 'train').glob('*.jpg'))\n",
    "    selected_images = random.sample(train_images, min(num_samples, len(train_images)))\n",
    "    \n",
    "    for i, image_path in enumerate(selected_images):\n",
    "        # Chargement de l'image\n",
    "        image = cv2.imread(str(image_path))\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Chargement des annotations\n",
    "        label_path = DATA_DIR / 'labels' / 'train' / (image_path.stem + '.txt')\n",
    "        \n",
    "        ax = axes[i]\n",
    "        ax.imshow(image_rgb)\n",
    "        \n",
    "        if label_path.exists():\n",
    "            with open(label_path, 'r') as f:\n",
    "                annotations = f.readlines()\n",
    "            \n",
    "            h, w = image_rgb.shape[:2]\n",
    "            \n",
    "            for ann in annotations:\n",
    "                parts = ann.strip().split()\n",
    "                if len(parts) == 5:\n",
    "                    class_id, x_center, y_center, width, height = map(float, parts)\n",
    "                    class_id = int(class_id)\n",
    "                    \n",
    "                    # Conversion vers coordonn√©es absolues\n",
    "                    x1 = int((x_center - width/2) * w)\n",
    "                    y1 = int((y_center - height/2) * h)\n",
    "                    x2 = int((x_center + width/2) * w)\n",
    "                    y2 = int((y_center + height/2) * h)\n",
    "                    \n",
    "                    # Dessin du rectangle\n",
    "                    rect = patches.Rectangle(\n",
    "                        (x1, y1), x2-x1, y2-y1,\n",
    "                        linewidth=2, \n",
    "                        edgecolor=plt.cm.Set3(class_id / len(SURVEILLANCE_CLASSES)),\n",
    "                        facecolor='none'\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "                    \n",
    "                    # Label de classe\n",
    "                    class_name = SURVEILLANCE_CLASSES.get(class_id, f\"class_{class_id}\")\n",
    "                    ax.text(\n",
    "                        x1, y1-5, class_name,\n",
    "                        color=plt.cm.Set3(class_id / len(SURVEILLANCE_CLASSES)),\n",
    "                        fontsize=8, fontweight='bold',\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.7)\n",
    "                    )\n",
    "        \n",
    "        ax.set_title(f\"Sample {i+1}: {image_path.name}\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"üìä √âchantillons du Dataset de Surveillance\", fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Analyse des classes\n",
    "def analyze_dataset_distribution():\n",
    "    \"\"\"\n",
    "    Analyse la distribution des classes dans le dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    class_counts = {class_id: 0 for class_id in SURVEILLANCE_CLASSES.keys()}\n",
    "    \n",
    "    # Parcours de tous les fichiers de labels\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        labels_dir = DATA_DIR / 'labels' / split\n",
    "        if labels_dir.exists():\n",
    "            for label_file in labels_dir.glob('*.txt'):\n",
    "                with open(label_file, 'r') as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) >= 1:\n",
    "                            class_id = int(float(parts[0]))\n",
    "                            if class_id in class_counts:\n",
    "                                class_counts[class_id] += 1\n",
    "    \n",
    "    # Visualisation de la distribution\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    class_names = [SURVEILLANCE_CLASSES[cid] for cid in sorted(class_counts.keys())]\n",
    "    counts = [class_counts[cid] for cid in sorted(class_counts.keys())]\n",
    "    \n",
    "    bars = plt.bar(class_names, counts, alpha=0.8)\n",
    "    plt.title('üìä Distribution des Classes dans le Dataset')\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Nombre d\\'Annotations')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Ajout des valeurs sur les barres\n",
    "    for bar, count in zip(bars, counts):\n",
    "        if count > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,\n",
    "                    f'{count}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# Visualisation des √©chantillons\n",
    "print(\"üñºÔ∏è Visualisation des √©chantillons du dataset...\")\n",
    "visualize_dataset_samples()\n",
    "\n",
    "# Analyse de la distribution\n",
    "print(\"\\nüìà Analyse de la distribution des classes...\")\n",
    "class_distribution = analyze_dataset_distribution()\n",
    "\n",
    "print(\"\\nüìä R√©sum√© de la distribution:\")\n",
    "total_annotations = sum(class_distribution.values())\n",
    "for class_id, count in class_distribution.items():\n",
    "    if count > 0:\n",
    "        percentage = (count / total_annotations) * 100\n",
    "        print(f\"  {SURVEILLANCE_CLASSES[class_id]}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total annotations: {total_annotations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_setup"
   },
   "source": [
    "## üß† Configuration du Mod√®le YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_pretrained_model"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Chargement du mod√®le pr√©-entra√Æn√©\n",
    "model_size = TRAINING_CONFIG[\"model_size\"]\n",
    "print(f\"üß† Chargement du mod√®le YOLO: {model_size}\")\n",
    "\n",
    "# T√©l√©chargement et chargement du mod√®le\n",
    "model = YOLO(model_size)\n",
    "\n",
    "print(f\"‚úÖ Mod√®le {model_size} charg√©\")\n",
    "print(f\"üìä Nombre de classes COCO originales: {len(model.names)}\")\n",
    "print(f\"üìä Nouvelles classes surveillance: {len(SURVEILLANCE_CLASSES)}\")\n",
    "\n",
    "# Information sur le mod√®le\n",
    "model_info = model.info(verbose=False)\n",
    "print(f\"\\nüîß Architecture du mod√®le:\")\n",
    "print(f\"  Param√®tres: ~{sum(p.numel() for p in model.model.parameters())/1e6:.1f}M\")\n",
    "print(f\"  GFLOPS: {model.model.model[-1].anchors.numel() if hasattr(model.model.model[-1], 'anchors') else 'N/A'}\")\n",
    "print(f\"  Device: {next(model.model.parameters()).device}\")\n",
    "\n",
    "# V√©rification GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ Mod√®le sur GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"üíæ M√©moire GPU utilis√©e: {torch.cuda.memory_allocated()/1e9:.1f} GB\")\nelse:\n",
    "    print(\"‚ö†Ô∏è Mod√®le sur CPU\")\n",
    "\n",
    "# Test de pr√©diction pour v√©rifier le fonctionnement\n",
    "print(\"\\nüß™ Test de pr√©diction...\")\n",
    "test_image_path = list((DATA_DIR / 'images' / 'train').glob('*.jpg'))[0]\n",
    "test_results = model.predict(test_image_path, verbose=False)\n",
    "print(f\"‚úÖ Test r√©ussi - {len(test_results[0].boxes)} d√©tections initiales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "configure_training"
   },
   "outputs": [],
   "source": [
    "# Configuration avanc√©e pour l'entra√Ænement\n",
    "training_args = {\n",
    "    # Dataset\n",
    "    \"data\": str(yaml_path),\n",
    "    \n",
    "    # Hyperparam√®tres de base\n",
    "    \"epochs\": TRAINING_CONFIG[\"epochs\"],\n",
    "    \"batch\": TRAINING_CONFIG[\"batch_size\"],\n",
    "    \"imgsz\": TRAINING_CONFIG[\"image_size\"],\n",
    "    \n",
    "    # Optimiseur\n",
    "    \"optimizer\": \"AdamW\",  # AdamW g√©n√©ralement meilleur que SGD\n",
    "    \"lr0\": 0.001,  # Learning rate initial\n",
    "    \"lrf\": 0.01,   # Learning rate final (lr0 * lrf)\n",
    "    \"momentum\": 0.937,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \n",
    "    # Scheduler\n",
    "    \"warmup_epochs\": 3,\n",
    "    \"warmup_momentum\": 0.8,\n",
    "    \"warmup_bias_lr\": 0.1,\n",
    "    \n",
    "    # Augmentation de donn√©es\n",
    "    \"hsv_h\": 0.015,      # Hue augmentation\n",
    "    \"hsv_s\": 0.7,        # Saturation augmentation  \n",
    "    \"hsv_v\": 0.4,        # Value augmentation\n",
    "    \"degrees\": 0.0,      # Rotation (disabled pour surveillance)\n",
    "    \"translate\": 0.1,    # Translation\n",
    "    \"scale\": 0.5,        # Scale augmentation\n",
    "    \"shear\": 0.0,        # Shear (disabled)\n",
    "    \"perspective\": 0.0,  # Perspective (disabled)\n",
    "    \"flipud\": 0.0,       # Flip up-down (disabled)\n",
    "    \"fliplr\": 0.5,       # Flip left-right\n",
    "    \"mosaic\": 1.0,       # Mosaic augmentation\n",
    "    \"mixup\": 0.0,        # Mixup augmentation (disabled)\n",
    "    \"copy_paste\": 0.0,   # Copy-paste augmentation (disabled)\n",
    "    \n",
    "    # Loss function\n",
    "    \"box\": 7.5,          # Box loss gain\n",
    "    \"cls\": 0.5,          # Class loss gain  \n",
    "    \"dfl\": 1.5,          # DFL loss gain\n",
    "    \n",
    "    # Validation et sauvegarde\n",
    "    \"patience\": TRAINING_CONFIG[\"patience\"],\n",
    "    \"save\": True,\n",
    "    \"save_period\": 10,   # Sauvegarder chaque 10 √©poques\n",
    "    \"cache\": \"ram\",      # Cache en RAM pour acc√©l√©rer\n",
    "    \n",
    "    # Monitoring\n",
    "    \"project\": str(RESULTS_DIR),\n",
    "    \"name\": f\"surveillance_yolo_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n",
    "    \"verbose\": True,\n",
    "    \"plots\": True,       # G√©n√©rer les plots automatiquement\n",
    "    \n",
    "    # Performance\n",
    "    \"workers\": 8 if torch.cuda.is_available() else 2,\n",
    "    \"device\": 0 if torch.cuda.is_available() else \"cpu\",\n",
    "}\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration d'entra√Ænement:\")\n",
    "for key, value in training_args.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Estimation du temps d'entra√Ænement\n",
    "dataset_size = sum(len(info) for info in dataset_info.values())\n",
    "estimated_time_per_epoch = (dataset_size / TRAINING_CONFIG[\"batch_size\"]) * 0.5  # 0.5s par batch estim√©\n",
    "total_estimated_time = estimated_time_per_epoch * TRAINING_CONFIG[\"epochs\"] / 60\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Estimation temps d'entra√Ænement:\")\n",
    "print(f\"  ~{estimated_time_per_epoch:.1f}s par √©poque\")\n",
    "print(f\"  ~{total_estimated_time:.1f} minutes au total\")\n",
    "print(f\"  Dataset: {dataset_size} images\")\n",
    "print(f\"  Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "\n",
    "# V√©rification de la m√©moire GPU si disponible\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    allocated_memory = torch.cuda.memory_allocated() / 1e9\n",
    "    print(f\"\\nüíæ M√©moire GPU: {allocated_memory:.1f}/{gpu_memory:.1f} GB\")\n",
    "    \n",
    "    if allocated_memory / gpu_memory > 0.8:\n",
    "        print(\"‚ö†Ô∏è M√©moire GPU √©lev√©e - R√©duisez batch_size si n√©cessaire\")\n",
    "    else:\n",
    "        print(\"‚úÖ M√©moire GPU OK pour l'entra√Ænement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## üöÄ Lancement de l'Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start_training"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üöÄ D√âBUT DE L'ENTRA√éNEMENT YOLO\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üïê Heure de d√©but: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üìä Mod√®le: {model_size}\")\n",
    "print(f\"üìà √âpoques: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"üì¶ Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"üñºÔ∏è Image size: {TRAINING_CONFIG['image_size']}\")\n",
    "print(f\"üíæ Dataset: {sum(len(info) for info in dataset_info.values())} images\")\n",
    "print()\n",
    "\n",
    "# Sauvegarde des m√©triques initiales\n",
    "start_time = time.time()\n",
    "initial_gpu_memory = torch.cuda.memory_allocated() / 1e9 if torch.cuda.is_available() else 0\n",
    "\n",
    "try:\n",
    "    # Lancement de l'entra√Ænement\n",
    "    print(\"üìö D√©marrage de l'entra√Ænement...\")\n",
    "    print(\"üìä M√©triques √† surveiller: mAP50, mAP50-95, Precision, Recall\")\n",
    "    print(\"‚ö†Ô∏è  L'entra√Ænement peut prendre du temps selon votre GPU...\")\n",
    "    print()\n",
    "    \n",
    "    # Entra√Ænement du mod√®le\n",
    "    results = model.train(**training_args)\n",
    "    \n",
    "    # Calcul du temps d'entra√Ænement\n",
    "    end_time = time.time()\n",
    "    training_duration = end_time - start_time\n",
    "    final_gpu_memory = torch.cuda.memory_allocated() / 1e9 if torch.cuda.is_available() else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üéâ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS !\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"üïê Dur√©e totale: {training_duration/60:.1f} minutes\")\n",
    "    print(f\"‚ö° Temps par √©poque: {training_duration/TRAINING_CONFIG['epochs']:.1f}s\")\n",
    "    print(f\"üíæ M√©moire GPU finale: {final_gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Extraction des m√©triques finales\n",
    "    if hasattr(results, 'results_dict'):\n",
    "        metrics = results.results_dict\n",
    "        print(f\"\\nüìä M√©triques finales:\")\n",
    "        if 'metrics/mAP50(B)' in metrics:\n",
    "            print(f\"  mAP@0.5: {metrics['metrics/mAP50(B)']:.3f}\")\n",
    "        if 'metrics/mAP50-95(B)' in metrics:\n",
    "            print(f\"  mAP@0.5-0.95: {metrics['metrics/mAP50-95(B)']:.3f}\")\n",
    "        if 'metrics/precision(B)' in metrics:\n",
    "            print(f\"  Pr√©cision: {metrics['metrics/precision(B)']:.3f}\")\n",
    "        if 'metrics/recall(B)' in metrics:\n",
    "            print(f\"  Rappel: {metrics['metrics/recall(B)']:.3f}\")\n",
    "    \n",
    "    # Sauvegarde du mod√®le final\n",
    "    model_save_path = MODELS_DIR / f\"surveillance_yolo_{datetime.now().strftime('%Y%m%d_%H%M')}.pt\"\n",
    "    model.save(model_save_path)\n",
    "    print(f\"\\nüíæ Mod√®le sauvegard√©: {model_save_path}\")\n",
    "    \n",
    "    # Log vers W&B si configur√©\n",
    "    if 'wandb' in globals() and wandb.run:\n",
    "        wandb.log({\n",
    "            \"training_duration_minutes\": training_duration/60,\n",
    "            \"final_gpu_memory_gb\": final_gpu_memory,\n",
    "            \"model_size\": model_size,\n",
    "            \"dataset_size\": sum(len(info) for info in dataset_info.values())\n",
    "        })\n",
    "    \n",
    "    training_success = True\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"\\n‚ùå ERREUR PENDANT L'ENTRA√éNEMENT: {e}\")\n",
    "    print(\"\\nüí° Solutions possibles:\")\n",
    "    print(\"  - R√©duire le batch_size\")\n",
    "    print(\"  - R√©duire la taille d'image (imgsz)\")\n",
    "    print(\"  - Utiliser un mod√®le plus petit (yolov8n.pt)\")\n",
    "    print(\"  - V√©rifier le format du dataset\")\n",
    "    print(\"  - Lib√©rer la m√©moire GPU\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"üßπ Cache GPU vid√©\")\n",
    "    \n",
    "    training_success = False\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## üìä √âvaluation du Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_model"
   },
   "outputs": [],
   "source": [
    "# √âvaluation compl√®te du mod√®le entra√Æn√©\n",
    "print(\"üìä √âVALUATION DU MOD√àLE ENTRA√éN√â\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if training_success:\n",
    "    # √âvaluation sur le set de validation\n",
    "    print(\"üìà √âvaluation sur le set de validation...\")\n",
    "    \n",
    "    try:\n",
    "        # Validation metrics\n",
    "        val_results = model.val(data=str(yaml_path), split='val')\n",
    "        \n",
    "        print(\"\\nüìä M√©triques de validation:\")\n",
    "        if hasattr(val_results, 'results_dict'):\n",
    "            metrics = val_results.results_dict\n",
    "            for key, value in metrics.items():\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"  {key}: {value:.4f}\")\n",
    "        \n",
    "        # M√©triques par classe si disponibles\n",
    "        if hasattr(val_results, 'ap_class_index'):\n",
    "            print(\"\\nüìã M√©triques par classe:\")\n",
    "            for i, class_idx in enumerate(val_results.ap_class_index):\n",
    "                if class_idx in SURVEILLANCE_CLASSES:\n",
    "                    class_name = SURVEILLANCE_CLASSES[class_idx]\n",
    "                    ap50 = val_results.ap50[i] if hasattr(val_results, 'ap50') else 0\n",
    "                    print(f\"  {class_name}: AP@0.5 = {ap50:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur √©valuation: {e}\")\n",
    "    \n",
    "    # Test sur quelques images\n",
    "    print(\"\\nüß™ Test sur images de validation...\")\n",
    "    \n",
    "    val_images = list((DATA_DIR / 'images' / 'val').glob('*.jpg'))[:6]\n",
    "    \n",
    "    if val_images:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, image_path in enumerate(val_images):\n",
    "            # Pr√©diction\n",
    "            results = model.predict(image_path, conf=0.25, verbose=False)\n",
    "            \n",
    "            # Chargement de l'image\n",
    "            image = cv2.imread(str(image_path))\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            ax = axes[i]\n",
    "            ax.imshow(image_rgb)\n",
    "            \n",
    "            # Affichage des pr√©dictions\n",
    "            if len(results[0].boxes) > 0:\n",
    "                boxes = results[0].boxes\n",
    "                for j in range(len(boxes)):\n",
    "                    # Coordonn√©es de la bo√Æte\n",
    "                    x1, y1, x2, y2 = boxes.xyxy[j].cpu().numpy()\n",
    "                    conf = boxes.conf[j].cpu().numpy()\n",
    "                    cls = int(boxes.cls[j].cpu().numpy())\n",
    "                    \n",
    "                    # Dessin du rectangle\n",
    "                    rect = patches.Rectangle(\n",
    "                        (x1, y1), x2-x1, y2-y1,\n",
    "                        linewidth=2,\n",
    "                        edgecolor='red',\n",
    "                        facecolor='none'\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "                    \n",
    "                    # Label avec confiance\n",
    "                    class_name = SURVEILLANCE_CLASSES.get(cls, f\"class_{cls}\")\n",
    "                    ax.text(\n",
    "                        x1, y1-5, f\"{class_name}: {conf:.2f}\",\n",
    "                        color='red', fontsize=8, fontweight='bold',\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='yellow', alpha=0.7)\n",
    "                    )\n",
    "            \n",
    "            ax.set_title(f\"Pr√©dictions: {image_path.name}\")\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(\"üéØ Pr√©dictions du Mod√®le sur Set de Validation\", fontsize=16, y=1.02)\n",
    "        plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pas d'√©valuation possible - Entra√Ænement √©chou√©\")\n",
    "\n",
    "print(\"\\n‚úÖ √âvaluation termin√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compare_models"
   },
   "outputs": [],
   "source": [
    "# Comparaison avec le mod√®le pr√©-entra√Æn√© COCO\n",
    "print(\"üÜö COMPARAISON MOD√àLE COCO vs SURVEILLANCE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if training_success:\n",
    "    # Chargement du mod√®le COCO original pour comparaison\n",
    "    coco_model = YOLO(model_size)\n",
    "    \n",
    "    # Test sur une image de validation\n",
    "    test_image = list((DATA_DIR / 'images' / 'val').glob('*.jpg'))[0]\n",
    "    \n",
    "    print(f\"üñºÔ∏è Test comparatif sur: {test_image.name}\")\n",
    "    \n",
    "    # Pr√©dictions mod√®le COCO\n",
    "    coco_results = coco_model.predict(test_image, conf=0.25, verbose=False)\n",
    "    \n",
    "    # Pr√©dictions mod√®le surveillance\n",
    "    surveillance_results = model.predict(test_image, conf=0.25, verbose=False)\n",
    "    \n",
    "    # Comparaison visuelle\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    # Chargement de l'image\n",
    "    image = cv2.imread(str(test_image))\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Mod√®le COCO\n",
    "    ax1.imshow(image_rgb)\n",
    "    if len(coco_results[0].boxes) > 0:\n",
    "        boxes = coco_results[0].boxes\n",
    "        for j in range(len(boxes)):\n",
    "            x1, y1, x2, y2 = boxes.xyxy[j].cpu().numpy()\n",
    "            conf = boxes.conf[j].cpu().numpy()\n",
    "            cls = int(boxes.cls[j].cpu().numpy())\n",
    "            \n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1), x2-x1, y2-y1,\n",
    "                linewidth=2, edgecolor='blue', facecolor='none'\n",
    "            )\n",
    "            ax1.add_patch(rect)\n",
    "            \n",
    "            # Nom de classe COCO\n",
    "            class_name = coco_model.names[cls]\n",
    "            ax1.text(\n",
    "                x1, y1-5, f\"{class_name}: {conf:.2f}\",\n",
    "                color='blue', fontsize=8, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue', alpha=0.7)\n",
    "            )\n",
    "    \n",
    "    ax1.set_title(f\"Mod√®le COCO Original\\n{len(coco_results[0].boxes)} d√©tections\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Mod√®le surveillance\n",
    "    ax2.imshow(image_rgb)\n",
    "    if len(surveillance_results[0].boxes) > 0:\n",
    "        boxes = surveillance_results[0].boxes\n",
    "        for j in range(len(boxes)):\n",
    "            x1, y1, x2, y2 = boxes.xyxy[j].cpu().numpy()\n",
    "            conf = boxes.conf[j].cpu().numpy()\n",
    "            cls = int(boxes.cls[j].cpu().numpy())\n",
    "            \n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1), x2-x1, y2-y1,\n",
    "                linewidth=2, edgecolor='red', facecolor='none'\n",
    "            )\n",
    "            ax2.add_patch(rect)\n",
    "            \n",
    "            # Nom de classe surveillance\n",
    "            class_name = SURVEILLANCE_CLASSES.get(cls, f\"class_{cls}\")\n",
    "            ax2.text(\n",
    "                x1, y1-5, f\"{class_name}: {conf:.2f}\",\n",
    "                color='red', fontsize=8, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='yellow', alpha=0.7)\n",
    "            )\n",
    "    \n",
    "    ax2.set_title(f\"Mod√®le Surveillance Fine-tun√©\\n{len(surveillance_results[0].boxes)} d√©tections\")\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"üîç Comparaison Mod√®les COCO vs Surveillance\", fontsize=16, y=0.98)\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyse comparative\n",
    "    print(\"\\nüìä Analyse comparative:\")\n",
    "    print(f\"  D√©tections COCO: {len(coco_results[0].boxes)}\")\n",
    "    print(f\"  D√©tections Surveillance: {len(surveillance_results[0].boxes)}\")\n",
    "    \n",
    "    # Classes d√©tect√©es\n",
    "    if len(coco_results[0].boxes) > 0:\n",
    "        coco_classes = [coco_model.names[int(cls)] for cls in coco_results[0].boxes.cls.cpu().numpy()]\n",
    "        print(f\"  Classes COCO: {set(coco_classes)}\")\n",
    "    \n",
    "    if len(surveillance_results[0].boxes) > 0:\n",
    "        surv_classes = [SURVEILLANCE_CLASSES.get(int(cls), f\"class_{cls}\") for cls in surveillance_results[0].boxes.cls.cpu().numpy()]\n",
    "        print(f\"  Classes Surveillance: {set(surv_classes)}\")\n",
    "    \n",
    "    print(\"\\nüí° Observations attendues:\")\n",
    "    print(\"  ‚Ä¢ Le mod√®le surveillance devrait mieux d√©tecter les objets sp√©cialis√©s\")\n",
    "    print(\"  ‚Ä¢ Les classes de surveillance sont plus sp√©cifiques au contexte\")\n",
    "    print(\"  ‚Ä¢ La pr√©cision devrait √™tre am√©lior√©e pour les sc√©narios cibl√©s\")\n",
    "\nelse:\n",
    "    print(\"‚ö†Ô∏è Comparaison impossible - Entra√Ænement non r√©ussi\")\n",
    "\n",
    "print(\"\\n‚úÖ Comparaison termin√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "optimization"
   },
   "source": [
    "## ‚ö° Optimisation et Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_optimized"
   },
   "outputs": [],
   "source": [
    "# Export du mod√®le dans diff√©rents formats pour d√©ploiement\n",
    "print(\"‚ö° EXPORT ET OPTIMISATION DU MOD√àLE\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "if training_success:\n",
    "    export_formats = {\n",
    "        \"ONNX\": \"onnx\",        # Standard inter-frameworks\n",
    "        \"TensorRT\": \"engine\",  # NVIDIA optimis√© (si GPU NVIDIA)\n",
    "        \"TorchScript\": \"torchscript\", # PyTorch optimis√©\n",
    "        \"OpenVINO\": \"openvino\",     # Intel optimis√©\n",
    "    }\n",
    "    \n",
    "    exported_models = {}\n",
    "    \n",
    "    for format_name, format_ext in export_formats.items():\n",
    "        try:\n",
    "            print(f\"\\nüì¶ Export {format_name}...\")\n",
    "            \n",
    "            if format_name == \"TensorRT\" and not torch.cuda.is_available():\n",
    "                print(f\"  ‚è≠Ô∏è TensorRT ignor√© (pas de GPU NVIDIA)\")\n",
    "                continue\n",
    "                \n",
    "            if format_name == \"OpenVINO\":\n",
    "                print(f\"  ‚è≠Ô∏è OpenVINO ignor√© (installation complexe sur Colab)\")\n",
    "                continue\n",
    "            \n",
    "            # Export du mod√®le\n",
    "            export_path = model.export(\n",
    "                format=format_ext,\n",
    "                imgsz=TRAINING_CONFIG[\"image_size\"],\n",
    "                optimize=True,\n",
    "                half=torch.cuda.is_available(),  # FP16 si GPU\n",
    "                device=0 if torch.cuda.is_available() else \"cpu\"\n",
    "            )\n",
    "            \n",
    "            exported_models[format_name] = export_path\n",
    "            print(f\"  ‚úÖ {format_name} export√©: {export_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Erreur export {format_name}: {e}\")\n",
    "    \n",
    "    # Test des performances des mod√®les export√©s\n",
    "    print(\"\\n‚ö° Benchmark des performances:\")\n",
    "    \n",
    "    test_image = list((DATA_DIR / 'images' / 'val').glob('*.jpg'))[0]\n",
    "    \n",
    "    # Test mod√®le PyTorch original\n",
    "    start_time = time.time()\n",
    "    for _ in range(10):\n",
    "        _ = model.predict(test_image, verbose=False)\n",
    "    pytorch_time = (time.time() - start_time) / 10\n",
    "    print(f\"  PyTorch: {pytorch_time*1000:.1f}ms/image\")\n",
    "    \n",
    "    # Test mod√®les export√©s\n",
    "    for format_name, model_path in exported_models.items():\n",
    "        try:\n",
    "            # Chargement du mod√®le export√©\n",
    "            exported_model = YOLO(model_path)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            for _ in range(10):\n",
    "                _ = exported_model.predict(test_image, verbose=False)\n",
    "            export_time = (time.time() - start_time) / 10\n",
    "            \n",
    "            speedup = pytorch_time / export_time\n",
    "            print(f\"  {format_name}: {export_time*1000:.1f}ms/image (speedup: {speedup:.1f}x)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  {format_name}: Erreur benchmark - {e}\")\n",
    "\nelse:\n",
    "    print(\"‚ö†Ô∏è Export impossible - Mod√®le non entra√Æn√©\")\n",
    "\n",
    "print(\"\\n‚úÖ Optimisation termin√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "integration_code"
   },
   "outputs": [],
   "source": [
    "# G√©n√©ration du code d'int√©gration pour le syst√®me principal\n",
    "print(\"üîó G√âN√âRATION CODE D'INT√âGRATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if training_success:\n",
    "    # Code d'int√©gration personnalis√©\n",
    "    integration_template = f'''\n",
    "# Int√©gration du mod√®le YOLO fine-tun√© dans le syst√®me de surveillance\n",
    "# Remplacez dans src/detection/yolo/detector.py\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "class SurveillanceYOLODetector:\n",
    "    \"\"\"\n",
    "    D√©tecteur YOLO sp√©cialis√© pour la surveillance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Classes sp√©cialis√©es surveillance\n",
    "    SURVEILLANCE_CLASSES = {{\n",
    "        {', '.join([f'{k}: \"{v}\"' for k, v in SURVEILLANCE_CLASSES.items()])}\n",
    "    }}\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_path: str = \"models/surveillance_yolo.pt\",\n",
    "                 confidence_threshold: float = 0.25,\n",
    "                 device: str = \"auto\"):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.device = self._setup_device(device)\n",
    "        \n",
    "        # Chargement du mod√®le fine-tun√©\n",
    "        if Path(model_path).exists():\n",
    "            self.model = YOLO(model_path)\n",
    "            print(f\"‚úÖ Mod√®le surveillance charg√©: {{model_path}}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Mod√®le introuvable: {{model_path}} - Utilisation mod√®le standard\")\n",
    "            self.model = YOLO(\"yolov8n.pt\")\n",
    "        \n",
    "        self.is_loaded = True\n",
    "    \n",
    "    def detect(self, frame, custom_confidence=None):\n",
    "        \"\"\"D√©tection avec le mod√®le fine-tun√©.\"\"\"\n",
    "        \n",
    "        conf = custom_confidence or self.confidence_threshold\n",
    "        \n",
    "        # Pr√©diction\n",
    "        results = self.model.predict(\n",
    "            frame.image,\n",
    "            conf=conf,\n",
    "            verbose=False,\n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        # Conversion vers le format DetectedObject\n",
    "        detections = []\n",
    "        \n",
    "        if len(results[0].boxes) > 0:\n",
    "            boxes = results[0].boxes\n",
    "            for i in range(len(boxes)):\n",
    "                x1, y1, x2, y2 = boxes.xyxy[i].cpu().numpy()\n",
    "                conf = float(boxes.conf[i].cpu().numpy())\n",
    "                cls = int(boxes.cls[i].cpu().numpy())\n",
    "                \n",
    "                # Cr√©ation BoundingBox\n",
    "                bbox = BoundingBox(\n",
    "                    x=int(x1),\n",
    "                    y=int(y1), \n",
    "                    width=int(x2-x1),\n",
    "                    height=int(y2-y1),\n",
    "                    confidence=conf\n",
    "                )\n",
    "                \n",
    "                # Cr√©ation DetectedObject\n",
    "                detection = DetectedObject(\n",
    "                    class_id=cls,\n",
    "                    class_name=self.SURVEILLANCE_CLASSES.get(cls, f\"class_{{cls}}\"),\n",
    "                    bbox=bbox,\n",
    "                    confidence=conf\n",
    "                )\n",
    "                \n",
    "                detections.append(detection)\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def _setup_device(self, device):\n",
    "        if device == \"auto\":\n",
    "            return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        return device\n",
    "\n",
    "# Usage dans le syst√®me principal:\n",
    "# detector = SurveillanceYOLODetector(\n",
    "#     model_path=\"models/surveillance_yolo_optimized.pt\",\n",
    "#     confidence_threshold=0.3\n",
    "# )\n",
    "'''\n",
    "    \n",
    "    # Sauvegarde du code d'int√©gration\n",
    "    integration_path = RESULTS_DIR / \"surveillance_yolo_integration.py\"\n",
    "    with open(integration_path, 'w') as f:\n",
    "        f.write(integration_template)\n",
    "    \n",
    "    print(f\"‚úÖ Code d'int√©gration g√©n√©r√©: {integration_path}\")\n",
    "    \n",
    "    # Instructions d'utilisation\n",
    "    print(\"\\nüìã INSTRUCTIONS D'INT√âGRATION:\")\n",
    "    print(\"1. üìÅ Copiez le mod√®le .pt dans le dossier models/ du projet\")\n",
    "    print(\"2. üîß Remplacez YOLODetector par SurveillanceYOLODetector\")\n",
    "    print(\"3. üß™ Testez avec vos donn√©es de surveillance r√©elles\")\n",
    "    print(\"4. ‚öôÔ∏è Ajustez confidence_threshold selon vos besoins\")\n",
    "    print(\"5. üìä Surveillez les m√©triques de performance en production\")\n",
    "    \n",
    "    # Configuration recommand√©e\n",
    "    print(\"\\n‚öôÔ∏è CONFIGURATION RECOMMAND√âE:\")\n",
    "    print(f\"  ‚Ä¢ Seuil confiance: 0.25-0.4 (selon pr√©cision/rappel souhait√©s)\")\n",
    "    print(f\"  ‚Ä¢ Taille image: {TRAINING_CONFIG['image_size']} (m√™me qu'entra√Ænement)\")\n",
    "    print(f\"  ‚Ä¢ Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "    print(f\"  ‚Ä¢ Format optimal: {'ONNX ou TensorRT' if torch.cuda.is_available() else 'ONNX'}\")\n",
    "    \nelse:\n",
    "    print(\"‚ö†Ô∏è G√©n√©ration impossible - Mod√®le non entra√Æn√©\")\n",
    "\n",
    "print(\"\\n‚úÖ Int√©gration pr√©par√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deployment"
   },
   "source": [
    "## üíæ Sauvegarde et D√©ploiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_artifacts"
   },
   "outputs": [],
   "source": [
    "# Sauvegarde compl√®te des artefacts d'entra√Ænement\n",
    "print(\"üíæ SAUVEGARDE DES ARTEFACTS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "if training_success:\n",
    "    # Cr√©ation du dossier de sauvegarde\n",
    "    save_dir = RESULTS_DIR / f\"surveillance_yolo_complete_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # 1. Mod√®le principal\n",
    "    print(\"üì¶ Sauvegarde mod√®le et poids...\")\n",
    "    model_save_path = save_dir / \"surveillance_yolo.pt\"\n",
    "    model.save(model_save_path)\n",
    "    print(f\"  ‚úÖ Mod√®le: {model_save_path}\")\n",
    "    \n",
    "    # 2. Configuration dataset\n",
    "    import shutil\n",
    "    dataset_config_path = save_dir / \"dataset.yaml\"\n",
    "    shutil.copy(yaml_path, dataset_config_path)\n",
    "    print(f\"  ‚úÖ Config dataset: {dataset_config_path}\")\n",
    "    \n",
    "    # 3. M√©triques et logs d'entra√Ænement\n",
    "    training_metadata = {\n",
    "        \"model_info\": {\n",
    "            \"base_model\": model_size,\n",
    "            \"classes_count\": len(SURVEILLANCE_CLASSES),\n",
    "            \"classes\": SURVEILLANCE_CLASSES,\n",
    "        },\n",
    "        \"training_config\": TRAINING_CONFIG,\n",
    "        \"training_args\": {k: str(v) for k, v in training_args.items()},\n",
    "        \"dataset_info\": {\n",
    "            \"total_images\": sum(len(info) for info in dataset_info.values()),\n",
    "            \"splits\": {k: len(v) for k, v in dataset_info.items()},\n",
    "            \"class_distribution\": class_distribution\n",
    "        },\n",
    "        \"performance\": {\n",
    "            \"training_duration_minutes\": training_duration/60 if 'training_duration' in locals() else None,\n",
    "            \"gpu_used\": torch.cuda.get_device_name() if torch.cuda.is_available() else \"CPU\",\n",
    "            \"final_metrics\": getattr(results, 'results_dict', {}) if 'results' in locals() else {}\n",
    "        },\n",
    "        \"export_info\": {\n",
    "            \"exported_formats\": list(exported_models.keys()) if 'exported_models' in locals() else [],\n",
    "            \"pytorch_inference_ms\": pytorch_time*1000 if 'pytorch_time' in locals() else None\n",
    "        },\n",
    "        \"created_at\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    metadata_path = save_dir / \"training_metadata.json\"\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(training_metadata, f, indent=2, default=str)\n",
    "    print(f\"  ‚úÖ M√©tadonn√©es: {metadata_path}\")\n",
    "    \n",
    "    # 4. Code d'int√©gration\n",
    "    integration_dest = save_dir / \"integration_code.py\"\n",
    "    if integration_path.exists():\n",
    "        shutil.copy(integration_path, integration_dest)\n",
    "        print(f\"  ‚úÖ Code int√©gration: {integration_dest}\")\n",
    "    \n",
    "    # 5. Mod√®les export√©s\n",
    "    if 'exported_models' in locals():\n",
    "        exports_dir = save_dir / \"exported_models\"\n",
    "        exports_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        for format_name, model_path in exported_models.items():\n",
    "            try:\n",
    "                dest_path = exports_dir / f\"surveillance_yolo.{format_name.lower()}\"\n",
    "                shutil.copy(model_path, dest_path)\n",
    "                print(f\"  ‚úÖ Export {format_name}: {dest_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è Erreur copie {format_name}: {e}\")\n",
    "    \n",
    "    # 6. Documentation README\n",
    "    readme_content = f'''\n",
    "# üéØ Mod√®le YOLO Surveillance Fine-tun√©\n",
    "\n",
    "## Description\n",
    "Mod√®le YOLO v8 sp√©cialement fine-tun√© pour la d√©tection d'objets en contexte de surveillance de grande distribution.\n",
    "\n",
    "## Informations Mod√®le\n",
    "- **Mod√®le de base**: {model_size}\n",
    "- **Classes**: {len(SURVEILLANCE_CLASSES)} classes sp√©cialis√©es\n",
    "- **Entra√Ænement**: {TRAINING_CONFIG[\"epochs\"]} √©poques\n",
    "- **Dataset**: {sum(len(info) for info in dataset_info.values())} images\n",
    "- **GPU utilis√©**: {torch.cuda.get_device_name() if torch.cuda.is_available() else \"CPU\"}\n",
    "- **Date cr√©ation**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "\n",
    "## Classes D√©tect√©es\n",
    "```python\n",
    "CLASSES = {{\n",
    "    {chr(10).join([f\"    {k}: '{v}'\" for k, v in SURVEILLANCE_CLASSES.items()])}\n",
    "}}\n",
    "```\n",
    "\n",
    "## Utilisation\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Chargement du mod√®le\n",
    "model = YOLO('surveillance_yolo.pt')\n",
    "\n",
    "# Pr√©diction\n",
    "results = model.predict('image.jpg', conf=0.25)\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "results[0].show()\n",
    "```\n",
    "\n",
    "## Performance\n",
    "- **Pr√©cision optimis√©e** pour contexte surveillance\n",
    "- **Classes sp√©cialis√©es** adapt√©es aux magasins\n",
    "- **Transfer learning** depuis COCO pour rapidit√©\n",
    "{f\"- **Temps inf√©rence**: ~{pytorch_time*1000:.0f}ms par image\" if 'pytorch_time' in locals() else \"\"}\n",
    "\n",
    "## Int√©gration\n",
    "Consultez `integration_code.py` pour l'int√©gration dans le syst√®me de surveillance complet.\n",
    "\n",
    "## Fichiers Inclus\n",
    "- `surveillance_yolo.pt` - Mod√®le principal\n",
    "- `dataset.yaml` - Configuration classes\n",
    "- `training_metadata.json` - M√©triques d'entra√Ænement\n",
    "- `integration_code.py` - Code d'int√©gration\n",
    "- `exported_models/` - Mod√®les optimis√©s (ONNX, etc.)\n",
    "\n",
    "## Support\n",
    "Pour questions ou am√©liorations, consultez la documentation du syst√®me de surveillance complet.\n",
    "'''\n",
    "    \n",
    "    readme_path = save_dir / \"README.md\"\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(readme_content)\n",
    "    print(f\"  ‚úÖ Documentation: {readme_path}\")\n",
    "    \n",
    "    # 7. Archive compl√®te\n",
    "    print(\"\\nüì¶ Cr√©ation de l'archive...\")\n",
    "    archive_name = f\"surveillance_yolo_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "    \n",
    "    try:\n",
    "        archive_path = shutil.make_archive(\n",
    "            str(RESULTS_DIR / archive_name), \n",
    "            'zip', \n",
    "            str(save_dir)\n",
    "        )\n",
    "        print(f\"  ‚úÖ Archive cr√©√©e: {archive_path}\")\n",
    "        \n",
    "        # Taille de l'archive\n",
    "        archive_size = Path(archive_path).stat().st_size / (1024*1024)\n",
    "        print(f\"  üìä Taille archive: {archive_size:.1f} MB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Erreur cr√©ation archive: {e}\")\n",
    "    \n",
    "    # 8. T√©l√©chargement sur Colab\n",
    "    if 'google.colab' in str(get_ipython()):\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            print(\"\\nüì• T√©l√©chargement sur Colab...\")\n",
    "            \n",
    "            # T√©l√©charger l'archive\n",
    "            if 'archive_path' in locals() and Path(archive_path).exists():\n",
    "                files.download(archive_path)\n",
    "                print(\"  ‚úÖ Archive t√©l√©charg√©e\")\n",
    "            \n",
    "            # T√©l√©charger le mod√®le principal\n",
    "            files.download(str(model_save_path))\n",
    "            print(\"  ‚úÖ Mod√®le t√©l√©charg√©\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è T√©l√©chargement impossible: {e}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Sauvegarde termin√©e dans: {save_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pas de sauvegarde - Entra√Ænement non r√©ussi\")\n",
    "\n",
    "print(\"\\nüìã FICHIERS G√âN√âR√âS:\")\n",
    "if training_success:\n",
    "    print(f\"  üìÅ Dossier principal: {save_dir}\")\n",
    "    print(f\"  ü§ñ Mod√®le YOLO: surveillance_yolo.pt\")\n",
    "    print(f\"  ‚öôÔ∏è Configuration: dataset.yaml\")\n",
    "    print(f\"  üìä M√©tadonn√©es: training_metadata.json\")\n",
    "    print(f\"  üîß Code int√©gration: integration_code.py\")\n",
    "    print(f\"  üìñ Documentation: README.md\")\n",
    "    print(f\"  üì¶ Archive: {archive_name}.zip (si cr√©√©e)\")\n",
    "print(\"\\nüíæ Sauvegarde termin√©e !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## üéØ Conclusion et Prochaines √âtapes\n",
    "\n",
    "### ‚úÖ Ce que vous avez accompli :\n",
    "\n",
    "1. **üéØ Transfer Learning YOLO** : Adaptation depuis COCO vers surveillance\n",
    "2. **üìä Dataset Personnalis√©** : Classes sp√©cialis√©es pour la surveillance\n",
    "3. **‚ö° Optimisation** : Export ONNX/TensorRT pour d√©ploiement\n",
    "4. **üìà √âvaluation** : M√©triques compl√®tes et comparaisons\n",
    "5. **üîß Int√©gration** : Code pr√™t pour le syst√®me principal\n",
    "\n",
    "### üìä R√©sultats Attendus :\n",
    "\n",
    "Le mod√®le fine-tun√© devrait montrer :\n",
    "- **üéØ Classes sp√©cialis√©es** mieux adapt√©es √† la surveillance\n",
    "- **üìà Pr√©cision am√©lior√©e** pour objets de surveillance\n",
    "- **‚ö° Performance optimis√©e** pour d√©ploiement temps r√©el\n",
    "- **üîß Int√©gration facile** dans le syst√®me existant\n",
    "\n",
    "### üìä M√©triques Importantes :\n",
    "\n",
    "√Ä surveiller en production :\n",
    "- **mAP@0.5** > 0.7 pour les classes critiques (person, handbag)\n",
    "- **Pr√©cision** > 0.8 pour minimiser les faux positifs\n",
    "- **Rappel** > 0.75 pour ne pas manquer les vrais positifs\n",
    "- **Temps d'inf√©rence** < 50ms pour temps r√©el\n",
    "\n",
    "### üöÄ Prochaines √âtapes Recommand√©es :\n",
    "\n",
    "1. **üìä Dataset R√©el** : Collectez et annotez vos donn√©es de surveillance\n",
    "2. **üîÑ Fine-tuning It√©ratif** : Am√©liorez avec donn√©es terrain\n",
    "3. **üìà Validation Crois√©e** : Testez sur diff√©rents magasins/conditions\n",
    "4. **‚ö° Optimisation Edge** : TensorRT/OpenVINO pour d√©ploiement embarqu√©\n",
    "5. **üìä Monitoring Production** : M√©triques temps r√©el et drift detection\n",
    "\n",
    "### üí° Conseils pour la Production :\n",
    "\n",
    "#### Dataset\n",
    "- **üì∏ Images vari√©es** : Diff√©rentes conditions (√©clairage, foule, heures)\n",
    "- **üè∑Ô∏è Annotations pr√©cises** : IoU > 0.8, validation par experts\n",
    "- **‚öñÔ∏è Classes √©quilibr√©es** : SMOTE ou oversampling pour classes rares\n",
    "- **üìà Augmentation** : Rotation, √©chelle, luminosit√© selon contexte\n",
    "\n",
    "#### Mod√®le\n",
    "- **üéõÔ∏è Hyperparam√®tres** : Grid search sur lr, batch_size, epochs\n",
    "- **üîç Seuils optimaux** : Courbes PR pour balance pr√©cision/rappel\n",
    "- **üìä Validation** : K-fold ou temporal split pour robustesse\n",
    "- **‚ö° Ensemble** : Combinaison de plusieurs mod√®les si ressources suffisantes\n",
    "\n",
    "#### D√©ploiement\n",
    "- **üñ•Ô∏è Infrastructure** : GPU pour temps r√©el, fallback CPU\n",
    "- **üìà Monitoring** : Latence, m√©moire, drift de donn√©es\n",
    "- **üîÑ CI/CD** : Pipeline automatique retrain/deploy\n",
    "- **üë• Feedback Loop** : Annotations terrain pour am√©lioration continue\n",
    "\n",
    "### üõ†Ô∏è Int√©gration Syst√®me Complet :\n",
    "\n",
    "```python\n",
    "# Dans votre syst√®me principal\n",
    "from surveillance_yolo_integration import SurveillanceYOLODetector\n",
    "\n",
    "# Remplacer YOLODetector par SurveillanceYOLODetector\n",
    "detector = SurveillanceYOLODetector(\n",
    "    model_path=\"models/surveillance_yolo.pt\",\n",
    "    confidence_threshold=0.3\n",
    ")\n",
    "\n",
    "# Le reste du pipeline reste identique\n",
    "results = detector.detect(frame)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ F√©licitations ! Vous ma√Ætrisez maintenant le transfer learning YOLO pour la surveillance.**\n",
    "\n",
    "**üìö Ressources Compl√©mentaires :**\n",
    "- [Ultralytics YOLOv8 Docs](https://docs.ultralytics.com/)\n",
    "- [Transfer Learning Best Practices](https://arxiv.org/abs/1411.1792)\n",
    "- [YOLO Transfer Learning Guide](https://github.com/ultralytics/ultralytics)\n",
    "- [Syst√®me de Surveillance Complet](https://github.com/elfried-kinzoun/intelligent-surveillance-system)\n",
    "\n",
    "*D√©velopp√© pour r√©volutionner la d√©tection d'objets en surveillance*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}