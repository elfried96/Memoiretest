#!/usr/bin/env python3
"""
ğŸ¯ MAIN QWEN - Pipeline UNIQUEMENT avec Qwen2-VL
================================================

Version dÃ©diÃ©e EXCLUSIVEMENT au modÃ¨le Qwen2-VL.
AUCUN fallback - Si Qwen2-VL Ã©choue, le systÃ¨me s'arrÃªte.
"""

import asyncio
import cv2
import time
import base64
import json
import argparse
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum
import logging
from io import BytesIO
import numpy as np

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# Imports du systÃ¨me de surveillance
from src.core.vlm.dynamic_model import DynamicVisionLanguageModel
from src.core.orchestrator.vlm_orchestrator import (
    ModernVLMOrchestrator, 
    OrchestrationConfig, 
    OrchestrationMode
)
from src.core.types import DetectedObject, BoundingBox
from src.detection.yolo_detector import YOLODetector
from src.detection.tracking.byte_tracker import BYTETracker
from src.core.vlm.memory_system import vlm_memory


class AlertLevel(Enum):
    """Niveaux d'alerte du systÃ¨me."""
    NORMAL = "normal"
    ATTENTION = "attention" 
    ALERTE = "alerte"
    CRITIQUE = "critique"


@dataclass
class SurveillanceResult:
    """RÃ©sultat de surveillance pour export JSON."""
    frame_id: int
    timestamp: float
    detections_count: int
    persons_detected: int
    alert_level: str
    vlm_analysis: Optional[Dict] = None
    actions_taken: List[str] = None
    processing_time: float = 0.0


class QwenOnlySurveillanceSystem:
    """SystÃ¨me de surveillance UNIQUEMENT pour Qwen2-VL - AUCUN fallback."""
    
    def __init__(
        self,
        video_source: str = 0,
        vlm_model: str = "qwen2-vl-72b", 
        orchestration_mode: OrchestrationMode = OrchestrationMode.BALANCED,
        save_results: bool = True,
        save_frames: bool = False
    ):
        self.video_source = video_source
        self.vlm_model = vlm_model  # FORCE Qwen2-VL - pas de "none"
        self.orchestration_mode = orchestration_mode
        self.save_results = save_results
        self.save_frames = save_frames
        
        # Dossiers de sortie spÃ©cifiques Qwen
        self.output_dir = Path("surveillance_output_qwen_only")
        self.output_dir.mkdir(exist_ok=True)
        
        if save_frames:
            self.frames_dir = self.output_dir / "frames"
            self.frames_dir.mkdir(exist_ok=True)
        
        # === COMPOSANTS PRINCIPAUX ===
        
        # 1. DÃ©tection et tracking
        self.yolo_detector = YOLODetector(
            model_path="yolov11n.pt",
            device="auto"
        )
        self.tracker = BYTETracker()
        
        # 2. VLM UNIQUEMENT QWEN2-VL - FALLBACK DÃ‰SACTIVÃ‰
        self.vlm = DynamicVisionLanguageModel(
            default_model=vlm_model,
            enable_fallback=False  # âŒ AUCUN FALLBACK
        )
        
        config = OrchestrationConfig(
            mode=orchestration_mode,
            enable_advanced_tools=True,
            max_concurrent_tools=4,
            confidence_threshold=0.7
        )
        
        self.orchestrator = ModernVLMOrchestrator(
            vlm_model_name=vlm_model,
            config=config
        )
        
        # âœ… VLM OBLIGATOIRE - pas de mode dÃ©gradÃ©
        self.vlm_enabled = True
        logger.info(f"âœ… SYSTÃˆME QWEN2-VL ONLY - ModÃ¨le: {vlm_model}")
        logger.info("âš ï¸ AUCUN FALLBACK - Qwen2-VL obligatoire")
        
        # === Ã‰TAT DU SYSTÃˆME ===
        self.frame_count = 0
        self.results_log = []
        self.processing_stats = {
            "total_frames": 0,
            "detected_objects": 0,
            "persons_detected": 0,
            "vlm_analyses": 0,
            "vlm_triggered": 0,
            "alerts_triggered": 0,
            "total_processing_time": 0.0,
            "average_fps": 0.0
        }
        
        # === SYSTÃˆME DE DÃ‰CLENCHEMENT INTELLIGENT ===
        self.last_vlm_trigger_time = 0
        self.vlm_cooldown_seconds = 5
        self.person_count_history = []
        self.alert_history = []
        
        logger.info(f"ğŸ¯ SystÃ¨me QWEN2-VL ONLY initialisÃ© - Mode: {orchestration_mode.value}")
        logger.info(f"ğŸ“ RÃ©sultats sauvÃ©s dans: {self.output_dir}")
    
    async def initialize(self):
        """Initialisation - ECHEC SI QWEN2-VL N'EST PAS DISPONIBLE."""
        logger.info("ğŸš€ Initialisation QWEN2-VL ONLY...")
        
        # Chargement OBLIGATOIRE de Qwen2-VL
        logger.info(f"â³ Chargement OBLIGATOIRE de {self.vlm_model}...")
        vlm_loaded = await self.vlm.load_model()
        
        if not vlm_loaded:
            # ğŸ›‘ ARRÃŠT COMPLET - pas de fallback
            logger.error("âŒ Ã‰CHEC: Qwen2-VL non disponible")
            logger.error("âŒ ARRÃŠT DU SYSTÃˆME - Aucun fallback configurÃ©")
            sys.exit(1)
        
        logger.info(f"âœ… {self.vlm_model} chargÃ© avec succÃ¨s - SYSTÃˆME OPÃ‰RATIONNEL")
        
        # Test des composants
        logger.info("ğŸ” Tests des composants...")
        
        # Test YOLO
        test_frame = np.zeros((480, 640, 3), dtype=np.uint8)
        test_detections = self.yolo_detector.detect(test_frame)
        logger.info(f"âœ… YOLO opÃ©rationnel - {len(test_detections)} dÃ©tections test")
        
        # Health check OBLIGATOIRE
        status = await self.orchestrator.health_check()
        logger.info(f"ğŸ“Š Health check Qwen2-VL: {status}")
        
        if not status.get('vlm_ready', False):
            logger.error("âŒ VLM non prÃªt - ARRÃŠT SYSTÃˆME")
            sys.exit(1)
        
        logger.info("ğŸ¯ SystÃ¨me QWEN2-VL ONLY prÃªt pour surveillance!")
    
    def create_detections_list(self, yolo_results) -> List[DetectedObject]:
        """Convertit les rÃ©sultats YOLO en liste de Detection."""
        detections = []
        
        for result in yolo_results:
            if hasattr(result, 'boxes') and result.boxes is not None:
                for box in result.boxes:
                    # Extraction des coordonnÃ©es
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].cpu().numpy()
                    cls = int(box.cls[0].cpu().numpy())
                    
                    # Nom de classe
                    class_names = result.names
                    class_name = class_names.get(cls, f"class_{cls}")
                    
                    # CrÃ©ation de la dÃ©tection
                    detection = DetectedObject(
                        class_id=cls,
                        class_name=class_name,
                        bbox=BoundingBox(x1=float(x1), y1=float(y1), x2=float(x2), y2=float(y2)),
                        confidence=float(conf),
                        track_id=None
                    )
                    detections.append(detection)
        
        return detections
    
    def _should_trigger_vlm_analysis(self, detections: List[DetectedObject], persons_count: int, context: Dict[str, Any]) -> bool:
        """
        DÃ©termine si Qwen2-VL doit Ãªtre dÃ©clenchÃ©.
        """
        current_time = time.time()
        
        # 1. VÃ©rifier le cooldown
        if current_time - self.last_vlm_trigger_time < self.vlm_cooldown_seconds:
            return False
        
        # 2. Toujours dÃ©clencher si beaucoup de personnes
        if persons_count >= 3:
            logger.info(f"ğŸš¨ Qwen2-VL dÃ©clenchÃ©: {persons_count} personnes dÃ©tectÃ©es")
            return True
        
        # 3. Maintenir historique du nombre de personnes
        self.person_count_history.append(persons_count)
        if len(self.person_count_history) > 10:
            self.person_count_history.pop(0)
        
        # 4. DÃ©tecter changement soudain de population
        if len(self.person_count_history) >= 5:
            recent_avg = sum(self.person_count_history[-5:]) / 5
            if persons_count > recent_avg + 1:
                logger.info(f"ğŸ“ˆ Qwen2-VL dÃ©clenchÃ©: augmentation population {recent_avg:.1f} â†’ {persons_count}")
                return True
        
        # 5. Objets suspects dÃ©tectÃ©s
        suspicious_objects = ["backpack", "handbag", "suitcase", "umbrella", "sports ball", "bag"]
        for detection in detections:
            if detection.class_name in suspicious_objects:
                logger.info(f"ğŸ‘œ Qwen2-VL dÃ©clenchÃ©: objet suspect '{detection.class_name}' dÃ©tectÃ©")
                return True
        
        # 6. Personne seule qui reste longtemps
        if persons_count == 1 and len(self.person_count_history) >= 8:
            if all(count == 1 for count in self.person_count_history[-8:]):
                logger.info("ğŸ• Qwen2-VL dÃ©clenchÃ©: personne seule depuis longtemps")
                return True
        
        # 7. DÃ©clenchement pÃ©riodique
        if not context.get("test_mode", False):
            if (current_time - self.last_vlm_trigger_time > 60 and persons_count > 0):
                logger.info("â° Qwen2-VL dÃ©clenchÃ©: contrÃ´le pÃ©riodique de sÃ©curitÃ©")
                return True
        
        return False
    
    def encode_frame_to_base64(self, frame: np.ndarray) -> str:
        """Encode un frame OpenCV en base64 pour Qwen2-VL."""
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        _, buffer = cv2.imencode('.jpg', frame_rgb, [cv2.IMWRITE_JPEG_QUALITY, 85])
        frame_b64 = base64.b64encode(buffer).decode('utf-8')
        return frame_b64
    
    def save_frame_with_detections(self, frame: np.ndarray, detections: List[DetectedObject], frame_id: int):
        """Sauvegarde un frame avec les dÃ©tections dessinÃ©es."""
        if not self.save_frames:
            return
            
        overlay_frame = frame.copy()
        
        # Dessiner les dÃ©tections
        for detection in detections:
            bbox = detection.bbox
            color = (0, 255, 0) if detection.class_name == "person" else (255, 0, 0)
            
            # Rectangle
            cv2.rectangle(
                overlay_frame,
                (int(bbox.x1), int(bbox.y1)),
                (int(bbox.x2), int(bbox.y2)),
                color, 2
            )
            
            # Label avec indication Qwen2-VL
            label = f"{detection.class_name}: {detection.confidence:.2f} [QWEN2-VL]"
            cv2.putText(
                overlay_frame, label,
                (int(bbox.x1), int(bbox.y1) - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2
            )
        
        # Sauvegarder
        frame_path = self.frames_dir / f"qwen_only_frame_{frame_id:06d}.jpg"
        cv2.imwrite(str(frame_path), overlay_frame)
        logger.debug(f"ğŸ–¼ï¸ Frame Qwen2-VL ONLY sauvÃ©: {frame_path}")
    
    async def process_frame(self, frame: np.ndarray) -> SurveillanceResult:
        """Traite un frame complet avec UNIQUEMENT Qwen2-VL."""
        
        start_time = time.time()
        self.frame_count += 1
        
        # === Ã‰TAPE 1: DÃ‰TECTION YOLO ===
        yolo_results = self.yolo_detector.detect(frame)
        detections = self.create_detections_list(yolo_results)
        
        # === Ã‰TAPE 1.5: TRACKING ===
        tracked_objects = self.tracker.update(detections)
        
        persons_count = len([d for d in detections if d.class_name == "person"])
        
        self.processing_stats["detected_objects"] += len(detections)
        self.processing_stats["persons_detected"] += persons_count
        
        # === Ã‰TAPE 2: ANALYSE QWEN2-VL UNIQUEMENT ===
        vlm_analysis = None
        alert_level = AlertLevel.NORMAL
        actions_taken = []
        
        # VÃ©rifier que Qwen2-VL est OBLIGATOIREMENT chargÃ©
        if not (hasattr(self.vlm, 'model') and self.vlm.model is not None):
            logger.error("âŒ ERREUR CRITIQUE: Qwen2-VL non chargÃ©")
            raise RuntimeError("Qwen2-VL non disponible - ARRÃŠT SYSTÃˆME")
        
        logger.debug(f"ğŸ§  Frame {self.frame_count} - Analyse QWEN2-VL ONLY...")
        
        # Encodage pour Qwen2-VL
        frame_b64 = self.encode_frame_to_base64(frame)
        
        # Contexte enrichi avec mÃ©moire historique
        memory_context = vlm_memory.get_context_for_vlm()
        
        context = {
            "frame_id": self.frame_count,
            "timestamp": time.time(),
            "location": "Store Main Area",
            "camera": "CAM_01_QWEN_ONLY",
            "person_count": persons_count,
            "total_objects": len(detections),
            "time_of_day": time.strftime("%H:%M:%S"),
            "vlm_model": "qwen2-vl-72b-ONLY",
            **memory_context
        }
        
        # DÃ‰CLENCHEMENT INTELLIGENT DE QWEN2-VL
        should_trigger_vlm = self._should_trigger_vlm_analysis(detections, persons_count, context)
        
        try:
            if should_trigger_vlm:
                # Marquer le dÃ©clenchement
                self.last_vlm_trigger_time = time.time()
                self.processing_stats["vlm_triggered"] += 1
                
                # Analyse orchestrÃ©e UNIQUEMENT avec Qwen2-VL
                vlm_analysis = await self.orchestrator.analyze_surveillance_frame(
                    frame_data=frame_b64,
                    detections=detections,
                    context=context
                )
                
                self.processing_stats["vlm_analyses"] += 1
            else:
                # Pas de dÃ©clenchement VLM - analyse lÃ©gÃ¨re seulement
                vlm_analysis = None
            
            # DÃ©cisions basÃ©es sur l'analyse Qwen2-VL
            if vlm_analysis is not None:
                if vlm_analysis.suspicion_level.value in ["HIGH", "CRITICAL"]:
                    alert_level = AlertLevel.ALERTE
                    actions_taken = ["qwen_alert_triggered", "recording_started"]
                    self.processing_stats["alerts_triggered"] += 1
                elif vlm_analysis.suspicion_level.value == "MEDIUM":
                    alert_level = AlertLevel.ATTENTION
                    actions_taken = ["qwen_increased_monitoring"]
            else:
                # Analyse de base sans VLM (surveillance continue rapide)
                if persons_count >= 3:
                    alert_level = AlertLevel.ATTENTION
                    actions_taken = ["high_occupancy_basic"]
                elif len(detections) > 5:
                    alert_level = AlertLevel.ATTENTION
                    actions_taken = ["many_objects_detected"]
            
        except Exception as e:
            logger.error(f"âŒ Erreur analyse Qwen2-VL frame {self.frame_count}: {e}")
            # En mode QWEN ONLY, on peut dÃ©cider d'arrÃªter ou continuer
            # Pour l'instant on continue mais on log l'erreur
        
        # === SAUVEGARDE FRAME SI DEMANDÃ‰E ===
        if len(detections) > 0 or alert_level != AlertLevel.NORMAL:
            self.save_frame_with_detections(frame, detections, self.frame_count)
        
        # === CRÃ‰ATION DU RÃ‰SULTAT ===
        processing_time = time.time() - start_time
        
        # SÃ©rialisation sÃ©curisÃ©e de vlm_analysis
        vlm_analysis_dict = None
        if vlm_analysis:
            try:
                if hasattr(vlm_analysis, 'to_dict'):
                    vlm_analysis_dict = vlm_analysis.to_dict()
                elif hasattr(vlm_analysis, '__dict__'):
                    vlm_analysis_dict = vlm_analysis.__dict__.copy()
                    # Convertir les enums en strings
                    for key, value in vlm_analysis_dict.items():
                        if hasattr(value, 'value'):
                            vlm_analysis_dict[key] = value.value
                    # Marquer comme QWEN ONLY
                    vlm_analysis_dict["model_used"] = "qwen2-vl-72b-ONLY"
            except Exception:
                vlm_analysis_dict = None
        
        result = SurveillanceResult(
            frame_id=self.frame_count,
            timestamp=time.time(),
            detections_count=len(detections),
            persons_detected=persons_count,
            alert_level=alert_level.value,
            vlm_analysis=vlm_analysis_dict,
            actions_taken=actions_taken,
            processing_time=processing_time
        )
        
        # === MISE Ã€ JOUR DES STATISTIQUES ===
        self.processing_stats["total_frames"] += 1
        self.processing_stats["total_processing_time"] += processing_time
        
        if self.processing_stats["total_frames"] > 0:
            avg_time = self.processing_stats["total_processing_time"] / self.processing_stats["total_frames"]
            self.processing_stats["average_fps"] = 1.0 / avg_time if avg_time > 0 else 0
        
        # === ENREGISTREMENT EN MÃ‰MOIRE ===
        vlm_triggered_for_memory = (vlm_analysis is not None)
        vlm_memory.add_frame(
            frame_id=self.frame_count,
            detections=detections,
            vlm_triggered=vlm_triggered_for_memory,
            vlm_analysis=vlm_analysis,
            alert_level=alert_level.value,
            actions_taken=actions_taken
        )
        
        # === LOGGING DÃ‰TAILLÃ‰ QWEN2-VL ONLY ===
        if persons_count > 0 or alert_level != AlertLevel.NORMAL:
            memory_stats = vlm_memory.get_memory_stats()
            
            logger.info(f"ğŸ“Š [QWEN2-VL ONLY] Frame {self.frame_count}: "
                       f"{len(detections)} objs, {persons_count} personnes, "
                       f"Alert: {alert_level.value}, "
                       f"Actions: {actions_taken}, "
                       f"Temps: {processing_time:.2f}s, "
                       f"MÃ©moire: {memory_stats['current_frames_in_memory']} frames, "
                       f"{memory_stats['active_persons']} personnes actives")
        elif self.frame_count % 60 == 0:
            # Calcul du taux de dÃ©clenchement
            trigger_rate = (self.processing_stats['vlm_triggered'] / self.processing_stats['total_frames'] * 100) if self.processing_stats['total_frames'] > 0 else 0
            memory_stats = vlm_memory.get_memory_stats()
            
            logger.info(f"ğŸ“ˆ [QWEN2-VL ONLY] Frame {self.frame_count}: "
                       f"FPS: {self.processing_stats['average_fps']:.1f}, "
                       f"Total objets: {self.processing_stats['detected_objects']}, "
                       f"VLM dÃ©clenchÃ©: {self.processing_stats['vlm_triggered']}/{self.processing_stats['total_frames']} ({trigger_rate:.1f}%), "
                       f"Analyses VLM: {self.processing_stats['vlm_analyses']}, "
                       f"Patterns dÃ©tectÃ©s: {memory_stats['patterns_detected']}")
        
        return result
    
    async def run_surveillance(self, max_frames: int = None):
        """Lance la surveillance en mode QWEN2-VL ONLY."""
        logger.info("ğŸ¬ DÃ©marrage surveillance QWEN2-VL ONLY...")
        
        # Ouverture de la source vidÃ©o
        cap = cv2.VideoCapture(self.video_source)
        
        if not cap.isOpened():
            logger.error(f"âŒ Impossible d'ouvrir source vidÃ©o: {self.video_source}")
            return
        
        # Optimisations extraction frames
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M','J','P','G'))
        
        # Informations vidÃ©o
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        logger.info(f"ğŸ“¹ Source vidÃ©o: {self.video_source}")
        logger.info(f"ğŸ“ RÃ©solution: {width}x{height} | FPS: {fps:.2f} | Frames: {total_frames}")
        logger.info(f"ğŸ¤– ModÃ¨le VLM: {self.vlm_model} UNIQUEMENT")
        
        try:
            frame_processed = 0
            
            while True:
                # Lecture optimisÃ©e du frame
                ret, frame = cap.read()
                if not ret:
                    logger.warning("ğŸ“¹ Fin de vidÃ©o ou erreur lecture")
                    break
                
                # Validation du frame
                if frame is None or frame.size == 0:
                    logger.warning("âš ï¸ Frame vide dÃ©tectÃ©")
                    continue
                
                if frame.shape[0] < 100 or frame.shape[1] < 100:
                    logger.warning(f"âš ï¸ Frame trop petit: {frame.shape}")
                    continue
                
                # Traitement complet du frame
                result = await self.process_frame(frame)
                self.results_log.append(result)
                
                frame_processed += 1
                
                # Limite de frames si spÃ©cifiÃ©e
                if max_frames and frame_processed >= max_frames:
                    logger.info(f"ğŸ Limite de {max_frames} frames atteinte")
                    break
        
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ ArrÃªt par interruption clavier")
        
        finally:
            # Nettoyage
            cap.release()
            
            # Sauvegarde des rÃ©sultats
            if self.save_results:
                self.save_results_to_json()
            
            # Statistiques finales
            self.print_final_statistics()
    
    def _serialize_result(self, result):
        """SÃ©rialise un rÃ©sultat en Ã©vitant les erreurs JSON."""
        import datetime
        
        def serialize_value(value):
            if hasattr(value, 'value'):
                return value.value
            elif isinstance(value, datetime.datetime):
                return value.isoformat()
            elif isinstance(value, dict):
                return {k: serialize_value(v) for k, v in value.items()}
            elif isinstance(value, list):
                return [serialize_value(item) for item in value]
            else:
                return value
        
        try:
            result_dict = asdict(result)
            return {key: serialize_value(value) for key, value in result_dict.items()}
        except Exception as e:
            return {
                "frame_id": getattr(result, 'frame_id', 0),
                "timestamp": getattr(result, 'timestamp', 0),
                "detections_count": getattr(result, 'detections_count', 0),
                "persons_detected": getattr(result, 'persons_detected', 0),
                "alert_level": getattr(result, 'alert_level', 'normal'),
                "actions_taken": getattr(result, 'actions_taken', []),
                "processing_time": getattr(result, 'processing_time', 0),
                "vlm_analysis": None,
                "model_used": "qwen2-vl-72b-ONLY"
            }
    
    def save_results_to_json(self):
        """Sauvegarde les rÃ©sultats en JSON."""
        results_file = self.output_dir / f"qwen_only_surveillance_{int(time.time())}.json"
        
        output_data = {
            "metadata": {
                "video_source": str(self.video_source),
                "vlm_model": self.vlm_model,
                "model_type": "qwen2-vl-72b-ONLY",
                "fallback_enabled": False,
                "orchestration_mode": self.orchestration_mode.value,
                "total_frames": len(self.results_log),
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            },
            "statistics": self.processing_stats,
            "results": [self._serialize_result(result) for result in self.results_log]
        }
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ RÃ©sultats QWEN2-VL ONLY sauvÃ©s: {results_file}")
    
    def print_final_statistics(self):
        """Affiche les statistiques finales."""
        logger.info("=" * 60)
        logger.info("ğŸ“ˆ STATISTIQUES FINALES QWEN2-VL ONLY")
        logger.info("=" * 60)
        
        # Statistiques gÃ©nÃ©rales
        for key, value in self.processing_stats.items():
            if isinstance(value, float):
                logger.info(f"  â€¢ {key}: {value:.2f}")
            else:
                logger.info(f"  â€¢ {key}: {value}")
        
        # EfficacitÃ© du dÃ©clenchement intelligent
        logger.info("")
        logger.info("ğŸ§  EFFICACITÃ‰ QWEN2-VL UNIQUEMENT:")
        logger.info("-" * 60)
        
        total_frames = self.processing_stats.get("total_frames", 1)
        vlm_triggered = self.processing_stats.get("vlm_triggered", 0)
        vlm_analyses = self.processing_stats.get("vlm_analyses", 0)
        
        trigger_rate = (vlm_triggered / total_frames * 100) if total_frames > 0 else 0
        success_rate = (vlm_analyses / vlm_triggered * 100) if vlm_triggered > 0 else 0
        
        logger.info(f"  ğŸ¯ Frames total traitÃ©s: {total_frames}")
        logger.info(f"  âš¡ Qwen2-VL dÃ©clenchÃ©: {vlm_triggered} fois ({trigger_rate:.1f}%)")
        logger.info(f"  âœ… Analyses rÃ©ussies: {vlm_analyses} ({success_rate:.1f}%)")
        logger.info(f"  ğŸš€ Ã‰conomie traitement: {(100 - trigger_rate):.1f}%")
        
        # Statistiques mÃ©moire
        memory_stats = vlm_memory.get_memory_stats()
        logger.info("")
        logger.info("ğŸ§  SYSTÃˆME DE MÃ‰MOIRE:")
        logger.info("-" * 60)
        logger.info(f"  ğŸ’¾ Frames en mÃ©moire: {memory_stats['current_frames_in_memory']}")
        logger.info(f"  ğŸ‘¥ Personnes trackÃ©es: {memory_stats['active_persons']}")
        logger.info(f"  ğŸ” Patterns dÃ©tectÃ©s: {memory_stats['patterns_detected']}")


def parse_arguments():
    """Parse les arguments de la ligne de commande."""
    parser = argparse.ArgumentParser(
        description="ğŸ¯ SystÃ¨me de Surveillance QWEN2-VL UNIQUEMENT",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument("--video", "-v", default="webcam",
                       help="Source vidÃ©o")
    parser.add_argument("--model", "-m", default="qwen2-vl-72b",
                       help="ModÃ¨le VLM Qwen2-VL")
    parser.add_argument("--mode", default="BALANCED",
                       choices=["FAST", "BALANCED", "THOROUGH"],
                       help="Mode orchestration")
    parser.add_argument("--max-frames", type=int, default=None,
                       help="Nombre max de frames")
    parser.add_argument("--save-frames", action="store_true",
                       help="Sauvegarder frames avec dÃ©tections")
    parser.add_argument("--no-save", action="store_true",
                       help="Ne pas sauvegarder les rÃ©sultats")
    
    return parser.parse_args()


async def main():
    """Point d'entrÃ©e principal QWEN2-VL ONLY."""
    args = parse_arguments()
    
    print(f"""
ğŸ¯ SYSTÃˆME DE SURVEILLANCE QWEN2-VL UNIQUEMENT
===============================================

Configuration:
ğŸ“¹ Source vidÃ©o  : {args.video}
ğŸ¤– ModÃ¨le VLM    : {args.model} UNIQUEMENT
âš™ï¸ Mode          : {args.mode}
ğŸ’¾ Sauvegarde    : {'ActivÃ©e' if not args.no_save else 'DÃ©sactivÃ©e'}
ğŸ–¼ï¸ Frames        : {'SauvÃ©es' if args.save_frames else 'Non sauvÃ©es'}
ğŸ“Š Max frames    : {args.max_frames or 'IllimitÃ©'}

âš ï¸ ATTENTION: AUCUN FALLBACK CONFIGURÃ‰
Si {args.model} Ã©choue â†’ ARRÃŠT DU SYSTÃˆME

WORKFLOW QWEN2-VL ONLY:
1. ğŸ“¹ Capture vidÃ©o â†’ logs dÃ©taillÃ©s
2. ğŸ” DÃ©tection YOLO â†’ comptage objets  
3. ğŸ§  Analyse Qwen2-VL UNIQUEMENT
4. ğŸš¨ Prise dÃ©cisions â†’ actions automatisÃ©es
5. ğŸ’¾ Export JSON â†’ rÃ©sultats structurÃ©s
6. ğŸ“Š Statistiques finales â†’ rapport complet
""")
    
    # Configuration du mode
    mode_mapping = {
        "FAST": OrchestrationMode.FAST,
        "BALANCED": OrchestrationMode.BALANCED,
        "THOROUGH": OrchestrationMode.THOROUGH
    }
    
    # Validation source vidÃ©o
    video_source = args.video
    if video_source.lower() == "webcam":
        video_source = 0
    
    # Initialisation systÃ¨me QWEN2-VL ONLY
    system = QwenOnlySurveillanceSystem(
        video_source=video_source,
        vlm_model=args.model,
        orchestration_mode=mode_mapping[args.mode],
        save_results=not args.no_save,
        save_frames=args.save_frames
    )
    
    try:
        # Initialisation et dÃ©marrage
        await system.initialize()
        await system.run_surveillance(max_frames=args.max_frames)
        
    except Exception as e:
        logger.error(f"âŒ Erreur systÃ¨me QWEN2-VL ONLY: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())