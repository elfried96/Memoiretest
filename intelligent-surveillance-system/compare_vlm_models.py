#!/usr/bin/env python3
"""Script de comparaison entre Kimi-VL et Qwen2-VL."""

import os
import json
import asyncio
import subprocess
from pathlib import Path
from datetime import datetime


class VLMComparison:
    """Outil de comparaison des modÃ¨les VLM."""
    
    def __init__(self):
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "kimi_vl": None,
            "qwen2_vl": None,
            "comparison": {}
        }
    
    def run_benchmark(self, script_name: str, model_name: str):
        """ExÃ©cuter un benchmark et capturer les rÃ©sultats."""
        
        print(f"\nğŸš€ Lancement benchmark {model_name}")
        print("=" * 50)
        
        try:
            # ExÃ©cuter le script de test
            result = subprocess.run(
                ["python", script_name], 
                capture_output=True, 
                text=True,
                timeout=1800  # 30 minutes max
            )
            
            if result.returncode == 0:
                print(f"âœ… {model_name} - Test rÃ©ussi")
                return {
                    "success": True,
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode
                }
            else:
                print(f"âŒ {model_name} - Test Ã©chouÃ© (code: {result.returncode})")
                return {
                    "success": False,
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode
                }
                
        except subprocess.TimeoutExpired:
            print(f"â° {model_name} - Timeout (30 min dÃ©passÃ©)")
            return {
                "success": False,
                "error": "timeout",
                "timeout": True
            }
            
        except Exception as e:
            print(f"âŒ {model_name} - Erreur: {e}")
            return {
                "success": False,
                "error": str(e),
                "exception": True
            }
    
    def parse_results(self, output: str) -> dict:
        """Parser les rÃ©sultats d'un benchmark."""
        
        parsed = {
            "tests_realises": 0,
            "taux_succes": 0.0,
            "temps_moyen": 0.0,
            "temps_total": 0.0,
            "details_tests": [],
            "raw_output": output
        }
        
        lines = output.split('\n')
        
        for line in lines:
            # Extraction des mÃ©triques principales
            if "Tests rÃ©alisÃ©s:" in line:
                try:
                    parsed["tests_realises"] = int(line.split(':')[1].strip())
                except:
                    pass
            
            elif "Taux de succÃ¨s:" in line:
                try:
                    parsed["taux_succes"] = float(line.split(':')[1].strip().rstrip('%'))
                except:
                    pass
            
            elif "Temps moyen:" in line:
                try:
                    parsed["temps_moyen"] = float(line.split(':')[1].strip().rstrip('s'))
                except:
                    pass
            
            elif "Temps total:" in line:
                try:
                    parsed["temps_total"] = float(line.split(':')[1].strip().rstrip('s'))
                except:
                    pass
            
            # DÃ©tails des tests individuels
            elif line.strip().startswith("âœ…") or line.strip().startswith("âŒ"):
                parsed["details_tests"].append(line.strip())
        
        return parsed
    
    def generate_comparison(self):
        """GÃ©nÃ©rer la comparaison dÃ©taillÃ©e."""
        
        if not self.results["kimi_vl"] or not self.results["qwen2_vl"]:
            print("âŒ Impossible de comparer - rÃ©sultats manquants")
            return
        
        kimi_success = self.results["kimi_vl"]["success"]
        qwen_success = self.results["qwen2_vl"]["success"]
        
        comparison = {
            "both_working": kimi_success and qwen_success,
            "kimi_only": kimi_success and not qwen_success,
            "qwen_only": not kimi_success and qwen_success,
            "both_failed": not kimi_success and not qwen_success
        }
        
        if comparison["both_working"]:
            # Comparaison dÃ©taillÃ©e des performances
            kimi_parsed = self.parse_results(self.results["kimi_vl"]["stdout"])
            qwen_parsed = self.parse_results(self.results["qwen2_vl"]["stdout"])
            
            comparison["performance"] = {
                "kimi_vl": kimi_parsed,
                "qwen2_vl": qwen_parsed,
                "winner": self.determine_winner(kimi_parsed, qwen_parsed)
            }
        
        self.results["comparison"] = comparison
        return comparison
    
    def determine_winner(self, kimi_stats: dict, qwen_stats: dict) -> dict:
        """DÃ©terminer le modÃ¨le gagnant selon diffÃ©rents critÃ¨res."""
        
        winner = {
            "overall": None,
            "speed": None,
            "reliability": None,
            "efficiency": None,
            "scores": {
                "kimi_vl": 0,
                "qwen2_vl": 0
            },
            "reasoning": []
        }
        
        # CritÃ¨re 1: FiabilitÃ© (taux de succÃ¨s)
        if kimi_stats["taux_succes"] > qwen_stats["taux_succes"]:
            winner["reliability"] = "kimi_vl"
            winner["scores"]["kimi_vl"] += 3
            winner["reasoning"].append(f"Kimi-VL plus fiable ({kimi_stats['taux_succes']:.1f}% vs {qwen_stats['taux_succes']:.1f}%)")
        elif qwen_stats["taux_succes"] > kimi_stats["taux_succes"]:
            winner["reliability"] = "qwen2_vl"
            winner["scores"]["qwen2_vl"] += 3
            winner["reasoning"].append(f"Qwen2-VL plus fiable ({qwen_stats['taux_succes']:.1f}% vs {kimi_stats['taux_succes']:.1f}%)")
        else:
            winner["reasoning"].append("FiabilitÃ© Ã©gale")
        
        # CritÃ¨re 2: Vitesse (temps moyen)
        if kimi_stats["temps_moyen"] < qwen_stats["temps_moyen"]:
            winner["speed"] = "kimi_vl"
            winner["scores"]["kimi_vl"] += 2
            winner["reasoning"].append(f"Kimi-VL plus rapide ({kimi_stats['temps_moyen']:.2f}s vs {qwen_stats['temps_moyen']:.2f}s)")
        elif qwen_stats["temps_moyen"] < kimi_stats["temps_moyen"]:
            winner["speed"] = "qwen2_vl"
            winner["scores"]["qwen2_vl"] += 2
            winner["reasoning"].append(f"Qwen2-VL plus rapide ({qwen_stats['temps_moyen']:.2f}s vs {kimi_stats['temps_moyen']:.2f}s)")
        else:
            winner["reasoning"].append("Vitesse similaire")
        
        # CritÃ¨re 3: EfficacitÃ© (tests rÃ©ussis par seconde)
        kimi_efficiency = (kimi_stats["taux_succes"] / 100) * kimi_stats["tests_realises"] / max(kimi_stats["temps_total"], 1)
        qwen_efficiency = (qwen_stats["taux_succes"] / 100) * qwen_stats["tests_realises"] / max(qwen_stats["temps_total"], 1)
        
        if kimi_efficiency > qwen_efficiency:
            winner["efficiency"] = "kimi_vl"
            winner["scores"]["kimi_vl"] += 1
            winner["reasoning"].append(f"Kimi-VL plus efficace ({kimi_efficiency:.2f} vs {qwen_efficiency:.2f} tests/s)")
        elif qwen_efficiency > kimi_efficiency:
            winner["efficiency"] = "qwen2_vl"
            winner["scores"]["qwen2_vl"] += 1
            winner["reasoning"].append(f"Qwen2-VL plus efficace ({qwen_efficiency:.2f} vs {kimi_efficiency:.2f} tests/s)")
        
        # Gagnant global
        if winner["scores"]["kimi_vl"] > winner["scores"]["qwen2_vl"]:
            winner["overall"] = "kimi_vl"
        elif winner["scores"]["qwen2_vl"] > winner["scores"]["kimi_vl"]:
            winner["overall"] = "qwen2_vl"
        else:
            winner["overall"] = "tie"
        
        return winner
    
    def print_comparison_report(self):
        """Afficher le rapport de comparaison."""
        
        print("\n" + "="*60)
        print("ğŸ“Š RAPPORT DE COMPARAISON VLM")
        print("="*60)
        
        comparison = self.results["comparison"]
        
        # Status global
        print(f"\nğŸ” Status des modÃ¨les:")
        print(f"  â€¢ Kimi-VL: {'âœ… Fonctionnel' if self.results['kimi_vl']['success'] else 'âŒ Ã‰chec'}")
        print(f"  â€¢ Qwen2-VL: {'âœ… Fonctionnel' if self.results['qwen2_vl']['success'] else 'âŒ Ã‰chec'}")
        
        # ScÃ©narios
        if comparison["both_working"]:
            print(f"\nğŸ¯ Les deux modÃ¨les fonctionnent - Comparaison possible!")
            
            perf = comparison["performance"]
            winner = perf["winner"]
            
            print(f"\nğŸ“ˆ Performances:")
            print(f"  Kimi-VL:   {perf['kimi_vl']['taux_succes']:.1f}% rÃ©ussite, {perf['kimi_vl']['temps_moyen']:.2f}s moyen")
            print(f"  Qwen2-VL:  {perf['qwen2_vl']['taux_succes']:.1f}% rÃ©ussite, {perf['qwen2_vl']['temps_moyen']:.2f}s moyen")
            
            print(f"\nğŸ† Gagnant: {winner['overall'].upper() if winner['overall'] != 'tie' else 'Ã‰GALITÃ‰'}")
            print(f"  Scores: Kimi-VL {winner['scores']['kimi_vl']} - Qwen2-VL {winner['scores']['qwen2_vl']}")
            
            print(f"\nğŸ’¡ Analyse dÃ©taillÃ©e:")
            for reason in winner["reasoning"]:
                print(f"  â€¢ {reason}")
            
            # Recommandation
            print(f"\nğŸ¯ Recommandation:")
            if winner['overall'] == 'kimi_vl':
                print("  ğŸ‘‘ Utilisez Kimi-VL pour ce projet")
                print("  ğŸ”§ Configuration recommandÃ©e: kimi-vl-a3b-thinking")
            elif winner['overall'] == 'qwen2_vl':
                print("  ğŸ‘‘ Utilisez Qwen2-VL pour ce projet")
                print("  ğŸ”§ Configuration recommandÃ©e: qwen2-vl-7b-instruct")
            else:
                print("  âš–ï¸  Performance Ã©quivalente - choisir selon les prÃ©fÃ©rences:")
                print("     â€¢ Kimi-VL: Plus rÃ©cent, spÃ©cialisÃ© surveillance")
                print("     â€¢ Qwen2-VL: Plus mature, OCR intÃ©grÃ©")
        
        elif comparison["kimi_only"]:
            print(f"\nâœ… Seul Kimi-VL fonctionne")
            print(f"  ğŸ¯ Recommandation: Utiliser Kimi-VL exclusivement")
        
        elif comparison["qwen_only"]:
            print(f"\nâœ… Seul Qwen2-VL fonctionne") 
            print(f"  ğŸ¯ Recommandation: Utiliser Qwen2-VL exclusivement")
        
        else:
            print(f"\nâŒ Aucun modÃ¨le ne fonctionne")
            print(f"  ğŸ”§ Action requise: VÃ©rifier la configuration systÃ¨me")
    
    def save_results(self, filename: str = "vlm_comparison_results.json"):
        """Sauvegarder les rÃ©sultats."""
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ RÃ©sultats sauvÃ©s dans {filename}")
    
    def run_full_comparison(self):
        """ExÃ©cuter la comparaison complÃ¨te."""
        
        print("ğŸš€ COMPARAISON KIMI-VL vs QWEN2-VL")
        print("=" * 60)
        print("âš ï¸  Cette comparaison peut prendre 30-60 minutes")
        print("ğŸ”„ Les modÃ¨les seront testÃ©s sÃ©quentiellement pour Ã©viter les conflits")
        
        input("\nPress Enter pour continuer ou Ctrl+C pour annuler...")
        
        # Test Kimi-VL
        self.results["kimi_vl"] = self.run_benchmark("test_kimi_vl_only.py", "Kimi-VL")
        
        # Test Qwen2-VL  
        self.results["qwen2_vl"] = self.run_benchmark("test_qwen2_vl_only.py", "Qwen2-VL")
        
        # Analyse comparative
        self.generate_comparison()
        
        # Rapport final
        self.print_comparison_report()
        
        # Sauvegarde
        self.save_results()


if __name__ == "__main__":
    comparator = VLMComparison()
    
    try:
        comparator.run_full_comparison()
    except KeyboardInterrupt:
        print("\nâ¹ï¸  Comparaison interrompue")
    except Exception as e:
        print(f"\nâŒ Erreur: {e}")
        import traceback
        traceback.print_exc()